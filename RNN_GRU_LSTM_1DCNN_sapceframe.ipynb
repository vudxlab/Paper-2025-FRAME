{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, add, LSTM, Dense, Dropout,GRU, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'D:/OneDrive/DXLab_Vu/BaiBao/Trong nuoc/2024/Paper-2024-1DCNNLSTM-Khung/Code\\Data'\n",
    "\n",
    "# all_data = {}\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.mat'):\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "        \n",
    "#         # Load the .mat file and add its contents to the dictionary\n",
    "#         mat_data = loadmat(filepath)\n",
    "        \n",
    "#         # Use filename (without extension) as key for the data\n",
    "#         key = os.path.splitext(filename)[0]\n",
    "#         row_means = np.mean(mat_data['acceleration'],1)\n",
    "#         rows_2_keep = row_means != 0\n",
    "#         all_data[key] = mat_data['acceleration'][rows_2_keep]\n",
    "        \n",
    "# keys_to_stack = [f'spaceframe{i}' for i in range(1,11)]\n",
    "# input_data = np.stack([all_data[key] for key in keys_to_stack], axis=0)\n",
    "\n",
    "# # Create the corresponding labels\n",
    "# output_labels = np.linspace(0,10,11)  # Using 0 and 1 as class labels for binary cross-entropy\n",
    "# label = output_labels\n",
    "\n",
    "# input_data = input_data[:,:,:10000]\n",
    "# input_data.shape, output_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the data at index (1, 1, :) which has a shape of (8000,)\n",
    "# Data = input_data[1,:, :]\n",
    "# print(Data.shape)\n",
    "# # Create the plot\n",
    "# fig, axes = plt.subplots(12, 1, figsize=(15, 8), sharex=True)\n",
    "\n",
    "# title_font = {'family': 'Times New Roman', 'size': 16, 'weight': 'bold'}\n",
    "# label_font = {'family': 'Times New Roman', 'size': 14}\n",
    "# plt.rcParams['xtick.labelsize'] = 10\n",
    "# plt.rcParams['ytick.labelsize'] = 10\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# # Plot the data for each sub-array\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.plot(Data[i, :], linewidth=1, color = 'b')\n",
    "#     # ax.set_title(f'Z24 Signal Data at Index (1, {i}, :)', fontsize=12)\n",
    "    \n",
    "#     ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     ax.minorticks_on()\n",
    "#     ax.grid(True, which='minor', color='#999999', linestyle='--', alpha=0.2)\n",
    "#     ax.set_xlim(-100, Data.shape[1]+100)\n",
    "# # Set common labels using axes\n",
    "# axes[-1].set_xlabel('Điểm dữ liệu', fontsize=14, fontdict=label_font)\n",
    "# axes[0].set_title('Dữ liệu Khung không gian', fontsize=16, fontdict=title_font)\n",
    "\n",
    "# # Create a \"super\" axis for the common Y-label and make it invisible\n",
    "# super_ax = fig.add_subplot(111, frame_on=False)\n",
    "# plt.tick_params(labelcolor=\"none\", bottom=False, left=False)\n",
    "# super_ax.set_ylabel(\"Giá trị\", fontsize=14, labelpad=15, fontdict=label_font)\n",
    "\n",
    "# # Move the super axis ylabel to avoid overlap with subplots\n",
    "# super_ax.yaxis.set_label_coords(-0.06,0.5)\n",
    "\n",
    "# # Adjust the layout so that plots do not overlap\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_for_different_shapes(arrays):\n",
    "#     \"\"\"\n",
    "#     Kiểm tra xem các mảng trong danh sách có kích thước không đồng nhất không.\n",
    "\n",
    "#     Parameters:\n",
    "#         arrays (list): Danh sách các mảng NumPy.\n",
    "\n",
    "#     Returns:\n",
    "#         list: Danh sách các mảng không đồng nhất.\n",
    "#     \"\"\"\n",
    "#     inhomogeneous_arrays = []\n",
    "#     expected_shape = None\n",
    "#     for array in arrays:\n",
    "#         if expected_shape is None:\n",
    "#             expected_shape = array.shape\n",
    "#         elif array.shape != expected_shape:\n",
    "#             inhomogeneous_arrays.append(array)\n",
    "#     return inhomogeneous_arrays\n",
    "\n",
    "# def augment_time_series_data(input_data, labels, num_augmentations=5):\n",
    "#     \"\"\"\n",
    "#     Augment time series data.\n",
    "\n",
    "#     :param input_data: Original time series data array.\n",
    "#     :param labels: Corresponding labels for the data.\n",
    "#     :param num_augmentations: Number of augmented samples to generate per original sample.\n",
    "\n",
    "#     :return: Augmented data array and corresponding labels.\n",
    "#     \"\"\"\n",
    "#     augmented_data = []\n",
    "#     augmented_labels = []\n",
    "\n",
    "#     num_samples, num_channels, sequence_length = input_data.shape\n",
    "\n",
    "#     for i in range(num_samples):\n",
    "#         for _ in range(num_augmentations):\n",
    "#             # Choose a random augmentation technique\n",
    "#             augmentation_type = random.choices(['noise', 'reverse', 'crop_pad', 'time_warp', 'random_shift'],\n",
    "#                                                weights=[0.6, 0.1, 0.1, 0.1, 0.1])[0]\n",
    "\n",
    "#             if augmentation_type == 'noise':\n",
    "#                 # Add random noise\n",
    "#                 noise = np.random.normal(0, 0.00005, input_data[i].shape)\n",
    "#                 augmented_sample = input_data[i] + noise\n",
    "\n",
    "#             elif augmentation_type == 'reverse':\n",
    "#                 # Reverse the sequence\n",
    "#                 augmented_sample = np.flip(input_data[i], axis=-1)\n",
    "\n",
    "#             elif augmentation_type == 'crop_pad':\n",
    "#                 # Crop and pad the sequence\n",
    "#                 crop_size = random.randint(1, sequence_length // 100)\n",
    "#                 padded_sample = np.pad(input_data[i], ((0, 0), (crop_size, 0)), mode='constant', constant_values=0)\n",
    "#                 augmented_sample = padded_sample[:, :-crop_size]\n",
    "\n",
    "#             elif augmentation_type == 'time_warp':\n",
    "#                 # Time warping\n",
    "#                 start_idx = random.randint(0, sequence_length // 2)\n",
    "#                 end_idx = random.randint(start_idx, sequence_length)\n",
    "#                 warped_segment = np.mean(input_data[i][:, start_idx:end_idx], axis=1, keepdims=True)\n",
    "#                 augmented_sample = np.concatenate((warped_segment, input_data[i][:, end_idx:]), axis=1)\n",
    "\n",
    "#             elif augmentation_type == 'random_shift':\n",
    "#                 # Random shifting\n",
    "#                 shift_amount = random.randint(-(sequence_length // 10), sequence_length // 10)\n",
    "#                 augmented_sample = np.roll(input_data[i], shift_amount, axis=-1)\n",
    "\n",
    "#             if augmented_sample.shape == (num_channels, sequence_length):\n",
    "#                 augmented_data.append(augmented_sample)\n",
    "#                 augmented_labels.append(labels[i])\n",
    "#             else:\n",
    "#                 print(\"Invalid shape:\", augmented_sample.shape)\n",
    "\n",
    "#     # Convert to numpy arrays\n",
    "#     # Sử dụng hàm\n",
    "#     inhomogeneous_arrays = check_for_different_shapes(augmented_data)\n",
    "#     if inhomogeneous_arrays:\n",
    "#         print(\"Các mảng không đồng nhất:\")\n",
    "#         for array in inhomogeneous_arrays:\n",
    "#             print(array.shape)\n",
    "#     else:\n",
    "#         print(\"Tất cả các mảng có kích thước giống nhau.\")\n",
    "\n",
    "#     return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "# # Sử dụng hàm\n",
    "# augmented_data, augmented_labels = augment_time_series_data(input_data, output_labels, num_augmentations=30)\n",
    "# print(augmented_data.shape, augmented_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def reshape_time_series_data_v8(input_data, label_data, segments_per_new_sample, segment_length):\n",
    "#     \"\"\"\n",
    "#     Reshape time series data and corresponding labels into a specified shape.\n",
    "\n",
    "#     :param input_data: Original time series data array.\n",
    "#     :param label_data: Corresponding labels for the data.\n",
    "#     :param segments_per_new_sample: Number of segments per new sample.\n",
    "#     :param segment_length: Length of each segment.\n",
    "\n",
    "#     :return: Reshaped data array and corresponding labels.\n",
    "#     \"\"\"\n",
    "#     num_samples_original, num_channels, length_original = input_data.shape\n",
    "\n",
    "#     # Validate the feasibility of reshaping\n",
    "#     if length_original % segment_length != 0:\n",
    "#         raise ValueError(\"Segment length must evenly divide the original length.\")\n",
    "\n",
    "#     total_segments_per_original_sample = (length_original // segment_length) * num_channels\n",
    "#     num_samples_new = (num_samples_original * total_segments_per_original_sample) // segments_per_new_sample\n",
    "\n",
    "#     # Validate if reshaping is possible\n",
    "#     if (num_samples_original * total_segments_per_original_sample) % segments_per_new_sample != 0:\n",
    "#         raise ValueError(\"Reshaping not possible with the given dimensions.\")\n",
    "\n",
    "#     # Initialize reshaped data and labels\n",
    "#     new_shape = (num_samples_new, segments_per_new_sample, segment_length)\n",
    "#     reshaped_data = np.zeros(new_shape)\n",
    "#     reshaped_labels = np.zeros(num_samples_new)\n",
    "\n",
    "#     # Reshape the data and labels\n",
    "#     count = 0\n",
    "#     for i in range(num_samples_original):\n",
    "#         segment_count = 0\n",
    "#         for j in range(num_channels):\n",
    "#             for k in range(length_original // segment_length):\n",
    "#                 start_idx = k * segment_length\n",
    "#                 end_idx = start_idx + segment_length\n",
    "#                 reshaped_data[count, segment_count % segments_per_new_sample, :] = input_data[i, j, start_idx:end_idx]\n",
    "#                 if (segment_count + 1) % segments_per_new_sample == 0:\n",
    "#                     reshaped_labels[count] = label_data[i]  # Assign corresponding label\n",
    "#                     count += 1\n",
    "#                 segment_count += 1\n",
    "\n",
    "#     return reshaped_data, reshaped_labels\n",
    "\n",
    "# # Example usage\n",
    "# segments_per_new_sample = 10\n",
    "# segment_length = 2000\n",
    "\n",
    "# # Assume 'augmented_data' and 'augmented_labels' are your input data and labels\n",
    "# reshaped_data, reshaped_labels = reshape_time_series_data_v8(augmented_data, augmented_labels, segments_per_new_sample, segment_length)\n",
    "# print(reshaped_data.shape, reshaped_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = np.load('reshaped_data.npy')\n",
    "reshaped_labels = np.load('reshaped_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(1987, 10, 2000)\n",
      "y_train's shape:(1987,)\n",
      "X_test's shape:(663, 10, 2000)\n",
      "y_test's shape:(663,)\n",
      "X_val's shape:(662, 10, 2000)\n",
      "y_val's shape:(662,)\n"
     ]
    }
   ],
   "source": [
    "input_train = reshaped_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_train, output_train, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train.shape))\n",
    "print(\"y_train's shape:\" + str(y_train.shape))\n",
    "print(\"X_test's shape:\" + str(X_test.shape))\n",
    "print(\"y_test's shape:\" + str(y_test.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "No. Labels: 10\n"
     ]
    }
   ],
   "source": [
    "label=np.unique(y_train)\n",
    "print('Label = ' + str(label))\n",
    "num_classes = len(np.unique(y_train))\n",
    "print('No. Labels: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session()\n",
    "\n",
    "# from tensorflow.keras.layers import SimpleRNN, Dense, Flatten\n",
    "    \n",
    "    \n",
    "# def build_RNN_model(input_shape, num_classes):\n",
    "#     input_tensor = Input(shape=input_shape)    \n",
    "#     x = SimpleRNN(200,return_sequences=True)(input_tensor)\n",
    "#     x = SimpleRNN(200,return_sequences=True,dropout=0.5)(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(100)(x)\n",
    "#     output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "#     model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Run the model on GPU if available\n",
    "# with tf.device('/GPU:0'):\n",
    "#     RNN_model = build_RNN_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "#     RNN_model.summary()\n",
    "\n",
    "#     # Early stopping callback\n",
    "#     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "#     # Train the model\n",
    "#     history_RNN = RNN_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 256)           512256    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 256)          1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 256)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5, 256)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 128)            98432     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 5, 128)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 5, 64)             8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 64)            256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               41088     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 663,114\n",
      "Trainable params: 662,218\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/63 [==============>...............] - ETA: 0s - loss: 1.1143 - accuracy: 0.6953"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_1DCNN_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # 1D-CNN Preprocessing Layers\n",
    "    x = Conv1D(filters=256, kernel_size=1, padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool1D()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=64, kernel_size=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Dense Layers for Classification\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_model = build_1DCNN_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    DCNN_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_1DCNN = DCNN_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session()\n",
    "\n",
    "# def build_LSTM_model(input_shape, num_classes):\n",
    "#     input_tensor = Input(shape=input_shape)    \n",
    "#     x = LSTM(200, return_sequences=True)(input_tensor)  \n",
    "#     x = LSTM(200, return_sequences=True,dropout=0.5)(x)  \n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(100)(x)\n",
    "#     output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "#     model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Run the model on GPU if available\n",
    "# with tf.device('/GPU:0'):\n",
    "#     LSTM_model = build_LSTM_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "#     LSTM_model.summary()\n",
    "\n",
    "#     # Early stopping callback\n",
    "#     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "#     # Train the model\n",
    "#     history_LSTM = LSTM_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 10, 200)           1321200   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 10, 200)           241200    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,763,510\n",
      "Trainable params: 1,763,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 5s 29ms/step - loss: 2.1447 - accuracy: 0.2159 - val_loss: 1.7898 - val_accuracy: 0.2885\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.1423 - accuracy: 0.6522 - val_loss: 1.1895 - val_accuracy: 0.6828\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6092 - accuracy: 0.8244 - val_loss: 0.8783 - val_accuracy: 0.7991\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3660 - accuracy: 0.8983 - val_loss: 0.8825 - val_accuracy: 0.8127\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.3522 - accuracy: 0.8903 - val_loss: 0.8582 - val_accuracy: 0.8338\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1777 - accuracy: 0.9456 - val_loss: 1.0819 - val_accuracy: 0.8399\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.2035 - accuracy: 0.9411 - val_loss: 0.9973 - val_accuracy: 0.8308\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1267 - accuracy: 0.9597 - val_loss: 1.2039 - val_accuracy: 0.8384\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0842 - accuracy: 0.9693 - val_loss: 1.1113 - val_accuracy: 0.8610\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0909 - accuracy: 0.9703 - val_loss: 1.2224 - val_accuracy: 0.8640\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0455 - accuracy: 0.9844 - val_loss: 1.3597 - val_accuracy: 0.8656\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 1.4931 - val_accuracy: 0.8610\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 1.5218 - val_accuracy: 0.8640\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0621 - accuracy: 0.9829 - val_loss: 1.4387 - val_accuracy: 0.8505\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0842 - accuracy: 0.9743 - val_loss: 1.3680 - val_accuracy: 0.8474\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0359 - accuracy: 0.9864 - val_loss: 1.3029 - val_accuracy: 0.8625\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 1.4127 - val_accuracy: 0.8671\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 7.6124e-04 - accuracy: 1.0000 - val_loss: 1.4801 - val_accuracy: 0.8671\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.9237e-04 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.8671\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.3413e-04 - accuracy: 1.0000 - val_loss: 1.5323 - val_accuracy: 0.8671\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.0853e-04 - accuracy: 1.0000 - val_loss: 1.5584 - val_accuracy: 0.8671\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7857e-04 - accuracy: 1.0000 - val_loss: 1.5769 - val_accuracy: 0.8671\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.3446e-04 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.8671\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.1939e-04 - accuracy: 1.0000 - val_loss: 1.6138 - val_accuracy: 0.8671\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.1186e-04 - accuracy: 1.0000 - val_loss: 1.6322 - val_accuracy: 0.8671\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.0024e-04 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.8671\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 9.6753e-05 - accuracy: 1.0000 - val_loss: 1.6637 - val_accuracy: 0.8686\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 8.2783e-05 - accuracy: 1.0000 - val_loss: 1.6797 - val_accuracy: 0.8686\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 7.0411e-05 - accuracy: 1.0000 - val_loss: 1.6940 - val_accuracy: 0.8686\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 6.1757e-05 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.8686\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.5709e-05 - accuracy: 1.0000 - val_loss: 1.7188 - val_accuracy: 0.8686\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.4873e-05 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.8701\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.2766e-05 - accuracy: 1.0000 - val_loss: 1.7466 - val_accuracy: 0.8686\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 4.9282e-05 - accuracy: 1.0000 - val_loss: 1.7602 - val_accuracy: 0.8686\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 4.3884e-05 - accuracy: 1.0000 - val_loss: 1.7693 - val_accuracy: 0.8686\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.6419e-05 - accuracy: 1.0000 - val_loss: 1.7816 - val_accuracy: 0.8686\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.6453e-05 - accuracy: 1.0000 - val_loss: 1.7935 - val_accuracy: 0.8686\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.4157e-05 - accuracy: 1.0000 - val_loss: 1.8032 - val_accuracy: 0.8686\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.1781e-05 - accuracy: 1.0000 - val_loss: 1.8133 - val_accuracy: 0.8686\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.8592e-05 - accuracy: 1.0000 - val_loss: 1.8292 - val_accuracy: 0.8686\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.7487e-05 - accuracy: 1.0000 - val_loss: 1.8396 - val_accuracy: 0.8686\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.6795e-05 - accuracy: 1.0000 - val_loss: 1.8485 - val_accuracy: 0.8686\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.3542e-05 - accuracy: 1.0000 - val_loss: 1.8571 - val_accuracy: 0.8686\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.1215e-05 - accuracy: 1.0000 - val_loss: 1.8645 - val_accuracy: 0.8686\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.3080e-05 - accuracy: 1.0000 - val_loss: 1.8735 - val_accuracy: 0.8686\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.0034e-05 - accuracy: 1.0000 - val_loss: 1.8813 - val_accuracy: 0.8686\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8461e-05 - accuracy: 1.0000 - val_loss: 1.8893 - val_accuracy: 0.8686\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.5713e-05 - accuracy: 1.0000 - val_loss: 1.8967 - val_accuracy: 0.8701\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7046e-05 - accuracy: 1.0000 - val_loss: 1.9062 - val_accuracy: 0.8686\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7566e-05 - accuracy: 1.0000 - val_loss: 1.9163 - val_accuracy: 0.8686\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.3839e-05 - accuracy: 1.0000 - val_loss: 1.9261 - val_accuracy: 0.8686\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.3038e-05 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.8686\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.2244e-05 - accuracy: 1.0000 - val_loss: 1.9419 - val_accuracy: 0.8686\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.1271e-05 - accuracy: 1.0000 - val_loss: 1.9498 - val_accuracy: 0.8686\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.0567e-05 - accuracy: 1.0000 - val_loss: 1.9568 - val_accuracy: 0.8686\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.0254e-05 - accuracy: 1.0000 - val_loss: 1.9633 - val_accuracy: 0.8701\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.0418e-05 - accuracy: 1.0000 - val_loss: 1.9704 - val_accuracy: 0.8701\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.0556e-05 - accuracy: 1.0000 - val_loss: 1.9785 - val_accuracy: 0.8701\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 9.5310e-06 - accuracy: 1.0000 - val_loss: 1.9865 - val_accuracy: 0.8701\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 9.5318e-06 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.8686\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 8.7678e-06 - accuracy: 1.0000 - val_loss: 2.0005 - val_accuracy: 0.8686\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 7.8588e-06 - accuracy: 1.0000 - val_loss: 2.0067 - val_accuracy: 0.8701\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 8.4322e-06 - accuracy: 1.0000 - val_loss: 2.0180 - val_accuracy: 0.8686\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 7.2980e-06 - accuracy: 1.0000 - val_loss: 2.0259 - val_accuracy: 0.8701\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 7.2783e-06 - accuracy: 1.0000 - val_loss: 2.0325 - val_accuracy: 0.8701\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 7.5010e-06 - accuracy: 1.0000 - val_loss: 2.0385 - val_accuracy: 0.8701\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 6.2199e-06 - accuracy: 1.0000 - val_loss: 2.0477 - val_accuracy: 0.8701\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 6.1808e-06 - accuracy: 1.0000 - val_loss: 2.0543 - val_accuracy: 0.8701\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 7.2885e-06 - accuracy: 1.0000 - val_loss: 2.0638 - val_accuracy: 0.8701\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.3446e-06 - accuracy: 1.0000 - val_loss: 2.0693 - val_accuracy: 0.8701\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 6.4879e-06 - accuracy: 1.0000 - val_loss: 2.0789 - val_accuracy: 0.8701\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 5.2065e-06 - accuracy: 1.0000 - val_loss: 2.0849 - val_accuracy: 0.8701\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.7086e-06 - accuracy: 1.0000 - val_loss: 2.0921 - val_accuracy: 0.8701\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.1205e-06 - accuracy: 1.0000 - val_loss: 2.0986 - val_accuracy: 0.8701\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 4.5203e-06 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.8701\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.2086e-06 - accuracy: 1.0000 - val_loss: 2.1089 - val_accuracy: 0.8701\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.2069e-06 - accuracy: 1.0000 - val_loss: 2.1162 - val_accuracy: 0.8701\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.6335e-06 - accuracy: 1.0000 - val_loss: 2.1227 - val_accuracy: 0.8701\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 4.0055e-06 - accuracy: 1.0000 - val_loss: 2.1294 - val_accuracy: 0.8701\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.2991e-06 - accuracy: 1.0000 - val_loss: 2.1350 - val_accuracy: 0.8701\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.0164e-06 - accuracy: 1.0000 - val_loss: 2.1417 - val_accuracy: 0.8701\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.4789e-06 - accuracy: 1.0000 - val_loss: 2.1486 - val_accuracy: 0.8701\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.1296e-06 - accuracy: 1.0000 - val_loss: 2.1554 - val_accuracy: 0.8701\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.6862e-06 - accuracy: 1.0000 - val_loss: 2.1612 - val_accuracy: 0.8701\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.9951e-06 - accuracy: 1.0000 - val_loss: 2.1674 - val_accuracy: 0.8701\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.5233e-06 - accuracy: 1.0000 - val_loss: 2.1734 - val_accuracy: 0.8701\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.5912e-06 - accuracy: 1.0000 - val_loss: 2.1790 - val_accuracy: 0.8701\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.2143e-06 - accuracy: 1.0000 - val_loss: 2.1853 - val_accuracy: 0.8701\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.3984e-06 - accuracy: 1.0000 - val_loss: 2.1910 - val_accuracy: 0.8701\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.3467e-06 - accuracy: 1.0000 - val_loss: 2.1975 - val_accuracy: 0.8701\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.0176e-06 - accuracy: 1.0000 - val_loss: 2.2032 - val_accuracy: 0.8701\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.1689e-06 - accuracy: 1.0000 - val_loss: 2.2099 - val_accuracy: 0.8701\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8914e-06 - accuracy: 1.0000 - val_loss: 2.2161 - val_accuracy: 0.8701\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 2.3169e-06 - accuracy: 1.0000 - val_loss: 2.2218 - val_accuracy: 0.8686\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9225e-06 - accuracy: 1.0000 - val_loss: 2.2290 - val_accuracy: 0.8686\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.6333e-06 - accuracy: 1.0000 - val_loss: 2.2339 - val_accuracy: 0.8686\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.6451e-06 - accuracy: 1.0000 - val_loss: 2.2396 - val_accuracy: 0.8686\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5754e-06 - accuracy: 1.0000 - val_loss: 2.2449 - val_accuracy: 0.8686\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5741e-06 - accuracy: 1.0000 - val_loss: 2.2510 - val_accuracy: 0.8686\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5546e-06 - accuracy: 1.0000 - val_loss: 2.2585 - val_accuracy: 0.8686\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = GRU(200, return_sequences=True)(input_tensor)   \n",
    "    x = GRU(200, return_sequences=True,dropout=0.5)(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    GRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    GRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_GRU = GRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 10, 400)          2642400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 10, 400)          722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               400100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,765,910\n",
      "Trainable params: 3,765,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 8s 46ms/step - loss: 2.0213 - accuracy: 0.2813 - val_loss: 1.4027 - val_accuracy: 0.5438\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8958 - accuracy: 0.7358 - val_loss: 0.8488 - val_accuracy: 0.7764\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.4882 - accuracy: 0.8571 - val_loss: 0.7699 - val_accuracy: 0.8066\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.2619 - accuracy: 0.9200 - val_loss: 0.8484 - val_accuracy: 0.8172\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.2029 - accuracy: 0.9371 - val_loss: 0.7944 - val_accuracy: 0.8520\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0925 - accuracy: 0.9728 - val_loss: 0.8380 - val_accuracy: 0.8550\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.1337 - accuracy: 0.9562 - val_loss: 0.9921 - val_accuracy: 0.8535\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 1.0850 - val_accuracy: 0.8535\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0559 - accuracy: 0.9809 - val_loss: 1.4463 - val_accuracy: 0.8308\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0907 - accuracy: 0.9708 - val_loss: 0.9788 - val_accuracy: 0.8535\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.9972 - val_accuracy: 0.8625\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 1.0461 - val_accuracy: 0.8595\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.0899 - val_accuracy: 0.8580\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.1470 - val_accuracy: 0.8595\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.7927e-04 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 0.8610\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8088e-04 - accuracy: 1.0000 - val_loss: 1.1660 - val_accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3503e-04 - accuracy: 1.0000 - val_loss: 1.1730 - val_accuracy: 0.8610\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1409e-04 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.8610\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0027e-04 - accuracy: 1.0000 - val_loss: 1.1857 - val_accuracy: 0.8610\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 9.4593e-05 - accuracy: 1.0000 - val_loss: 1.1940 - val_accuracy: 0.8610\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.8575e-05 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.1784e-05 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.8610\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.4233e-05 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.8610\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.7939e-05 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.3520e-05 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.2372e-05 - accuracy: 1.0000 - val_loss: 1.2356 - val_accuracy: 0.8610\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.6616e-05 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.4018e-05 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.8610\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.0195e-05 - accuracy: 1.0000 - val_loss: 1.2557 - val_accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.5358e-05 - accuracy: 1.0000 - val_loss: 1.2627 - val_accuracy: 0.8595\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.3757e-05 - accuracy: 1.0000 - val_loss: 1.2693 - val_accuracy: 0.8595\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.1741e-05 - accuracy: 1.0000 - val_loss: 1.2749 - val_accuracy: 0.8595\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.8531e-05 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.8595\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.6609e-05 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.8595\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.6050e-05 - accuracy: 1.0000 - val_loss: 1.2936 - val_accuracy: 0.8595\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.2870e-05 - accuracy: 1.0000 - val_loss: 1.2986 - val_accuracy: 0.8595\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 2.5620e-05 - accuracy: 1.0000 - val_loss: 1.3058 - val_accuracy: 0.8595\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.0982e-05 - accuracy: 1.0000 - val_loss: 1.3103 - val_accuracy: 0.8610\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.1225e-05 - accuracy: 1.0000 - val_loss: 1.3162 - val_accuracy: 0.8595\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.7404e-05 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.8595\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.7192e-05 - accuracy: 1.0000 - val_loss: 1.3259 - val_accuracy: 0.8595\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8154e-05 - accuracy: 1.0000 - val_loss: 1.3320 - val_accuracy: 0.8595\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.6078e-05 - accuracy: 1.0000 - val_loss: 1.3373 - val_accuracy: 0.8595\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4585e-05 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 0.8595\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4204e-05 - accuracy: 1.0000 - val_loss: 1.3485 - val_accuracy: 0.8595\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 1.4048e-05 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.8610\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2665e-05 - accuracy: 1.0000 - val_loss: 1.3572 - val_accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 1.2521e-05 - accuracy: 1.0000 - val_loss: 1.3626 - val_accuracy: 0.8610\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1182e-05 - accuracy: 1.0000 - val_loss: 1.3673 - val_accuracy: 0.8610\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 1.0697e-05 - accuracy: 1.0000 - val_loss: 1.3726 - val_accuracy: 0.8625\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 9.5538e-06 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.8625\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 9.5885e-06 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.8625\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 9.1173e-06 - accuracy: 1.0000 - val_loss: 1.3875 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 8.6273e-06 - accuracy: 1.0000 - val_loss: 1.3919 - val_accuracy: 0.8625\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 8.1184e-06 - accuracy: 1.0000 - val_loss: 1.3975 - val_accuracy: 0.8625\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.8612e-06 - accuracy: 1.0000 - val_loss: 1.4018 - val_accuracy: 0.8625\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.5280e-06 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.8625\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.0250e-06 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.8625\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 7.0720e-06 - accuracy: 1.0000 - val_loss: 1.4158 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 7.1335e-06 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.8625\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.8082e-06 - accuracy: 1.0000 - val_loss: 1.4254 - val_accuracy: 0.8625\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 5.7035e-06 - accuracy: 1.0000 - val_loss: 1.4290 - val_accuracy: 0.8625\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.5120e-06 - accuracy: 1.0000 - val_loss: 1.4332 - val_accuracy: 0.8625\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 5.7662e-06 - accuracy: 1.0000 - val_loss: 1.4380 - val_accuracy: 0.8625\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.9402e-06 - accuracy: 1.0000 - val_loss: 1.4423 - val_accuracy: 0.8625\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.8195e-06 - accuracy: 1.0000 - val_loss: 1.4466 - val_accuracy: 0.8625\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.4855e-06 - accuracy: 1.0000 - val_loss: 1.4511 - val_accuracy: 0.8625\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.6639e-06 - accuracy: 1.0000 - val_loss: 1.4555 - val_accuracy: 0.8625\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 4.0842e-06 - accuracy: 1.0000 - val_loss: 1.4599 - val_accuracy: 0.8625\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 4.1347e-06 - accuracy: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.8625\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 4.0521e-06 - accuracy: 1.0000 - val_loss: 1.4696 - val_accuracy: 0.8625\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.5017e-06 - accuracy: 1.0000 - val_loss: 1.4735 - val_accuracy: 0.8625\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.9141e-06 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.8625\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.5491e-06 - accuracy: 1.0000 - val_loss: 1.4820 - val_accuracy: 0.8625\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.3500e-06 - accuracy: 1.0000 - val_loss: 1.4870 - val_accuracy: 0.8625\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 3.1288e-06 - accuracy: 1.0000 - val_loss: 1.4914 - val_accuracy: 0.8610\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.9683e-06 - accuracy: 1.0000 - val_loss: 1.4957 - val_accuracy: 0.8610\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.8872e-06 - accuracy: 1.0000 - val_loss: 1.4994 - val_accuracy: 0.8625\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.8700e-06 - accuracy: 1.0000 - val_loss: 1.5042 - val_accuracy: 0.8610\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.6851e-06 - accuracy: 1.0000 - val_loss: 1.5096 - val_accuracy: 0.8610\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.5342e-06 - accuracy: 1.0000 - val_loss: 1.5135 - val_accuracy: 0.8610\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.3259e-06 - accuracy: 1.0000 - val_loss: 1.5175 - val_accuracy: 0.8610\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.3417e-06 - accuracy: 1.0000 - val_loss: 1.5222 - val_accuracy: 0.8610\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 2.4163e-06 - accuracy: 1.0000 - val_loss: 1.5259 - val_accuracy: 0.8610\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.2161e-06 - accuracy: 1.0000 - val_loss: 1.5319 - val_accuracy: 0.8610\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.9117e-06 - accuracy: 1.0000 - val_loss: 1.5355 - val_accuracy: 0.8610\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.0320e-06 - accuracy: 1.0000 - val_loss: 1.5400 - val_accuracy: 0.8610\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8816e-06 - accuracy: 1.0000 - val_loss: 1.5435 - val_accuracy: 0.8610\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.9011e-06 - accuracy: 1.0000 - val_loss: 1.5479 - val_accuracy: 0.8610\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.7980e-06 - accuracy: 1.0000 - val_loss: 1.5517 - val_accuracy: 0.8610\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.6427e-06 - accuracy: 1.0000 - val_loss: 1.5560 - val_accuracy: 0.8610\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.6565e-06 - accuracy: 1.0000 - val_loss: 1.5604 - val_accuracy: 0.8610\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 1.6802e-06 - accuracy: 1.0000 - val_loss: 1.5654 - val_accuracy: 0.8610\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4633e-06 - accuracy: 1.0000 - val_loss: 1.5690 - val_accuracy: 0.8610\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.4235e-06 - accuracy: 1.0000 - val_loss: 1.5742 - val_accuracy: 0.8610\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3238e-06 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.8610\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3251e-06 - accuracy: 1.0000 - val_loss: 1.5821 - val_accuracy: 0.8610\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2416e-06 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.8610\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.2485e-06 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.8595\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.0490e-06 - accuracy: 1.0000 - val_loss: 1.5950 - val_accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(input_tensor)   \n",
    "    x = Bidirectional(GRU(200, return_sequences=True,dropout=0.5))(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    BiGRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_BiGRU = BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN-biGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 128)           768128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,035,478\n",
      "Trainable params: 2,035,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 9s 46ms/step - loss: 2.0593 - accuracy: 0.2240 - val_loss: 1.5219 - val_accuracy: 0.4637\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.0111 - accuracy: 0.6392 - val_loss: 1.2536 - val_accuracy: 0.6526\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.5047 - accuracy: 0.8284 - val_loss: 0.7003 - val_accuracy: 0.7885\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.3070 - accuracy: 0.8953 - val_loss: 0.6171 - val_accuracy: 0.8278\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.1770 - accuracy: 0.9396 - val_loss: 0.6165 - val_accuracy: 0.8489\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0926 - accuracy: 0.9703 - val_loss: 0.7174 - val_accuracy: 0.8489\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.2701 - accuracy: 0.9230 - val_loss: 0.5761 - val_accuracy: 0.8610\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0992 - accuracy: 0.9733 - val_loss: 0.6833 - val_accuracy: 0.8444\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0837 - accuracy: 0.9708 - val_loss: 0.6025 - val_accuracy: 0.8686\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0445 - accuracy: 0.9849 - val_loss: 0.6640 - val_accuracy: 0.8701\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0585 - accuracy: 0.9809 - val_loss: 0.6434 - val_accuracy: 0.8776\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0922 - accuracy: 0.9718 - val_loss: 0.5621 - val_accuracy: 0.8746\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0443 - accuracy: 0.9879 - val_loss: 0.6610 - val_accuracy: 0.8686\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.6356 - val_accuracy: 0.8837\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.7553 - val_accuracy: 0.8731\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0976 - accuracy: 0.9799 - val_loss: 0.8580 - val_accuracy: 0.8066\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0988 - accuracy: 0.9678 - val_loss: 0.5412 - val_accuracy: 0.8837\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.5967 - val_accuracy: 0.8761\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.7381 - val_accuracy: 0.8807\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0049 - accuracy: 0.9975 - val_loss: 0.6899 - val_accuracy: 0.8792\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.6568 - val_accuracy: 0.8882\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.6969 - val_accuracy: 0.8807\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.8457 - val_accuracy: 0.8746\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.1148 - accuracy: 0.9748 - val_loss: 0.6722 - val_accuracy: 0.8746\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.7939 - val_accuracy: 0.8701\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0555 - accuracy: 0.9849 - val_loss: 0.7601 - val_accuracy: 0.8671\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.8179 - val_accuracy: 0.8535\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0842 - accuracy: 0.9708 - val_loss: 0.6590 - val_accuracy: 0.8625\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.6268 - val_accuracy: 0.8792\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.6716 - val_accuracy: 0.8716\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.6537 - val_accuracy: 0.8897\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.6740 - val_accuracy: 0.8776\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.6244e-04 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.9049e-04 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.8867\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8979e-04 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8867\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.2300e-04 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8867\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.3355e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8837\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3018e-04 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8837\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5359e-04 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8837\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 8.6974e-05 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8837\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.5511e-05 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8837\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.4579e-05 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8852\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.2274e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8852\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.6325e-05 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8837\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.4973e-05 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.8837\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.4554e-05 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8852\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.9761e-05 - accuracy: 1.0000 - val_loss: 0.7300 - val_accuracy: 0.8852\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.9229e-05 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.8837\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.0542e-05 - accuracy: 1.0000 - val_loss: 0.7377 - val_accuracy: 0.8837\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.5260e-05 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8837\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.3363e-05 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.8822\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.9200e-05 - accuracy: 1.0000 - val_loss: 0.7412 - val_accuracy: 0.8822\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.7941e-05 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8837\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.9592e-05 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.8837\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.2048e-05 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8837\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.9245e-05 - accuracy: 1.0000 - val_loss: 0.7648 - val_accuracy: 0.8837\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.1641e-05 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.8837\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.8537e-05 - accuracy: 1.0000 - val_loss: 0.7708 - val_accuracy: 0.8837\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8123e-05 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.8837\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.4720e-05 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.8837\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.2678e-05 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.8837\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.2934e-05 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.8837\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.9606e-05 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.8837\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.1443e-05 - accuracy: 1.0000 - val_loss: 0.7875 - val_accuracy: 0.8837\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.6224e-05 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.8837\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.9158e-05 - accuracy: 1.0000 - val_loss: 0.7920 - val_accuracy: 0.8837\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.3323e-05 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8852\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.2523e-05 - accuracy: 1.0000 - val_loss: 0.7894 - val_accuracy: 0.8852\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.2393e-05 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.8852\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.3050e-05 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.8852\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.4461e-05 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.8852\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5636e-05 - accuracy: 1.0000 - val_loss: 0.8262 - val_accuracy: 0.8837\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 2.0132e-05 - accuracy: 1.0000 - val_loss: 0.8269 - val_accuracy: 0.8822\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5726e-05 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.8837\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.8835e-05 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.8852\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.9405e-06 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.8852\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.9889e-06 - accuracy: 1.0000 - val_loss: 0.8267 - val_accuracy: 0.8852\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 8.6821e-06 - accuracy: 1.0000 - val_loss: 0.8315 - val_accuracy: 0.8837\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.1888e-05 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.8822\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 9.3101e-06 - accuracy: 1.0000 - val_loss: 0.8397 - val_accuracy: 0.8837\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 8.0483e-06 - accuracy: 1.0000 - val_loss: 0.8420 - val_accuracy: 0.8837\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 8.0207e-06 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.8837\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.2092e-06 - accuracy: 1.0000 - val_loss: 0.8468 - val_accuracy: 0.8822\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 6.3067e-06 - accuracy: 1.0000 - val_loss: 0.8511 - val_accuracy: 0.8822\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.1408e-06 - accuracy: 1.0000 - val_loss: 0.8559 - val_accuracy: 0.8822\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.5048e-06 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.8807\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 7.1549e-06 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.8807\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.0856e-06 - accuracy: 1.0000 - val_loss: 0.8622 - val_accuracy: 0.8807\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.3239e-06 - accuracy: 1.0000 - val_loss: 0.8622 - val_accuracy: 0.8822\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 6.4303e-06 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.8822\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.5522e-06 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.8867\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.9088e-06 - accuracy: 1.0000 - val_loss: 0.8516 - val_accuracy: 0.8852\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.7661e-06 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.8852\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.0461e-06 - accuracy: 1.0000 - val_loss: 0.8606 - val_accuracy: 0.8837\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 5.1472e-06 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.8822\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.6654e-06 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.8822\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.4833e-06 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.8822\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 3.2174e-06 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.8822\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.1253e-06 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.8822\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 4.9683e-06 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_CNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_BiGRU_model = build_CNN_BiGRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_DCNN_BiGRU = DCNN_BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reshaped_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_2d \u001b[38;5;241m=\u001b[39m \u001b[43mreshaped_data\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, reshaped_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# (1000 * 10, 2000)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Áp dụng PCA để giảm số timesteps từ 2000 xuống 500\u001b[39;00m\n\u001b[0;32m      4\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reshaped_data' is not defined"
     ]
    }
   ],
   "source": [
    "X_2d = reshaped_data.reshape(-1, reshaped_data.shape[2])  # (1000 * 10, 2000)\n",
    "\n",
    "# Áp dụng PCA để giảm số timesteps từ 2000 xuống 500\n",
    "n_components = 1000\n",
    "pca = PCA(n_components=n_components)\n",
    "X_2d_reduced = pca.fit_transform(X_2d)  # (1000 * 10, 500)\n",
    "\n",
    "# Chuyển lại thành dạng 3D\n",
    "X_reduced = X_2d_reduced.reshape(reshaped_data.shape[0], reshaped_data.shape[1], n_components)  # (1000, 10, 500)\n",
    "print(\"Kích thước dữ liệu sau PCA:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_PCA_1DCNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    PCA_DCNN_BiGRU_model = build_PCA_1DCNN_BiGRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    PCA_DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_PCA_DCNN_BiGRU = PCA_DCNN_BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.9139\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.2585 - accuracy: 0.8686\n",
      "21/21 [==============================] - 1s 12ms/step - loss: 1.5950 - accuracy: 0.8610\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8807 - accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "DCNN_valid_loss, DCNN_valid_acc = DCNN_model.evaluate(X_valid, y_valid)\n",
    "GRU_valid_loss, GRU_valid_acc = GRU_model.evaluate(X_valid, y_valid)\n",
    "biGRU_valid_loss, biGRU_valid_acc = BiGRU_model.evaluate(X_valid, y_valid)\n",
    "DCNN_biGRU_valid_loss, DCNN_biGRU_valid_acc = DCNN_BiGRU_model.evaluate(X_valid, y_valid)\n",
    "PCA_DCNN_biGRU_valid_loss, PCA_DCNN_biGRU_valid_acc = PCA_DCNN_BiGRU_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['1DCNN','GRU', 'biGRU', '1DCNN_biGRU', 'PCA_1DCNN_biGRU']\n",
    "# val_accuracy = [RNN_valid_loss, DCNN_valid_loss, LSTM_valid_loss, GRU_valid_loss, biGRU_valid_loss, DCNN_biGRU_valid_loss]\n",
    "# val_loss = [RNN_valid_acc, DCNN_valid_acc, LSTM_valid_acc, GRU_valid_acc, biGRU_valid_acc, DCNN_biGRU_valid_acc ]\n",
    "\n",
    "val_accuracy = [DCNN_valid_loss, GRU_valid_loss, biGRU_valid_loss, DCNN_biGRU_valid_loss, PCA_DCNN_biGRU_valid_loss]\n",
    "val_loss = [DCNN_valid_acc, GRU_valid_acc, biGRU_valid_acc, DCNN_biGRU_valid_acc, PCA_DCNN_biGRU_valid_acc]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Bar settings\n",
    "bar_width = 0.22\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create the plot with a scientific style\n",
    "# plt.style.use('classic')\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "\n",
    "# Plot the data with zorder=3 to make sure bars are in front of grid lines\n",
    "bar1 = ax.bar(index, val_accuracy, bar_width, label='Loss', zorder=3, color='skyblue', edgecolor='black')\n",
    "bar2 = ax.bar(index + bar_width, val_loss, bar_width, label='acuracy', zorder=3, color='steelblue', edgecolor='black')\n",
    "\n",
    "# Calculate the max height for a bar to determine text placement\n",
    "max_height = max(max(val_accuracy), max(val_loss))\n",
    "\n",
    "# Define a larger offset to move text above the top of the bars\n",
    "text_offset = max_height * 0.001  # Adjust this factor as needed\n",
    "\n",
    "# Add text above the bars\n",
    "for i, rect in enumerate(bar1):\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2.0, rect.get_height(), f'{val_accuracy[i]:.3f}', ha='center', va='bottom')\n",
    "\n",
    "for i, rect in enumerate(bar2):\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2.0, rect.get_height(), f'{val_loss[i]:.3f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_ylim(0, max_height + max_height * 0.1)  # Add 10% headroom above the tallest bar for text\n",
    "\n",
    "# Annotate the plot\n",
    "ax.set_title('Model Comparison for Validation Metrics', fontsize=16, loc='center', y=1.1)\n",
    "ax.set_xlabel('Models', fontsize=14)\n",
    "ax.set_ylabel('Metrics', fontsize=14)\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(models)\n",
    "\n",
    "# Place the legend above the chart\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=2, fontsize=12)\n",
    "\n",
    "# Add grid lines behind the bars by setting zorder=0\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, color='gray', zorder=0)\n",
    "\n",
    "# plt.savefig(os.path.join(figure_path, 'bar valid bi.png'))\n",
    "# print(\"Plot saved to '{}'.\".format(os.path.join(figure_path, 'bar valid bi.png')))\n",
    "\n",
    "# Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN_acc = history_RNN.history['accuracy']\n",
    "# RNN_val = history_RNN.history['val_accuracy']\n",
    "# plt.figure()\n",
    "# plt.plot(history_RNN.history['accuracy'], label='Training')\n",
    "# plt.plot(history_RNN.history['val_accuracy'], label='Validation')\n",
    "# plt.title(\"Plot Accuracy Training and Validation set\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# display(HTML('<hr>'))\n",
    "# print(\"--------------Test set----------------\")\n",
    "# # check test set\n",
    "# y_pred = RNN_model.predict(X_test,verbose = 0)\n",
    "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "# cm = confusion_matrix(y_test, y_pred_bool)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# disp.plot(cmap=plt.cm.Oranges)\n",
    "# plt.xlabel('Nhãn dự đoán')\n",
    "# plt.ylabel('Nhãn thực')\n",
    "# plt.title('Ma trận dự đoán trên tập kiểm tra')\n",
    "# plt.show()\n",
    "# report = classification_report(y_test, y_pred_bool,labels=label, output_dict=True)\n",
    "# df_report = pd.DataFrame(report).transpose()\n",
    "# display(df_report.round(3))\n",
    "\n",
    "# display(HTML('<hr>'))\n",
    "\n",
    "\n",
    "# print(\"--------------validate----------------\")\n",
    "# # check validate set\n",
    "# y_pred = RNN_model.predict(X_valid, verbose=0)\n",
    "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "# cm = confusion_matrix(y_valid, y_pred_bool)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm)  \n",
    "# disp.plot(cmap=plt.cm.Oranges)\n",
    "# plt.xlabel('Nhãn dự đoán')\n",
    "# plt.ylabel('Nhãn thực')\n",
    "# plt.title('Ma trận dự đoán trên tập kiểm thử')\n",
    "# plt.show()\n",
    "# report = classification_report(y_valid, y_pred_bool, labels=label, output_dict=True)\n",
    "# df_report = pd.DataFrame(report).transpose()\n",
    "# display(df_report.round(3))\n",
    "\n",
    "# display(HTML('<hr>'))\n",
    "# # check train set\n",
    "# print(\"----------------train----------------\")\n",
    "# y_pred = RNN_model.predict(X_train,verbose = 0)\n",
    "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "# cm = confusion_matrix(y_train, y_pred_bool)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# disp.plot(cmap=plt.cm.Oranges)\n",
    "# plt.xlabel('Nhãn dự đoán')\n",
    "# plt.ylabel('Nhãn thực')\n",
    "# plt.title('Ma trận dự đoán trên tập huấn luyện')\n",
    "# plt.show()\n",
    "# report = classification_report(y_train, y_pred_bool,labels=label, output_dict=True)\n",
    "# df_report = pd.DataFrame(report).transpose()\n",
    "# display(df_report.round(3))\n",
    "\n",
    "# # Final result\n",
    "# test_loss_RNN, test_acc_RNN = RNN_model.evaluate(X_test, y_test)\n",
    "# print('Final model has loss of test set is: {} and accuracy is: {}'.format(test_loss_RNN,test_acc_RNN))\n",
    "# val_loss_RNN, val_acc_RNN = RNN_model.evaluate(X_valid, y_valid)\n",
    "# print('Final model has loss of validation set is: {} and accuracy is: {}'.format(val_loss_RNN,val_acc_RNN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StellarGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
