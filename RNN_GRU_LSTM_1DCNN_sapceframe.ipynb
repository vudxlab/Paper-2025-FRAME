{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pickle\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, add, LSTM, Dense, Dropout,GRU, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'Data'\n",
    "\n",
    "# all_data = {}\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.mat'):\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "        \n",
    "#         # Load the .mat file and add its contents to the dictionary\n",
    "#         mat_data = loadmat(filepath)\n",
    "        \n",
    "#         # Use filename (without extension) as key for the data\n",
    "#         key = os.path.splitext(filename)[0]\n",
    "#         row_means = np.mean(mat_data['acceleration'],1)\n",
    "#         rows_2_keep = row_means != 0\n",
    "#         all_data[key] = mat_data['acceleration'][rows_2_keep]\n",
    "        \n",
    "# keys_to_stack = [f'spaceframe{i}' for i in range(1,11)]\n",
    "# input_data = np.stack([all_data[key] for key in keys_to_stack], axis=0)\n",
    "\n",
    "# # Create the corresponding labels\n",
    "# output_labels = np.linspace(0,10,11)  # Using 0 and 1 as class labels for binary cross-entropy\n",
    "# label = output_labels\n",
    "\n",
    "# input_data = input_data[:,:,:15000]\n",
    "# input_data.shape, output_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the data at index (1, 1, :) which has a shape of (8000,)\n",
    "# Data = input_data[1,:, :]\n",
    "# print(Data.shape)\n",
    "# # Create the plot\n",
    "# fig, axes = plt.subplots(12, 1, figsize=(15, 8), sharex=True)\n",
    "\n",
    "# title_font = {'family': 'Times New Roman', 'size': 16, 'weight': 'bold'}\n",
    "# label_font = {'family': 'Times New Roman', 'size': 14}\n",
    "# plt.rcParams['xtick.labelsize'] = 10\n",
    "# plt.rcParams['ytick.labelsize'] = 10\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# # Plot the data for each sub-array\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.plot(Data[i, :], linewidth=1, color = 'b')\n",
    "#     # ax.set_title(f'Z24 Signal Data at Index (1, {i}, :)', fontsize=12)\n",
    "    \n",
    "#     ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     ax.minorticks_on()\n",
    "#     ax.grid(True, which='minor', color='#999999', linestyle='--', alpha=0.2)\n",
    "#     ax.set_xlim(-100, Data.shape[1]+100)\n",
    "# # Set common labels using axes\n",
    "# axes[-1].set_xlabel('Điểm dữ liệu', fontsize=14, fontdict=label_font)\n",
    "# axes[0].set_title('Dữ liệu Khung không gian', fontsize=16, fontdict=title_font)\n",
    "\n",
    "# # Create a \"super\" axis for the common Y-label and make it invisible\n",
    "# super_ax = fig.add_subplot(111, frame_on=False)\n",
    "# plt.tick_params(labelcolor=\"none\", bottom=False, left=False)\n",
    "# super_ax.set_ylabel(\"Giá trị\", fontsize=14, labelpad=15, fontdict=label_font)\n",
    "\n",
    "# # Move the super axis ylabel to avoid overlap with subplots\n",
    "# super_ax.yaxis.set_label_coords(-0.06,0.5)\n",
    "\n",
    "# # Adjust the layout so that plots do not overlap\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_for_different_shapes(arrays):\n",
    "#     \"\"\"\n",
    "#     Kiểm tra xem các mảng trong danh sách có kích thước không đồng nhất không.\n",
    "\n",
    "#     Parameters:\n",
    "#         arrays (list): Danh sách các mảng NumPy.\n",
    "\n",
    "#     Returns:\n",
    "#         list: Danh sách các mảng không đồng nhất.\n",
    "#     \"\"\"\n",
    "#     inhomogeneous_arrays = []\n",
    "#     expected_shape = None\n",
    "#     for array in arrays:\n",
    "#         if expected_shape is None:\n",
    "#             expected_shape = array.shape\n",
    "#         elif array.shape != expected_shape:\n",
    "#             inhomogeneous_arrays.append(array)\n",
    "#     return inhomogeneous_arrays\n",
    "\n",
    "# def augment_time_series_data(input_data, labels, num_augmentations=5):\n",
    "#     \"\"\"\n",
    "#     Augment time series data.\n",
    "\n",
    "#     :param input_data: Original time series data array.\n",
    "#     :param labels: Corresponding labels for the data.\n",
    "#     :param num_augmentations: Number of augmented samples to generate per original sample.\n",
    "\n",
    "#     :return: Augmented data array and corresponding labels.\n",
    "#     \"\"\"\n",
    "#     augmented_data = []\n",
    "#     augmented_labels = []\n",
    "\n",
    "#     num_samples, num_channels, sequence_length = input_data.shape\n",
    "\n",
    "#     for i in range(num_samples):\n",
    "#         for _ in range(num_augmentations):\n",
    "#             # Choose a random augmentation technique\n",
    "#             augmentation_type = random.choices(['noise', 'reverse', 'crop_pad', 'time_warp', 'random_shift'],\n",
    "#                                                weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n",
    "\n",
    "#             if augmentation_type == 'noise':\n",
    "#                 # Add random noise\n",
    "#                 noise = np.random.normal(0, 0.00005, input_data[i].shape)\n",
    "#                 augmented_sample = input_data[i] + noise\n",
    "\n",
    "#             elif augmentation_type == 'reverse':\n",
    "#                 # Reverse the sequence\n",
    "#                 augmented_sample = np.flip(input_data[i], axis=-1)\n",
    "\n",
    "#             elif augmentation_type == 'crop_pad':\n",
    "#                 # Crop and pad the sequence\n",
    "#                 crop_size = random.randint(1, sequence_length // 100)\n",
    "#                 padded_sample = np.pad(input_data[i], ((0, 0), (crop_size, 0)), mode='constant', constant_values=0)\n",
    "#                 augmented_sample = padded_sample[:, :-crop_size]\n",
    "\n",
    "#             elif augmentation_type == 'time_warp':\n",
    "#                 # Time warping\n",
    "#                 start_idx = random.randint(0, sequence_length // 2)\n",
    "#                 end_idx = random.randint(start_idx, sequence_length)\n",
    "#                 warped_segment = np.mean(input_data[i][:, start_idx:end_idx], axis=1, keepdims=True)\n",
    "#                 augmented_sample = np.concatenate((warped_segment, input_data[i][:, end_idx:]), axis=1)\n",
    "\n",
    "#             elif augmentation_type == 'random_shift':\n",
    "#                 # Random shifting\n",
    "#                 shift_amount = random.randint(-(sequence_length // 10), sequence_length // 10)\n",
    "#                 augmented_sample = np.roll(input_data[i], shift_amount, axis=-1)\n",
    "\n",
    "#             if augmented_sample.shape == (num_channels, sequence_length):\n",
    "#                 augmented_data.append(augmented_sample)\n",
    "#                 augmented_labels.append(labels[i])\n",
    "#             else:\n",
    "#                 print(\"Invalid shape:\", augmented_sample.shape)\n",
    "\n",
    "#     # Convert to numpy arrays\n",
    "#     # Sử dụng hàm\n",
    "#     inhomogeneous_arrays = check_for_different_shapes(augmented_data)\n",
    "#     if inhomogeneous_arrays:\n",
    "#         print(\"Các mảng không đồng nhất:\")\n",
    "#         for array in inhomogeneous_arrays:\n",
    "#             print(array.shape)\n",
    "#     else:\n",
    "#         print(\"Tất cả các mảng có kích thước giống nhau.\")\n",
    "\n",
    "#     return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "# # Sử dụng hàm\n",
    "# augmented_data, augmented_labels = augment_time_series_data(input_data, output_labels, num_augmentations=30)\n",
    "# print(augmented_data.shape, augmented_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def reshape_time_series_data_v8(input_data, label_data, segments_per_new_sample, segment_length):\n",
    "#     \"\"\"\n",
    "#     Reshape time series data and corresponding labels into a specified shape.\n",
    "\n",
    "#     :param input_data: Original time series data array.\n",
    "#     :param label_data: Corresponding labels for the data.\n",
    "#     :param segments_per_new_sample: Number of segments per new sample.\n",
    "#     :param segment_length: Length of each segment.\n",
    "\n",
    "#     :return: Reshaped data array and corresponding labels.\n",
    "#     \"\"\"\n",
    "#     num_samples_original, num_channels, length_original = input_data.shape\n",
    "\n",
    "#     # Validate the feasibility of reshaping\n",
    "#     if length_original % segment_length != 0:\n",
    "#         raise ValueError(\"Segment length must evenly divide the original length.\")\n",
    "\n",
    "#     total_segments_per_original_sample = (length_original // segment_length) * num_channels\n",
    "#     num_samples_new = (num_samples_original * total_segments_per_original_sample) // segments_per_new_sample\n",
    "\n",
    "#     # Validate if reshaping is possible\n",
    "#     if (num_samples_original * total_segments_per_original_sample) % segments_per_new_sample != 0:\n",
    "#         raise ValueError(\"Reshaping not possible with the given dimensions.\")\n",
    "\n",
    "#     # Initialize reshaped data and labels\n",
    "#     new_shape = (num_samples_new, segments_per_new_sample, segment_length)\n",
    "#     reshaped_data = np.zeros(new_shape)\n",
    "#     reshaped_labels = np.zeros(num_samples_new)\n",
    "\n",
    "#     # Reshape the data and labels\n",
    "#     count = 0\n",
    "#     for i in range(num_samples_original):\n",
    "#         segment_count = 0\n",
    "#         for j in range(num_channels):\n",
    "#             for k in range(length_original // segment_length):\n",
    "#                 start_idx = k * segment_length\n",
    "#                 end_idx = start_idx + segment_length\n",
    "#                 reshaped_data[count, segment_count % segments_per_new_sample, :] = input_data[i, j, start_idx:end_idx]\n",
    "#                 if (segment_count + 1) % segments_per_new_sample == 0:\n",
    "#                     reshaped_labels[count] = label_data[i]  # Assign corresponding label\n",
    "#                     count += 1\n",
    "#                 segment_count += 1\n",
    "\n",
    "#     return reshaped_data, reshaped_labels\n",
    "\n",
    "# # Example usage\n",
    "# segments_per_new_sample = 10\n",
    "# segment_length = 2000\n",
    "\n",
    "# # Assume 'augmented_data' and 'augmented_labels' are your input data and labels\n",
    "# reshaped_data, reshaped_labels = reshape_time_series_data_v8(augmented_data, augmented_labels, segments_per_new_sample, segment_length)\n",
    "# print(reshaped_data.shape, reshaped_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('reshaped_data.npy', reshaped_data)\n",
    "# np.save('reshaped_label.npy', reshaped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = np.load('reshaped_data.npy')\n",
    "reshaped_labels = np.load('reshaped_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(1982, 10, 2000)\n",
      "y_train's shape:(1982,)\n",
      "X_test's shape:(425, 10, 2000)\n",
      "y_test's shape:(425,)\n",
      "X_val's shape:(425, 10, 2000)\n",
      "y_val's shape:(425,)\n"
     ]
    }
   ],
   "source": [
    "input_train = reshaped_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_train, output_train, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train.shape))\n",
    "print(\"y_train's shape:\" + str(y_train.shape))\n",
    "print(\"X_test's shape:\" + str(X_test.shape))\n",
    "print(\"y_test's shape:\" + str(y_test.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "No. Labels: 10\n"
     ]
    }
   ],
   "source": [
    "label=np.unique(y_train)\n",
    "print('Label = ' + str(label))\n",
    "num_classes = len(np.unique(y_train))\n",
    "print('No. Labels: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session()\n",
    "\n",
    "# def build_1DCNN_model(input_shape, num_classes):\n",
    "#     input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "#     # 1D-CNN Preprocessing Layers\n",
    "#     x = Conv1D(filters=256, kernel_size=1, padding=\"same\")(input_tensor)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPool1D()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Conv1D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Conv1D(filters=64, kernel_size=1, padding=\"same\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "#     # Dense Layers for Classification\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Run the model on GPU if available\n",
    "# with tf.device('/GPU:0'):\n",
    "#     DCNN_model = build_1DCNN_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "#     DCNN_model.summary()\n",
    "\n",
    "#     # Early stopping callback\n",
    "#     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "#     # Train the model\n",
    "#     history_1DCNN = DCNN_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session()\n",
    "\n",
    "# def build_GRU_model(input_shape, num_classes):\n",
    "#     input_tensor = Input(shape=input_shape)    \n",
    "#     x = GRU(200, return_sequences=True)(input_tensor)   \n",
    "#     x = GRU(200, return_sequences=True,dropout=0.5)(x)  \n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(100)(x)\n",
    "#     output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "#     model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Run the model on GPU if available\n",
    "# with tf.device('/GPU:0'):\n",
    "#     GRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "#     GRU_model.summary()\n",
    "\n",
    "#     # Early stopping callback\n",
    "#     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "#     # Train the model\n",
    "#     history_GRU = GRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session()\n",
    "\n",
    "# def build_GRU_model(input_shape, num_classes):\n",
    "#     input_tensor = Input(shape=input_shape)    \n",
    "#     x = Bidirectional(GRU(200, return_sequences=True))(input_tensor)   \n",
    "#     x = Bidirectional(GRU(200, return_sequences=True,dropout=0.5))(x)  \n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(100)(x)\n",
    "#     output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "#     model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Run the model on GPU if available\n",
    "# with tf.device('/GPU:0'):\n",
    "#     BiGRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "#     BiGRU_model.summary()\n",
    "\n",
    "#     # Early stopping callback\n",
    "    \n",
    "#     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "#     # Train the model\n",
    "#     history_BiGRU = BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN-biGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 128)           768128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,035,478\n",
      "Trainable params: 2,035,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 8s 41ms/step - loss: 2.2901 - accuracy: 0.1034 - val_loss: 2.2058 - val_accuracy: 0.1318\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.0318 - accuracy: 0.2038 - val_loss: 1.9204 - val_accuracy: 0.2329\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6895 - accuracy: 0.3249 - val_loss: 1.7297 - val_accuracy: 0.3506\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3496 - accuracy: 0.4364 - val_loss: 1.4548 - val_accuracy: 0.4565\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.9840 - accuracy: 0.5959 - val_loss: 1.4243 - val_accuracy: 0.5106\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6629 - accuracy: 0.7291 - val_loss: 1.1646 - val_accuracy: 0.6706\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4182 - accuracy: 0.8421 - val_loss: 1.1130 - val_accuracy: 0.7059\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3108 - accuracy: 0.8920 - val_loss: 1.2057 - val_accuracy: 0.7365\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2307 - accuracy: 0.9193 - val_loss: 1.1129 - val_accuracy: 0.7435\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1798 - accuracy: 0.9435 - val_loss: 1.0905 - val_accuracy: 0.7647\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0744 - accuracy: 0.9753 - val_loss: 1.2433 - val_accuracy: 0.7671\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0935 - accuracy: 0.9687 - val_loss: 2.0981 - val_accuracy: 0.6871\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1587 - accuracy: 0.9480 - val_loss: 1.1355 - val_accuracy: 0.7741\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0733 - accuracy: 0.9768 - val_loss: 1.2909 - val_accuracy: 0.7835\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0723 - accuracy: 0.9748 - val_loss: 1.3654 - val_accuracy: 0.7882\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0343 - accuracy: 0.9899 - val_loss: 1.2544 - val_accuracy: 0.7859\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0295 - accuracy: 0.9924 - val_loss: 1.3387 - val_accuracy: 0.7906\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0605 - accuracy: 0.9798 - val_loss: 1.1958 - val_accuracy: 0.7929\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0871 - accuracy: 0.9748 - val_loss: 1.1035 - val_accuracy: 0.7906\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 1.1821 - val_accuracy: 0.7929\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 1.2453 - val_accuracy: 0.7929\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0392 - accuracy: 0.9899 - val_loss: 1.3701 - val_accuracy: 0.7718\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0428 - accuracy: 0.9909 - val_loss: 1.3120 - val_accuracy: 0.7835\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.2815 - val_accuracy: 0.7953\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 1.2651 - val_accuracy: 0.7929\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0599 - accuracy: 0.9834 - val_loss: 1.4222 - val_accuracy: 0.7788\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0699 - accuracy: 0.9783 - val_loss: 1.6366 - val_accuracy: 0.7529\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1019 - accuracy: 0.9728 - val_loss: 1.3645 - val_accuracy: 0.7529\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0664 - accuracy: 0.9854 - val_loss: 1.3392 - val_accuracy: 0.7600\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 1.1975 - val_accuracy: 0.8047\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.2623 - val_accuracy: 0.7953\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.2902 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 1.4127 - val_accuracy: 0.7718\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 1.2345 - val_accuracy: 0.7953\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 1.2787 - val_accuracy: 0.7882\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 1.3438 - val_accuracy: 0.7906\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 1.2954 - val_accuracy: 0.8118\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0520 - accuracy: 0.9874 - val_loss: 1.6197 - val_accuracy: 0.7600\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0590 - accuracy: 0.9828 - val_loss: 1.3605 - val_accuracy: 0.7976\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0646 - accuracy: 0.9844 - val_loss: 1.3934 - val_accuracy: 0.7906\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0529 - accuracy: 0.9859 - val_loss: 1.3690 - val_accuracy: 0.7812\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0584 - accuracy: 0.9834 - val_loss: 1.1688 - val_accuracy: 0.7765\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 1.1673 - val_accuracy: 0.7835\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 1.2674 - val_accuracy: 0.7906\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 1.3931 - val_accuracy: 0.7882\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 1.4445 - val_accuracy: 0.7882\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 1.4872 - val_accuracy: 0.7882\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 1.3925 - val_accuracy: 0.8071\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0540 - accuracy: 0.9869 - val_loss: 1.2354 - val_accuracy: 0.7718\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0392 - accuracy: 0.9849 - val_loss: 1.3348 - val_accuracy: 0.7906\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0552 - accuracy: 0.9834 - val_loss: 1.4077 - val_accuracy: 0.7788\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 1.7047 - val_accuracy: 0.7694\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0378 - accuracy: 0.9899 - val_loss: 1.3720 - val_accuracy: 0.7812\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 1.3316 - val_accuracy: 0.7882\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 1.3651 - val_accuracy: 0.7882\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 1.3518 - val_accuracy: 0.7882\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.3989 - val_accuracy: 0.7976\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.4427 - val_accuracy: 0.7929\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 1.3821 - val_accuracy: 0.7976\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.4134e-04 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.7929\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 9.7153e-05 - accuracy: 1.0000 - val_loss: 1.4110 - val_accuracy: 0.7929\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.0558e-04 - accuracy: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.7929\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.8158e-04 - accuracy: 1.0000 - val_loss: 1.4433 - val_accuracy: 0.7976\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 8.2565e-05 - accuracy: 1.0000 - val_loss: 1.4391 - val_accuracy: 0.7976\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 8.0190e-05 - accuracy: 1.0000 - val_loss: 1.4568 - val_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 6.2925e-05 - accuracy: 1.0000 - val_loss: 1.4763 - val_accuracy: 0.7976\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 5.2456e-05 - accuracy: 1.0000 - val_loss: 1.4939 - val_accuracy: 0.7929\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 6.9319e-05 - accuracy: 1.0000 - val_loss: 1.4812 - val_accuracy: 0.7906\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 4.4425e-05 - accuracy: 1.0000 - val_loss: 1.4888 - val_accuracy: 0.7906\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 7.8662e-05 - accuracy: 1.0000 - val_loss: 1.4887 - val_accuracy: 0.7953\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 4.0104e-05 - accuracy: 1.0000 - val_loss: 1.4971 - val_accuracy: 0.7976\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.1851e-04 - accuracy: 1.0000 - val_loss: 1.5608 - val_accuracy: 0.8094\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0213 - accuracy: 0.9965 - val_loss: 1.6580 - val_accuracy: 0.7741\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1851 - accuracy: 0.9571 - val_loss: 1.0975 - val_accuracy: 0.7600\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0656 - accuracy: 0.9793 - val_loss: 1.1536 - val_accuracy: 0.7835\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 1.3131 - val_accuracy: 0.7765\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 1.4474 - val_accuracy: 0.7765\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 1.2770 - val_accuracy: 0.7765\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0456 - accuracy: 0.9823 - val_loss: 1.3265 - val_accuracy: 0.7788\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0185 - accuracy: 0.9929 - val_loss: 1.2769 - val_accuracy: 0.7953\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 1.3268 - val_accuracy: 0.7929\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 1.4130 - val_accuracy: 0.8024\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 1.4357 - val_accuracy: 0.7953\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 1.3157 - val_accuracy: 0.8212\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 1.4232 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 1.4032 - val_accuracy: 0.7765\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 1.4763 - val_accuracy: 0.7976\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.3251 - val_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.6227 - val_accuracy: 0.7812\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 1.4706 - val_accuracy: 0.7976\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.3619 - val_accuracy: 0.8024\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.3910e-04 - accuracy: 1.0000 - val_loss: 1.3897 - val_accuracy: 0.8024\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.6449e-04 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.8024\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4049e-04 - accuracy: 1.0000 - val_loss: 1.4008 - val_accuracy: 0.8024\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.9229e-04 - accuracy: 1.0000 - val_loss: 1.3920 - val_accuracy: 0.8024\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 5.7493e-05 - accuracy: 1.0000 - val_loss: 1.4136 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 8.4800e-05 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.8024\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 5.1521e-05 - accuracy: 1.0000 - val_loss: 1.4212 - val_accuracy: 0.8024\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7239e-04 - accuracy: 1.0000 - val_loss: 1.4841 - val_accuracy: 0.8071\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0872e-04 - accuracy: 1.0000 - val_loss: 1.4894 - val_accuracy: 0.8047\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_CNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_BiGRU_model = build_CNN_BiGRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_DCNN_BiGRU = DCNN_BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_2d = reshaped_data.reshape(-1, reshaped_data.shape[2])  # (1000 * 10, 2000)\n",
    "\n",
    "# # Áp dụng PCA để giảm số timesteps từ 2000 xuống 500\n",
    "# n_components = 1000\n",
    "# pca = PCA(n_components=n_components)\n",
    "# X_2d_reduced = pca.fit_transform(X_2d)  # (1000 * 10, 500)\n",
    "\n",
    "# # Chuyển lại thành dạng 3D\n",
    "# X_reduced = X_2d_reduced.reshape(reshaped_data.shape[0], reshaped_data.shape[1], n_components)  # (1000, 10, 500)\n",
    "# print(\"Kích thước dữ liệu sau PCA:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('pca_data.npy', X_reduced)\n",
    "pca_data = np.load('pca_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(1982, 10, 1000)\n",
      "y_train's shape:(1982,)\n",
      "X_test's shape:(425, 10, 1000)\n",
      "y_test's shape:(425,)\n",
      "X_val's shape:(425, 10, 1000)\n",
      "y_val's shape:(425,)\n"
     ]
    }
   ],
   "source": [
    "# input_train = reshaped_data\n",
    "# output_train = reshaped_labels\n",
    "\n",
    "input_train = pca_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train_1, X_temp_1, y_train_1, y_temp_1 = train_test_split(input_train, output_train, test_size=0.3, random_state=42)\n",
    "X_valid_1, X_test_1, y_valid_1, y_test_1 = train_test_split(X_temp_1, y_temp_1, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train_1.shape))\n",
    "print(\"y_train's shape:\" + str(y_train_1.shape))\n",
    "print(\"X_test's shape:\" + str(X_test_1.shape))\n",
    "print(\"y_test's shape:\" + str(y_test_1.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid_1.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 1000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 128)           384128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,651,478\n",
      "Trainable params: 1,651,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 10s 41ms/step - loss: 2.3027 - accuracy: 0.1034 - val_loss: 2.2751 - val_accuracy: 0.1482\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.9962 - accuracy: 0.2386 - val_loss: 1.8981 - val_accuracy: 0.2447\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.4688 - accuracy: 0.4087 - val_loss: 1.5728 - val_accuracy: 0.4118\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.9907 - accuracy: 0.5923 - val_loss: 1.2638 - val_accuracy: 0.5694\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.6386 - accuracy: 0.7366 - val_loss: 1.2363 - val_accuracy: 0.6800\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4050 - accuracy: 0.8471 - val_loss: 1.4171 - val_accuracy: 0.6894\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.3046 - accuracy: 0.8925 - val_loss: 1.1999 - val_accuracy: 0.7459\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.2104 - accuracy: 0.9294 - val_loss: 1.1873 - val_accuracy: 0.7647\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1147 - accuracy: 0.9662 - val_loss: 1.3266 - val_accuracy: 0.7694\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0916 - accuracy: 0.9682 - val_loss: 1.3351 - val_accuracy: 0.7788\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1066 - accuracy: 0.9667 - val_loss: 1.3678 - val_accuracy: 0.7953\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0732 - accuracy: 0.9738 - val_loss: 1.5240 - val_accuracy: 0.7671\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.1050 - accuracy: 0.9682 - val_loss: 1.5019 - val_accuracy: 0.7671\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0510 - accuracy: 0.9839 - val_loss: 1.5304 - val_accuracy: 0.7929\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.1044 - accuracy: 0.9707 - val_loss: 1.8891 - val_accuracy: 0.7482\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0974 - accuracy: 0.9692 - val_loss: 1.5068 - val_accuracy: 0.7624\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0518 - accuracy: 0.9864 - val_loss: 1.3757 - val_accuracy: 0.8047\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 1.5581 - val_accuracy: 0.7788\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0291 - accuracy: 0.9929 - val_loss: 1.4772 - val_accuracy: 0.8141\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 1.7323 - val_accuracy: 0.7859\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 1.7065 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.6579 - val_accuracy: 0.8165\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.6271 - val_accuracy: 0.8141\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 1.7280 - val_accuracy: 0.8094\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.6692 - val_accuracy: 0.8235\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 4.4036e-04 - accuracy: 1.0000 - val_loss: 1.6956 - val_accuracy: 0.8188\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.4436e-04 - accuracy: 1.0000 - val_loss: 1.7256 - val_accuracy: 0.8282\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.1247e-04 - accuracy: 1.0000 - val_loss: 1.6891 - val_accuracy: 0.8353\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.6525e-04 - accuracy: 1.0000 - val_loss: 1.7228 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.4062e-04 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.8282\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.2805e-04 - accuracy: 1.0000 - val_loss: 1.7591 - val_accuracy: 0.8259\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 5.3767e-04 - accuracy: 1.0000 - val_loss: 1.7550 - val_accuracy: 0.8306\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1837e-04 - accuracy: 1.0000 - val_loss: 1.7842 - val_accuracy: 0.8306\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2489e-04 - accuracy: 1.0000 - val_loss: 1.7955 - val_accuracy: 0.8329\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 7.7039e-05 - accuracy: 1.0000 - val_loss: 1.8077 - val_accuracy: 0.8306\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 7.2452e-05 - accuracy: 1.0000 - val_loss: 1.8125 - val_accuracy: 0.8306\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 8.3763e-05 - accuracy: 1.0000 - val_loss: 1.8297 - val_accuracy: 0.8306\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 9.8041e-05 - accuracy: 1.0000 - val_loss: 1.8248 - val_accuracy: 0.8329\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 5.6747e-05 - accuracy: 1.0000 - val_loss: 1.8470 - val_accuracy: 0.8329\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 4.4247e-05 - accuracy: 1.0000 - val_loss: 1.8673 - val_accuracy: 0.8329\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 6.2257e-05 - accuracy: 1.0000 - val_loss: 1.8732 - val_accuracy: 0.8400\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 5.3800e-05 - accuracy: 1.0000 - val_loss: 1.8661 - val_accuracy: 0.8353\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 4.2682e-05 - accuracy: 1.0000 - val_loss: 1.8598 - val_accuracy: 0.8353\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 4.4850e-05 - accuracy: 1.0000 - val_loss: 1.8826 - val_accuracy: 0.8353\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 5.5385e-05 - accuracy: 1.0000 - val_loss: 1.9091 - val_accuracy: 0.8329\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 5.9696e-05 - accuracy: 1.0000 - val_loss: 1.8975 - val_accuracy: 0.8353\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 5.5045e-05 - accuracy: 1.0000 - val_loss: 1.8970 - val_accuracy: 0.8376\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 5.7462e-05 - accuracy: 1.0000 - val_loss: 1.9238 - val_accuracy: 0.8329\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 7.5414e-05 - accuracy: 1.0000 - val_loss: 2.0140 - val_accuracy: 0.8259\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 4.2250e-05 - accuracy: 1.0000 - val_loss: 1.9980 - val_accuracy: 0.8306\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 7.2555e-05 - accuracy: 1.0000 - val_loss: 1.9742 - val_accuracy: 0.8353\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 4.8937e-05 - accuracy: 1.0000 - val_loss: 1.9879 - val_accuracy: 0.8376\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 3.2628e-05 - accuracy: 1.0000 - val_loss: 1.9935 - val_accuracy: 0.8400\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.6442e-05 - accuracy: 1.0000 - val_loss: 1.9996 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.0425e-05 - accuracy: 1.0000 - val_loss: 2.0261 - val_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.2285e-05 - accuracy: 1.0000 - val_loss: 2.0476 - val_accuracy: 0.8353\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.9332e-05 - accuracy: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.8353\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 5.3358e-05 - accuracy: 1.0000 - val_loss: 2.0338 - val_accuracy: 0.8376\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7367e-05 - accuracy: 1.0000 - val_loss: 2.0451 - val_accuracy: 0.8400\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 3.0262e-05 - accuracy: 1.0000 - val_loss: 2.0234 - val_accuracy: 0.8353\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.4339e-05 - accuracy: 1.0000 - val_loss: 2.0668 - val_accuracy: 0.8400\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6159e-05 - accuracy: 1.0000 - val_loss: 2.0678 - val_accuracy: 0.8400\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.4832e-05 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.8400\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.6492e-05 - accuracy: 1.0000 - val_loss: 2.0781 - val_accuracy: 0.8400\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2225e-05 - accuracy: 1.0000 - val_loss: 2.0998 - val_accuracy: 0.8400\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1977e-05 - accuracy: 1.0000 - val_loss: 2.1025 - val_accuracy: 0.8400\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.2331e-05 - accuracy: 1.0000 - val_loss: 2.1163 - val_accuracy: 0.8400\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0413e-05 - accuracy: 1.0000 - val_loss: 2.1244 - val_accuracy: 0.8400\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.0739e-05 - accuracy: 1.0000 - val_loss: 2.1239 - val_accuracy: 0.8376\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 9.6854e-06 - accuracy: 1.0000 - val_loss: 2.1216 - val_accuracy: 0.8353\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1481e-05 - accuracy: 1.0000 - val_loss: 2.1196 - val_accuracy: 0.8329\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3296e-05 - accuracy: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4462e-05 - accuracy: 1.0000 - val_loss: 2.1574 - val_accuracy: 0.8400\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.1178e-05 - accuracy: 1.0000 - val_loss: 2.1609 - val_accuracy: 0.8329\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.0566e-05 - accuracy: 1.0000 - val_loss: 2.1637 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 6.8104e-06 - accuracy: 1.0000 - val_loss: 2.1686 - val_accuracy: 0.8400\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 4.2080e-05 - accuracy: 1.0000 - val_loss: 2.0240 - val_accuracy: 0.8329\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7554e-05 - accuracy: 1.0000 - val_loss: 2.1210 - val_accuracy: 0.8376\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 8.6115e-06 - accuracy: 1.0000 - val_loss: 2.1526 - val_accuracy: 0.8353\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.0647e-05 - accuracy: 1.0000 - val_loss: 2.1724 - val_accuracy: 0.8306\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 8.3003e-06 - accuracy: 1.0000 - val_loss: 2.1891 - val_accuracy: 0.8329\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.5786e-04 - accuracy: 1.0000 - val_loss: 2.8828 - val_accuracy: 0.7929\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3178 - accuracy: 0.6796 - val_loss: 0.9797 - val_accuracy: 0.7365\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.2567 - accuracy: 0.9279 - val_loss: 1.2060 - val_accuracy: 0.7812\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0786 - accuracy: 0.9834 - val_loss: 1.3057 - val_accuracy: 0.8071\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0376 - accuracy: 0.9904 - val_loss: 1.4216 - val_accuracy: 0.8259\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 1.2808 - val_accuracy: 0.8306\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 1.5367 - val_accuracy: 0.8141\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 1.5612 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 1.6520 - val_accuracy: 0.8141\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6585 - val_accuracy: 0.8282\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.8376\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 7.6376e-04 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.8329\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 5.7205e-04 - accuracy: 1.0000 - val_loss: 1.7448 - val_accuracy: 0.8282\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 5.0642e-04 - accuracy: 1.0000 - val_loss: 1.7157 - val_accuracy: 0.8376\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.7026e-04 - accuracy: 1.0000 - val_loss: 1.7431 - val_accuracy: 0.8353\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.7689e-04 - accuracy: 1.0000 - val_loss: 1.7497 - val_accuracy: 0.8353\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.6164e-04 - accuracy: 1.0000 - val_loss: 1.7757 - val_accuracy: 0.8400\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.8462e-04 - accuracy: 1.0000 - val_loss: 1.7654 - val_accuracy: 0.8424\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 4.2774e-04 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_PCA_1DCNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    PCA_DCNN_BiGRU_model = build_PCA_1DCNN_BiGRU_model((X_train_1.shape[1], X_train_1.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    PCA_DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_PCA_DCNN_BiGRU = PCA_DCNN_BiGRU_model.fit(X_train_1, y_train_1, batch_size=32, epochs=100, validation_data=(X_valid_1, y_valid_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History saved to 'History/1dcnn_bigru_accuracy.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# DCNN_model.save(f'Model/model_1dcnn.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/1dcnn_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_1DCNN.history['accuracy'], \n",
    "#                 'val_accuracy': history_1DCNN.history['val_accuracy'],\n",
    "#                 'train_loss': history_1DCNN.history['loss'],\n",
    "#                 'val_loss': history_1DCNN.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/1dcnn_accuracy.pkl'))\n",
    "\n",
    "# GRU_model.save(f'Model/model_gru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/gru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_GRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_GRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_GRU.history['loss'],\n",
    "#                 'val_loss': history_GRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/gru_accuracy.pkl'))\n",
    "\n",
    "# BiGRU_model.save(f'Model/model_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/bigru_accuracy.pkl'))\n",
    "\n",
    "DCNN_BiGRU_model.save(f'Model/model_1dcnn_bigru.h5')\n",
    "# Save history as a.pkl file\n",
    "with open(f'History/1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "    pickle.dump({'train_accuracy': history_DCNN_BiGRU.history['accuracy'], \n",
    "                'val_accuracy': history_DCNN_BiGRU.history['val_accuracy'],\n",
    "                'train_loss': history_DCNN_BiGRU.history['loss'],\n",
    "                'val_loss': history_DCNN_BiGRU.history['val_loss']}, f)\n",
    "print(\"History saved to '{}'.\".format(f'History/1dcnn_bigru_accuracy.pkl'))\n",
    "\n",
    "# PCA_DCNN_BiGRU_model.save(f'Model/model_pca_1dcnn_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/pca_1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_PCA_DCNN_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_PCA_DCNN_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_PCA_DCNN_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_PCA_DCNN_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/pca_1dcnn_bigru_accuracy.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StellarGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
