{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, add, LSTM, Dense, Dropout,GRU, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 24, 10000), (11,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'D:/OneDrive/DXLab_Vu/BaiBao/Trong nuoc/2024/Paper-2024-1DCNNLSTM-Khung/Code\\Data'\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.mat'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load the .mat file and add its contents to the dictionary\n",
    "        mat_data = loadmat(filepath)\n",
    "        \n",
    "        # Use filename (without extension) as key for the data\n",
    "        key = os.path.splitext(filename)[0]\n",
    "        row_means = np.mean(mat_data['acceleration'],1)\n",
    "        rows_2_keep = row_means != 0\n",
    "        all_data[key] = mat_data['acceleration'][rows_2_keep]\n",
    "        \n",
    "keys_to_stack = [f'spaceframe{i}' for i in range(1,11)]\n",
    "input_data = np.stack([all_data[key] for key in keys_to_stack], axis=0)\n",
    "\n",
    "# Create the corresponding labels\n",
    "output_labels = np.linspace(0,10,11)  # Using 0 and 1 as class labels for binary cross-entropy\n",
    "label = output_labels\n",
    "\n",
    "input_data = input_data[:,:,:10000]\n",
    "input_data.shape, output_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid shape: (24, 8942)\n",
      "Invalid shape: (24, 5682)\n",
      "Invalid shape: (24, 5492)\n",
      "Invalid shape: (24, 5792)\n",
      "Invalid shape: (24, 1971)\n",
      "Invalid shape: (24, 5581)\n",
      "Invalid shape: (24, 1874)\n",
      "Invalid shape: (24, 7889)\n",
      "Invalid shape: (24, 4121)\n",
      "Invalid shape: (24, 5474)\n",
      "Invalid shape: (24, 1069)\n",
      "Invalid shape: (24, 4163)\n",
      "Invalid shape: (24, 2764)\n",
      "Invalid shape: (24, 985)\n",
      "Invalid shape: (24, 2335)\n",
      "Invalid shape: (24, 1864)\n",
      "Invalid shape: (24, 2912)\n",
      "Invalid shape: (24, 7259)\n",
      "Invalid shape: (24, 5081)\n",
      "Invalid shape: (24, 6907)\n",
      "Invalid shape: (24, 2692)\n",
      "Invalid shape: (24, 6947)\n",
      "Invalid shape: (24, 1326)\n",
      "Invalid shape: (24, 5816)\n",
      "Invalid shape: (24, 6992)\n",
      "Invalid shape: (24, 4235)\n",
      "Tất cả các mảng có kích thước giống nhau.\n",
      "(274, 24, 10000) (274,)\n"
     ]
    }
   ],
   "source": [
    "def check_for_different_shapes(arrays):\n",
    "    \"\"\"\n",
    "    Kiểm tra xem các mảng trong danh sách có kích thước không đồng nhất không.\n",
    "\n",
    "    Parameters:\n",
    "        arrays (list): Danh sách các mảng NumPy.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách các mảng không đồng nhất.\n",
    "    \"\"\"\n",
    "    inhomogeneous_arrays = []\n",
    "    expected_shape = None\n",
    "    for array in arrays:\n",
    "        if expected_shape is None:\n",
    "            expected_shape = array.shape\n",
    "        elif array.shape != expected_shape:\n",
    "            inhomogeneous_arrays.append(array)\n",
    "    return inhomogeneous_arrays\n",
    "\n",
    "def augment_time_series_data(input_data, labels, num_augmentations=5):\n",
    "    \"\"\"\n",
    "    Augment time series data.\n",
    "\n",
    "    :param input_data: Original time series data array.\n",
    "    :param labels: Corresponding labels for the data.\n",
    "    :param num_augmentations: Number of augmented samples to generate per original sample.\n",
    "\n",
    "    :return: Augmented data array and corresponding labels.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    num_samples, num_channels, sequence_length = input_data.shape\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for _ in range(num_augmentations):\n",
    "            # Choose a random augmentation technique\n",
    "            augmentation_type = random.choices(['noise', 'reverse', 'crop_pad', 'time_warp', 'random_shift'],\n",
    "                                               weights=[0.6, 0.1, 0.1, 0.1, 0.1])[0]\n",
    "\n",
    "            if augmentation_type == 'noise':\n",
    "                # Add random noise\n",
    "                noise = np.random.normal(0, 0.00005, input_data[i].shape)\n",
    "                augmented_sample = input_data[i] + noise\n",
    "\n",
    "            elif augmentation_type == 'reverse':\n",
    "                # Reverse the sequence\n",
    "                augmented_sample = np.flip(input_data[i], axis=-1)\n",
    "\n",
    "            elif augmentation_type == 'crop_pad':\n",
    "                # Crop and pad the sequence\n",
    "                crop_size = random.randint(1, sequence_length // 100)\n",
    "                padded_sample = np.pad(input_data[i], ((0, 0), (crop_size, 0)), mode='constant', constant_values=0)\n",
    "                augmented_sample = padded_sample[:, :-crop_size]\n",
    "\n",
    "            elif augmentation_type == 'time_warp':\n",
    "                # Time warping\n",
    "                start_idx = random.randint(0, sequence_length // 2)\n",
    "                end_idx = random.randint(start_idx, sequence_length)\n",
    "                warped_segment = np.mean(input_data[i][:, start_idx:end_idx], axis=1, keepdims=True)\n",
    "                augmented_sample = np.concatenate((warped_segment, input_data[i][:, end_idx:]), axis=1)\n",
    "\n",
    "            elif augmentation_type == 'random_shift':\n",
    "                # Random shifting\n",
    "                shift_amount = random.randint(-(sequence_length // 10), sequence_length // 10)\n",
    "                augmented_sample = np.roll(input_data[i], shift_amount, axis=-1)\n",
    "\n",
    "            if augmented_sample.shape == (num_channels, sequence_length):\n",
    "                augmented_data.append(augmented_sample)\n",
    "                augmented_labels.append(labels[i])\n",
    "            else:\n",
    "                print(\"Invalid shape:\", augmented_sample.shape)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    # Sử dụng hàm\n",
    "    inhomogeneous_arrays = check_for_different_shapes(augmented_data)\n",
    "    if inhomogeneous_arrays:\n",
    "        print(\"Các mảng không đồng nhất:\")\n",
    "        for array in inhomogeneous_arrays:\n",
    "            print(array.shape)\n",
    "    else:\n",
    "        print(\"Tất cả các mảng có kích thước giống nhau.\")\n",
    "\n",
    "    return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "# Sử dụng hàm\n",
    "augmented_data, augmented_labels = augment_time_series_data(input_data, output_labels, num_augmentations=30)\n",
    "print(augmented_data.shape, augmented_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3288, 10, 2000) (3288,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reshape_time_series_data_v8(input_data, label_data, segments_per_new_sample, segment_length):\n",
    "    \"\"\"\n",
    "    Reshape time series data and corresponding labels into a specified shape.\n",
    "\n",
    "    :param input_data: Original time series data array.\n",
    "    :param label_data: Corresponding labels for the data.\n",
    "    :param segments_per_new_sample: Number of segments per new sample.\n",
    "    :param segment_length: Length of each segment.\n",
    "\n",
    "    :return: Reshaped data array and corresponding labels.\n",
    "    \"\"\"\n",
    "    num_samples_original, num_channels, length_original = input_data.shape\n",
    "\n",
    "    # Validate the feasibility of reshaping\n",
    "    if length_original % segment_length != 0:\n",
    "        raise ValueError(\"Segment length must evenly divide the original length.\")\n",
    "\n",
    "    total_segments_per_original_sample = (length_original // segment_length) * num_channels\n",
    "    num_samples_new = (num_samples_original * total_segments_per_original_sample) // segments_per_new_sample\n",
    "\n",
    "    # Validate if reshaping is possible\n",
    "    if (num_samples_original * total_segments_per_original_sample) % segments_per_new_sample != 0:\n",
    "        raise ValueError(\"Reshaping not possible with the given dimensions.\")\n",
    "\n",
    "    # Initialize reshaped data and labels\n",
    "    new_shape = (num_samples_new, segments_per_new_sample, segment_length)\n",
    "    reshaped_data = np.zeros(new_shape)\n",
    "    reshaped_labels = np.zeros(num_samples_new)\n",
    "\n",
    "    # Reshape the data and labels\n",
    "    count = 0\n",
    "    for i in range(num_samples_original):\n",
    "        segment_count = 0\n",
    "        for j in range(num_channels):\n",
    "            for k in range(length_original // segment_length):\n",
    "                start_idx = k * segment_length\n",
    "                end_idx = start_idx + segment_length\n",
    "                reshaped_data[count, segment_count % segments_per_new_sample, :] = input_data[i, j, start_idx:end_idx]\n",
    "                if (segment_count + 1) % segments_per_new_sample == 0:\n",
    "                    reshaped_labels[count] = label_data[i]  # Assign corresponding label\n",
    "                    count += 1\n",
    "                segment_count += 1\n",
    "\n",
    "    return reshaped_data, reshaped_labels\n",
    "\n",
    "# Example usage\n",
    "segments_per_new_sample = 10\n",
    "segment_length = 2000\n",
    "\n",
    "# Assume 'augmented_data' and 'augmented_labels' are your input data and labels\n",
    "reshaped_data, reshaped_labels = reshape_time_series_data_v8(augmented_data, augmented_labels, segments_per_new_sample, segment_length)\n",
    "print(reshaped_data.shape, reshaped_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3288"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu sau PCA: (3288, 10, 500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_2d = reshaped_data.reshape(-1, reshaped_data.shape[2])  # (1000 * 10, 2000)\n",
    "\n",
    "# Áp dụng PCA để giảm số timesteps từ 2000 xuống 500\n",
    "n_components = 500\n",
    "pca = PCA(n_components=n_components)\n",
    "X_2d_reduced = pca.fit_transform(X_2d)  # (1000 * 10, 500)\n",
    "\n",
    "# Chuyển lại thành dạng 3D\n",
    "X_reduced = X_2d_reduced.reshape(reshaped_data.shape[0], reshaped_data.shape[1], n_components)  # (1000, 10, 500)\n",
    "print(\"Kích thước dữ liệu sau PCA:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(1972, 10, 2000)\n",
      "y_train's shape:(1972,)\n",
      "X_test's shape:(658, 10, 2000)\n",
      "y_test's shape:(658,)\n",
      "X_val's shape:(658, 10, 2000)\n",
      "y_val's shape:(658,)\n"
     ]
    }
   ],
   "source": [
    "input_train = reshaped_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = X_reduced\n",
    "# output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_train, output_train, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train.shape))\n",
    "print(\"y_train's shape:\" + str(y_train.shape))\n",
    "print(\"X_test's shape:\" + str(X_test.shape))\n",
    "print(\"y_test's shape:\" + str(y_test.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "No. Labels: 10\n"
     ]
    }
   ],
   "source": [
    "label=np.unique(y_train)\n",
    "print('Label = ' + str(label))\n",
    "num_classes = len(np.unique(y_train))\n",
    "print('No. Labels: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 128)           768128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,035,478\n",
      "Trainable params: 2,035,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 8s 42ms/step - loss: 2.2048 - accuracy: 0.1501 - val_loss: 1.7798 - val_accuracy: 0.3222\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2171 - accuracy: 0.5659 - val_loss: 0.8355 - val_accuracy: 0.7112\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5745 - accuracy: 0.7880 - val_loss: 0.6807 - val_accuracy: 0.7903\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3863 - accuracy: 0.8545 - val_loss: 0.6564 - val_accuracy: 0.8252\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2130 - accuracy: 0.9255 - val_loss: 0.6503 - val_accuracy: 0.8556\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1599 - accuracy: 0.9452 - val_loss: 0.5517 - val_accuracy: 0.8663\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0968 - accuracy: 0.9706 - val_loss: 0.5675 - val_accuracy: 0.8632\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0732 - accuracy: 0.9812 - val_loss: 0.7297 - val_accuracy: 0.8784\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.1160 - accuracy: 0.9665 - val_loss: 0.6073 - val_accuracy: 0.8632\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0507 - accuracy: 0.9858 - val_loss: 0.5640 - val_accuracy: 0.8875\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 0.6845 - val_accuracy: 0.8860\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.7097 - val_accuracy: 0.8784\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.0434 - accuracy: 0.9858 - val_loss: 0.6149 - val_accuracy: 0.8967\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.6092 - val_accuracy: 0.8967\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0321 - accuracy: 0.9934 - val_loss: 0.6338 - val_accuracy: 0.8997\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0931 - accuracy: 0.9711 - val_loss: 0.6522 - val_accuracy: 0.8845\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.5644 - val_accuracy: 0.8891\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.8570 - val_accuracy: 0.8678\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1406 - accuracy: 0.9625 - val_loss: 0.6813 - val_accuracy: 0.8678\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0802 - accuracy: 0.9792 - val_loss: 0.5317 - val_accuracy: 0.8921\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 0.6193 - val_accuracy: 0.8860\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.6050 - val_accuracy: 0.8891\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.6552 - val_accuracy: 0.8906\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.7000 - val_accuracy: 0.8936\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.6182 - val_accuracy: 0.8967\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.6984 - val_accuracy: 0.8860\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 6.4393e-04 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.8982\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 5.7612e-04 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8906\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.6455e-04 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8936\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1999e-04 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8921\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0032e-04 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8936\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8967\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2687e-04 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.9012\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 8.9950e-05 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8967\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 6.3622e-05 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8982\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 4.6109e-05 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8951\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 4.7809e-05 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8951\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 5.1409e-05 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8951\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 6.8555e-05 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8997\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 7.0272e-05 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8982\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 7.3351e-05 - accuracy: 1.0000 - val_loss: 0.7239 - val_accuracy: 0.8967\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 4.1872e-05 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.8982\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 3.3001e-05 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8982\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.8231e-05 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.9027\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.3078e-05 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.9027\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 4.9221e-05 - accuracy: 1.0000 - val_loss: 0.7318 - val_accuracy: 0.8936\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 6.3545e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8997\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.5173e-05 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.8997\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6916e-05 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8997\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6447e-04 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8997\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 4.0600e-05 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.9043\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.1080e-05 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.9027\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 9.3878e-05 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.9027\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.2786e-05 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8997\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6544e-05 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.8997\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3643e-05 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.8997\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 2.1663e-05 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 0.9012\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6113e-05 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.9012\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.9614e-05 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.9027\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2742e-05 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.9027\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1984e-05 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.9027\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0028e-05 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.8982\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.6147e-05 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.9027\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1811e-05 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.8982\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1266e-05 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.9027\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5451e-05 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.9027\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 8.1467e-06 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.9027\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 3.5412e-05 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.8967\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.3733e-05 - accuracy: 1.0000 - val_loss: 0.8310 - val_accuracy: 0.8997\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 2.0632e-05 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.9012\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0558e-05 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 0.9012\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.1186e-05 - accuracy: 1.0000 - val_loss: 0.8180 - val_accuracy: 0.8982\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 8.3815e-06 - accuracy: 1.0000 - val_loss: 0.8248 - val_accuracy: 0.8997\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0465 - accuracy: 0.9965 - val_loss: 1.5710 - val_accuracy: 0.8404\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.3903 - accuracy: 0.8844 - val_loss: 0.5772 - val_accuracy: 0.8708\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.1366 - accuracy: 0.9599 - val_loss: 0.4947 - val_accuracy: 0.8754\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0416 - accuracy: 0.9858 - val_loss: 0.5540 - val_accuracy: 0.8967\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0146 - accuracy: 0.9934 - val_loss: 0.6189 - val_accuracy: 0.8936\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.6907 - val_accuracy: 0.8875\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.7354 - val_accuracy: 0.8815\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0417 - accuracy: 0.9888 - val_loss: 1.0057 - val_accuracy: 0.8404\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 0.7622 - val_accuracy: 0.8739\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0591 - accuracy: 0.9868 - val_loss: 0.6455 - val_accuracy: 0.8997\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.5925 - val_accuracy: 0.9043\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.5819 - val_accuracy: 0.9043\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 8.8318e-04 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.9058\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 5.6242e-04 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.9043\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 2.7106e-04 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9027\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 2.4994e-04 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.9027\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5679e-04 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.9012\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2267e-04 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.9012\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6178e-04 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.9043\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2623e-04 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.9043\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 9.4464e-05 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.9043\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0176e-04 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.9043\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 6.4915e-05 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.9043\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 7.4627e-05 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 0.9043\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 5.7717e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.9058\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8640e-04 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.9073\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 9.3150e-05 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_CNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_BiGRU_model = build_CNN_BiGRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_DCNN_BiGRU = DCNN_BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StellarGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
