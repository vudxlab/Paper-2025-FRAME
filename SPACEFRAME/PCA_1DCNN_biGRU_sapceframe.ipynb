{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pickle\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, add, LSTM, Dense, Dropout,GRU, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'Data'\n",
    "\n",
    "# all_data = {}\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.mat'):\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "        \n",
    "#         # Load the .mat file and add its contents to the dictionary\n",
    "#         mat_data = loadmat(filepath)\n",
    "        \n",
    "#         # Use filename (without extension) as key for the data\n",
    "#         key = os.path.splitext(filename)[0]\n",
    "#         row_means = np.mean(mat_data['acceleration'],1)\n",
    "#         rows_2_keep = row_means != 0\n",
    "#         all_data[key] = mat_data['acceleration'][rows_2_keep]\n",
    "        \n",
    "# keys_to_stack = [f'spaceframe{i}' for i in range(1,11)]\n",
    "# input_data = np.stack([all_data[key] for key in keys_to_stack], axis=0)\n",
    "\n",
    "# # Create the corresponding labels\n",
    "# output_labels = np.linspace(0,10,11)  # Using 0 and 1 as class labels for binary cross-entropy\n",
    "# label = output_labels\n",
    "\n",
    "# input_data = input_data[:,:,:15000]\n",
    "# input_data.shape, output_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the data at index (1, 1, :) which has a shape of (8000,)\n",
    "# Data = input_data[1,:, :]\n",
    "# print(Data.shape)\n",
    "# # Create the plot\n",
    "# fig, axes = plt.subplots(12, 1, figsize=(15, 8), sharex=True)\n",
    "\n",
    "# title_font = {'family': 'Times New Roman', 'size': 16, 'weight': 'bold'}\n",
    "# label_font = {'family': 'Times New Roman', 'size': 14}\n",
    "# plt.rcParams['xtick.labelsize'] = 10\n",
    "# plt.rcParams['ytick.labelsize'] = 10\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# # Plot the data for each sub-array\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.plot(Data[i, :], linewidth=1, color = 'b')\n",
    "#     # ax.set_title(f'Z24 Signal Data at Index (1, {i}, :)', fontsize=12)\n",
    "    \n",
    "#     ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     ax.minorticks_on()\n",
    "#     ax.grid(True, which='minor', color='#999999', linestyle='--', alpha=0.2)\n",
    "#     ax.set_xlim(-100, Data.shape[1]+100)\n",
    "# # Set common labels using axes\n",
    "# axes[-1].set_xlabel('Điểm dữ liệu', fontsize=14, fontdict=label_font)\n",
    "# axes[0].set_title('Dữ liệu Khung không gian', fontsize=16, fontdict=title_font)\n",
    "\n",
    "# # Create a \"super\" axis for the common Y-label and make it invisible\n",
    "# super_ax = fig.add_subplot(111, frame_on=False)\n",
    "# plt.tick_params(labelcolor=\"none\", bottom=False, left=False)\n",
    "# super_ax.set_ylabel(\"Giá trị\", fontsize=14, labelpad=15, fontdict=label_font)\n",
    "\n",
    "# # Move the super axis ylabel to avoid overlap with subplots\n",
    "# super_ax.yaxis.set_label_coords(-0.06,0.5)\n",
    "\n",
    "# # Adjust the layout so that plots do not overlap\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_for_different_shapes(arrays):\n",
    "#     \"\"\"\n",
    "#     Kiểm tra xem các mảng trong danh sách có kích thước không đồng nhất không.\n",
    "\n",
    "#     Parameters:\n",
    "#         arrays (list): Danh sách các mảng NumPy.\n",
    "\n",
    "#     Returns:\n",
    "#         list: Danh sách các mảng không đồng nhất.\n",
    "#     \"\"\"\n",
    "#     inhomogeneous_arrays = []\n",
    "#     expected_shape = None\n",
    "#     for array in arrays:\n",
    "#         if expected_shape is None:\n",
    "#             expected_shape = array.shape\n",
    "#         elif array.shape != expected_shape:\n",
    "#             inhomogeneous_arrays.append(array)\n",
    "#     return inhomogeneous_arrays\n",
    "\n",
    "# def augment_time_series_data(input_data, labels, num_augmentations=5):\n",
    "#     \"\"\"\n",
    "#     Augment time series data.\n",
    "\n",
    "#     :param input_data: Original time series data array.\n",
    "#     :param labels: Corresponding labels for the data.\n",
    "#     :param num_augmentations: Number of augmented samples to generate per original sample.\n",
    "\n",
    "#     :return: Augmented data array and corresponding labels.\n",
    "#     \"\"\"\n",
    "#     augmented_data = []\n",
    "#     augmented_labels = []\n",
    "\n",
    "#     num_samples, num_channels, sequence_length = input_data.shape\n",
    "\n",
    "#     for i in range(num_samples):\n",
    "#         for _ in range(num_augmentations):\n",
    "#             # Choose a random augmentation technique\n",
    "#             augmentation_type = random.choices(['noise', 'reverse', 'crop_pad', 'time_warp', 'random_shift'],\n",
    "#                                                weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n",
    "\n",
    "#             if augmentation_type == 'noise':\n",
    "#                 # Add random noise\n",
    "#                 noise = np.random.normal(0, 0.00005, input_data[i].shape)\n",
    "#                 augmented_sample = input_data[i] + noise\n",
    "\n",
    "#             elif augmentation_type == 'reverse':\n",
    "#                 # Reverse the sequence\n",
    "#                 augmented_sample = np.flip(input_data[i], axis=-1)\n",
    "\n",
    "#             elif augmentation_type == 'crop_pad':\n",
    "#                 # Crop and pad the sequence\n",
    "#                 crop_size = random.randint(1, sequence_length // 100)\n",
    "#                 padded_sample = np.pad(input_data[i], ((0, 0), (crop_size, 0)), mode='constant', constant_values=0)\n",
    "#                 augmented_sample = padded_sample[:, :-crop_size]\n",
    "\n",
    "#             elif augmentation_type == 'time_warp':\n",
    "#                 # Time warping\n",
    "#                 start_idx = random.randint(0, sequence_length // 2)\n",
    "#                 end_idx = random.randint(start_idx, sequence_length)\n",
    "#                 warped_segment = np.mean(input_data[i][:, start_idx:end_idx], axis=1, keepdims=True)\n",
    "#                 augmented_sample = np.concatenate((warped_segment, input_data[i][:, end_idx:]), axis=1)\n",
    "\n",
    "#             elif augmentation_type == 'random_shift':\n",
    "#                 # Random shifting\n",
    "#                 shift_amount = random.randint(-(sequence_length // 10), sequence_length // 10)\n",
    "#                 augmented_sample = np.roll(input_data[i], shift_amount, axis=-1)\n",
    "\n",
    "#             if augmented_sample.shape == (num_channels, sequence_length):\n",
    "#                 augmented_data.append(augmented_sample)\n",
    "#                 augmented_labels.append(labels[i])\n",
    "#             else:\n",
    "#                 print(\"Invalid shape:\", augmented_sample.shape)\n",
    "\n",
    "#     # Convert to numpy arrays\n",
    "#     # Sử dụng hàm\n",
    "#     inhomogeneous_arrays = check_for_different_shapes(augmented_data)\n",
    "#     if inhomogeneous_arrays:\n",
    "#         print(\"Các mảng không đồng nhất:\")\n",
    "#         for array in inhomogeneous_arrays:\n",
    "#             print(array.shape)\n",
    "#     else:\n",
    "#         print(\"Tất cả các mảng có kích thước giống nhau.\")\n",
    "\n",
    "#     return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "# # Sử dụng hàm\n",
    "# augmented_data, augmented_labels = augment_time_series_data(input_data, output_labels, num_augmentations=30)\n",
    "# print(augmented_data.shape, augmented_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def reshape_time_series_data_v8(input_data, label_data, segments_per_new_sample, segment_length):\n",
    "#     \"\"\"\n",
    "#     Reshape time series data and corresponding labels into a specified shape.\n",
    "\n",
    "#     :param input_data: Original time series data array.\n",
    "#     :param label_data: Corresponding labels for the data.\n",
    "#     :param segments_per_new_sample: Number of segments per new sample.\n",
    "#     :param segment_length: Length of each segment.\n",
    "\n",
    "#     :return: Reshaped data array and corresponding labels.\n",
    "#     \"\"\"\n",
    "#     num_samples_original, num_channels, length_original = input_data.shape\n",
    "\n",
    "#     # Validate the feasibility of reshaping\n",
    "#     if length_original % segment_length != 0:\n",
    "#         raise ValueError(\"Segment length must evenly divide the original length.\")\n",
    "\n",
    "#     total_segments_per_original_sample = (length_original // segment_length) * num_channels\n",
    "#     num_samples_new = (num_samples_original * total_segments_per_original_sample) // segments_per_new_sample\n",
    "\n",
    "#     # Validate if reshaping is possible\n",
    "#     if (num_samples_original * total_segments_per_original_sample) % segments_per_new_sample != 0:\n",
    "#         raise ValueError(\"Reshaping not possible with the given dimensions.\")\n",
    "\n",
    "#     # Initialize reshaped data and labels\n",
    "#     new_shape = (num_samples_new, segments_per_new_sample, segment_length)\n",
    "#     reshaped_data = np.zeros(new_shape)\n",
    "#     reshaped_labels = np.zeros(num_samples_new)\n",
    "\n",
    "#     # Reshape the data and labels\n",
    "#     count = 0\n",
    "#     for i in range(num_samples_original):\n",
    "#         segment_count = 0\n",
    "#         for j in range(num_channels):\n",
    "#             for k in range(length_original // segment_length):\n",
    "#                 start_idx = k * segment_length\n",
    "#                 end_idx = start_idx + segment_length\n",
    "#                 reshaped_data[count, segment_count % segments_per_new_sample, :] = input_data[i, j, start_idx:end_idx]\n",
    "#                 if (segment_count + 1) % segments_per_new_sample == 0:\n",
    "#                     reshaped_labels[count] = label_data[i]  # Assign corresponding label\n",
    "#                     count += 1\n",
    "#                 segment_count += 1\n",
    "\n",
    "#     return reshaped_data, reshaped_labels\n",
    "\n",
    "# # Example usage\n",
    "# segments_per_new_sample = 10\n",
    "# segment_length = 2000\n",
    "\n",
    "# # Assume 'augmented_data' and 'augmented_labels' are your input data and labels\n",
    "# reshaped_data, reshaped_labels = reshape_time_series_data_v8(augmented_data, augmented_labels, segments_per_new_sample, segment_length)\n",
    "# print(reshaped_data.shape, reshaped_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('reshaped_data.npy', reshaped_data)\n",
    "# np.save('reshaped_label.npy', reshaped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = np.load('reshaped_data.npy')\n",
    "reshaped_labels = np.load('reshaped_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(1982, 10, 2000)\n",
      "y_train's shape:(1982,)\n",
      "X_test's shape:(425, 10, 2000)\n",
      "y_test's shape:(425,)\n",
      "X_val's shape:(425, 10, 2000)\n",
      "y_val's shape:(425,)\n"
     ]
    }
   ],
   "source": [
    "input_train = reshaped_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_train, output_train, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train.shape))\n",
    "print(\"y_train's shape:\" + str(y_train.shape))\n",
    "print(\"X_test's shape:\" + str(X_test.shape))\n",
    "print(\"y_test's shape:\" + str(y_test.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "No. Labels: 10\n"
     ]
    }
   ],
   "source": [
    "label=np.unique(y_train)\n",
    "print('Label = ' + str(label))\n",
    "num_classes = len(np.unique(y_train))\n",
    "print('No. Labels: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 256)           512256    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 256)          1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 256)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5, 256)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 128)            98432     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 5, 128)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 5, 64)             8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 64)            256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               41088     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 663,114\n",
      "Trainable params: 662,218\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 9ms/step - loss: 1.4404 - accuracy: 0.5565 - val_loss: 2.3090 - val_accuracy: 0.1529\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.9723 - val_loss: 2.3393 - val_accuracy: 0.0871\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9995 - val_loss: 2.3647 - val_accuracy: 0.0894\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3529 - val_accuracy: 0.1012\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2686 - val_accuracy: 0.1765\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0820 - val_accuracy: 0.2894\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7610 - val_accuracy: 0.4212\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.2641e-04 - accuracy: 1.0000 - val_loss: 1.2893 - val_accuracy: 0.6612\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.5982e-04 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.7812\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.4535e-04 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 0.8141\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.5263e-04 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.8282\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.9132e-04 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.8424\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.4017e-04 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.9285e-04 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.8494\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.5908e-04 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.8494\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.2630e-04 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.8494\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.0837e-04 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.8494\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.8740e-04 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.8494\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.6869e-04 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.8518\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.5156e-04 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8518\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.3919e-04 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.8518\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.2598e-04 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.8518\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.1050e-04 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.8541\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0830e-04 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 9.9388e-05 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.8541\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 9.1412e-05 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.8541\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.2900e-05 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8541\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.8115e-05 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8541\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.4367e-05 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.8541\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.7089e-05 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8541\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.1869e-05 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.8541\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.9204e-05 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.8541\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.4108e-05 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.8541\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.9342e-05 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8541\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.7586e-05 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8541\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.5587e-05 - accuracy: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.8541\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.3424e-05 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.8541\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.0374e-05 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.8541\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.8839e-05 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.8541\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.6235e-05 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.8541\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.4855e-05 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.8541\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.3078e-05 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8541\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.1248e-05 - accuracy: 1.0000 - val_loss: 0.5942 - val_accuracy: 0.8541\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.8631e-05 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.8541\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.9021e-05 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8541\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.6714e-05 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8541\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.4544e-05 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8541\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.4066e-05 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.8541\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.2570e-05 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8541\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.1832e-05 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8541\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.0479e-05 - accuracy: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.8541\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.8940e-05 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.8541\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.8459e-05 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.8541\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.7518e-05 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.8541\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.6709e-05 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.8541\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.6148e-05 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8541\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.5544e-05 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.8541\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.4667e-05 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8541\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.4347e-05 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.8565\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.4060e-05 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.8541\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.2749e-05 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8565\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.2599e-05 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.8565\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.1616e-05 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.1415e-05 - accuracy: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.8565\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0685e-05 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.8565\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0151e-05 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.8565\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 9.8700e-06 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8565\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 9.3609e-06 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.8565\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.8997e-06 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.8565\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.8456e-06 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.8565\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.3968e-06 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8565\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.8644e-06 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.8565\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.7584e-06 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.8565\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.3981e-06 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.8565\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.2623e-06 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8565\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.0334e-06 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.8565\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.6185e-06 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.8565\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.3225e-06 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.8565\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.0692e-06 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.8565\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.7672e-06 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.8565\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.9182e-06 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8565\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.4965e-06 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.8565\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.1134e-06 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.8565\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.1154e-06 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 0.8565\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.7229e-06 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.8565\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.6946e-06 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.8565\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.5251e-06 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8565\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.1745e-06 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.8565\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.1484e-06 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.8565\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.0150e-06 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.8565\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.7914e-06 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.8565\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.7687e-06 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.8565\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.5248e-06 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.8565\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.3956e-06 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.8565\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.2399e-06 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.8565\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.2343e-06 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.8565\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.9971e-06 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.8565\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.9707e-06 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.8565\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.8452e-06 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 0.8565\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.6758e-06 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.8565\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_1DCNN_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # 1D-CNN Preprocessing Layers\n",
    "    x = Conv1D(filters=256, kernel_size=1, padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool1D()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=64, kernel_size=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Dense Layers for Classification\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_model = build_1DCNN_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    DCNN_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_1DCNN = DCNN_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 10, 200)           1321200   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 10, 200)           241200    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,763,510\n",
      "Trainable params: 1,763,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 14ms/step - loss: 2.2944 - accuracy: 0.1226 - val_loss: 2.2392 - val_accuracy: 0.1812\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.1244 - accuracy: 0.2477 - val_loss: 1.9887 - val_accuracy: 0.2659\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.5826 - accuracy: 0.4667 - val_loss: 1.6034 - val_accuracy: 0.5341\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.0923 - accuracy: 0.6675 - val_loss: 1.4446 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.8102 - accuracy: 0.7513 - val_loss: 1.4552 - val_accuracy: 0.6447\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.8179 - val_loss: 1.6022 - val_accuracy: 0.6706\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.8602 - val_loss: 1.5419 - val_accuracy: 0.7106\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.2866 - accuracy: 0.9082 - val_loss: 1.8023 - val_accuracy: 0.7129\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.2148 - accuracy: 0.9299 - val_loss: 2.2292 - val_accuracy: 0.7294\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.9152 - val_loss: 2.1851 - val_accuracy: 0.7129\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.9495 - val_loss: 2.5385 - val_accuracy: 0.7129\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.1677 - accuracy: 0.9395 - val_loss: 2.5024 - val_accuracy: 0.7318\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.9627 - val_loss: 2.6578 - val_accuracy: 0.7341\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9768 - val_loss: 3.0238 - val_accuracy: 0.7365\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 3.2633 - val_accuracy: 0.7412\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 3.0973 - val_accuracy: 0.7153\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9627 - val_loss: 3.2160 - val_accuracy: 0.7153\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9596 - val_loss: 3.0528 - val_accuracy: 0.7129\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9934 - val_loss: 3.1773 - val_accuracy: 0.7435\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 3.3700 - val_accuracy: 0.7435\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.5417 - val_accuracy: 0.7506\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 7.3940e-04 - accuracy: 1.0000 - val_loss: 3.5632 - val_accuracy: 0.7435\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.4876e-04 - accuracy: 1.0000 - val_loss: 3.6314 - val_accuracy: 0.7435\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.3409e-04 - accuracy: 1.0000 - val_loss: 3.6827 - val_accuracy: 0.7459\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.0402e-04 - accuracy: 1.0000 - val_loss: 3.7260 - val_accuracy: 0.7435\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.8849e-04 - accuracy: 1.0000 - val_loss: 3.7736 - val_accuracy: 0.7435\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.6026e-04 - accuracy: 1.0000 - val_loss: 3.8185 - val_accuracy: 0.7435\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.2005e-04 - accuracy: 1.0000 - val_loss: 3.8539 - val_accuracy: 0.7459\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.1767e-04 - accuracy: 1.0000 - val_loss: 3.8924 - val_accuracy: 0.7435\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.7073e-04 - accuracy: 1.0000 - val_loss: 3.9264 - val_accuracy: 0.7435\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.4985e-04 - accuracy: 1.0000 - val_loss: 3.9554 - val_accuracy: 0.7435\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.4269e-04 - accuracy: 1.0000 - val_loss: 3.9878 - val_accuracy: 0.7459\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.5217e-04 - accuracy: 1.0000 - val_loss: 4.0229 - val_accuracy: 0.7459\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.1776e-04 - accuracy: 1.0000 - val_loss: 4.0493 - val_accuracy: 0.7459\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.1028e-04 - accuracy: 1.0000 - val_loss: 4.0782 - val_accuracy: 0.7459\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.1248e-04 - accuracy: 1.0000 - val_loss: 4.1064 - val_accuracy: 0.7459\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 8.9649e-05 - accuracy: 1.0000 - val_loss: 4.1349 - val_accuracy: 0.7459\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 8.1883e-05 - accuracy: 1.0000 - val_loss: 4.1568 - val_accuracy: 0.7459\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 8.8023e-05 - accuracy: 1.0000 - val_loss: 4.1910 - val_accuracy: 0.7459\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 7.4070e-05 - accuracy: 1.0000 - val_loss: 4.2121 - val_accuracy: 0.7459\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.9940e-05 - accuracy: 1.0000 - val_loss: 4.2398 - val_accuracy: 0.7459\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.9908e-05 - accuracy: 1.0000 - val_loss: 4.2581 - val_accuracy: 0.7459\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.4643e-05 - accuracy: 1.0000 - val_loss: 4.2842 - val_accuracy: 0.7459\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.7573e-05 - accuracy: 1.0000 - val_loss: 4.3123 - val_accuracy: 0.7459\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.2100e-05 - accuracy: 1.0000 - val_loss: 4.3330 - val_accuracy: 0.7459\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.9807e-05 - accuracy: 1.0000 - val_loss: 4.3573 - val_accuracy: 0.7459\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.3092e-05 - accuracy: 1.0000 - val_loss: 4.3826 - val_accuracy: 0.7459\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 4.6643e-05 - accuracy: 1.0000 - val_loss: 4.4018 - val_accuracy: 0.7459\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 4.0700e-05 - accuracy: 1.0000 - val_loss: 4.4200 - val_accuracy: 0.7459\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.7781e-05 - accuracy: 1.0000 - val_loss: 4.4363 - val_accuracy: 0.7459\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.6516e-05 - accuracy: 1.0000 - val_loss: 4.4579 - val_accuracy: 0.7459\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.1187e-05 - accuracy: 1.0000 - val_loss: 4.4782 - val_accuracy: 0.7459\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.1824e-05 - accuracy: 1.0000 - val_loss: 4.4995 - val_accuracy: 0.7459\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.1224e-05 - accuracy: 1.0000 - val_loss: 4.5193 - val_accuracy: 0.7459\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.0884e-05 - accuracy: 1.0000 - val_loss: 4.5380 - val_accuracy: 0.7459\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.9166e-05 - accuracy: 1.0000 - val_loss: 4.5596 - val_accuracy: 0.7459\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.9759e-05 - accuracy: 1.0000 - val_loss: 4.5850 - val_accuracy: 0.7459\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.5514e-05 - accuracy: 1.0000 - val_loss: 4.6051 - val_accuracy: 0.7459\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.2679e-05 - accuracy: 1.0000 - val_loss: 4.6238 - val_accuracy: 0.7459\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.2752e-05 - accuracy: 1.0000 - val_loss: 4.6410 - val_accuracy: 0.7459\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.3142e-05 - accuracy: 1.0000 - val_loss: 4.6597 - val_accuracy: 0.7459\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.8149e-05 - accuracy: 1.0000 - val_loss: 4.6768 - val_accuracy: 0.7459\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.1379e-05 - accuracy: 1.0000 - val_loss: 4.6937 - val_accuracy: 0.7435\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.7645e-05 - accuracy: 1.0000 - val_loss: 4.7136 - val_accuracy: 0.7459\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.7490e-05 - accuracy: 1.0000 - val_loss: 4.7308 - val_accuracy: 0.7459\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.6173e-05 - accuracy: 1.0000 - val_loss: 4.7487 - val_accuracy: 0.7459\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.6416e-05 - accuracy: 1.0000 - val_loss: 4.7672 - val_accuracy: 0.7459\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.4033e-05 - accuracy: 1.0000 - val_loss: 4.7883 - val_accuracy: 0.7459\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.4781e-05 - accuracy: 1.0000 - val_loss: 4.8052 - val_accuracy: 0.7459\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.3508e-05 - accuracy: 1.0000 - val_loss: 4.8245 - val_accuracy: 0.7459\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.2550e-05 - accuracy: 1.0000 - val_loss: 4.8401 - val_accuracy: 0.7459\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0834e-05 - accuracy: 1.0000 - val_loss: 4.8558 - val_accuracy: 0.7459\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.1709e-05 - accuracy: 1.0000 - val_loss: 4.8751 - val_accuracy: 0.7459\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.2059e-05 - accuracy: 1.0000 - val_loss: 4.8911 - val_accuracy: 0.7459\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.0623e-05 - accuracy: 1.0000 - val_loss: 4.9104 - val_accuracy: 0.7459\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 9.6908e-06 - accuracy: 1.0000 - val_loss: 4.9219 - val_accuracy: 0.7459\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.2661e-05 - accuracy: 1.0000 - val_loss: 4.9466 - val_accuracy: 0.7459\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.9425e-06 - accuracy: 1.0000 - val_loss: 4.9654 - val_accuracy: 0.7459\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 8.1782e-06 - accuracy: 1.0000 - val_loss: 4.9774 - val_accuracy: 0.7459\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 9.4834e-06 - accuracy: 1.0000 - val_loss: 4.9982 - val_accuracy: 0.7459\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.6571e-06 - accuracy: 1.0000 - val_loss: 5.0101 - val_accuracy: 0.7459\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 8.5550e-06 - accuracy: 1.0000 - val_loss: 5.0250 - val_accuracy: 0.7459\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.3160e-06 - accuracy: 1.0000 - val_loss: 5.0401 - val_accuracy: 0.7459\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 7.3264e-06 - accuracy: 1.0000 - val_loss: 5.0564 - val_accuracy: 0.7459\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.4991e-06 - accuracy: 1.0000 - val_loss: 5.0728 - val_accuracy: 0.7459\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 7.6571e-06 - accuracy: 1.0000 - val_loss: 5.0885 - val_accuracy: 0.7459\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.2026e-06 - accuracy: 1.0000 - val_loss: 5.1062 - val_accuracy: 0.7459\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.0598e-06 - accuracy: 1.0000 - val_loss: 5.1187 - val_accuracy: 0.7459\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.0844e-06 - accuracy: 1.0000 - val_loss: 5.1339 - val_accuracy: 0.7459\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.6341e-06 - accuracy: 1.0000 - val_loss: 5.1473 - val_accuracy: 0.7459\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.1292e-06 - accuracy: 1.0000 - val_loss: 5.1621 - val_accuracy: 0.7459\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.7572e-06 - accuracy: 1.0000 - val_loss: 5.1763 - val_accuracy: 0.7459\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 4.5792e-06 - accuracy: 1.0000 - val_loss: 5.1933 - val_accuracy: 0.7459\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 4.4764e-06 - accuracy: 1.0000 - val_loss: 5.2081 - val_accuracy: 0.7459\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.0465e-06 - accuracy: 1.0000 - val_loss: 5.2214 - val_accuracy: 0.7459\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.8330e-06 - accuracy: 1.0000 - val_loss: 5.2388 - val_accuracy: 0.7459\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 4.1784e-06 - accuracy: 1.0000 - val_loss: 5.2555 - val_accuracy: 0.7459\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 4.0789e-06 - accuracy: 1.0000 - val_loss: 5.2742 - val_accuracy: 0.7459\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.7777e-06 - accuracy: 1.0000 - val_loss: 5.2858 - val_accuracy: 0.7459\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.6707e-06 - accuracy: 1.0000 - val_loss: 5.2981 - val_accuracy: 0.7459\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = GRU(200, return_sequences=True)(input_tensor)   \n",
    "    x = GRU(200, return_sequences=True,dropout=0.5)(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    GRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    GRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_GRU = GRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 10, 400)          2642400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 10, 400)          722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               400100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,765,910\n",
      "Trainable params: 3,765,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 21ms/step - loss: 2.2883 - accuracy: 0.1372 - val_loss: 2.2042 - val_accuracy: 0.2424\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9371 - accuracy: 0.3476 - val_loss: 1.7818 - val_accuracy: 0.4447\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2962 - accuracy: 0.5949 - val_loss: 1.5310 - val_accuracy: 0.5459\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8062 - accuracy: 0.7513 - val_loss: 1.4485 - val_accuracy: 0.6282\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5629 - accuracy: 0.8219 - val_loss: 1.4993 - val_accuracy: 0.6729\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3312 - accuracy: 0.8900 - val_loss: 1.6904 - val_accuracy: 0.6706\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2509 - accuracy: 0.9173 - val_loss: 1.6499 - val_accuracy: 0.7247\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9652 - val_loss: 2.0197 - val_accuracy: 0.7271\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1268 - accuracy: 0.9566 - val_loss: 1.9609 - val_accuracy: 0.7294\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1151 - accuracy: 0.9632 - val_loss: 2.2374 - val_accuracy: 0.7153\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0834 - accuracy: 0.9717 - val_loss: 2.2829 - val_accuracy: 0.7388\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0951 - accuracy: 0.9682 - val_loss: 2.1076 - val_accuracy: 0.7435\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 2.1748 - val_accuracy: 0.7459\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0456 - accuracy: 0.9834 - val_loss: 2.6318 - val_accuracy: 0.7412\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0862 - accuracy: 0.9697 - val_loss: 2.2824 - val_accuracy: 0.7294\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 0.9788 - val_loss: 2.1160 - val_accuracy: 0.7624\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0582 - accuracy: 0.9818 - val_loss: 2.4742 - val_accuracy: 0.7271\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1017 - accuracy: 0.9667 - val_loss: 2.0279 - val_accuracy: 0.7506\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0343 - accuracy: 0.9914 - val_loss: 1.9372 - val_accuracy: 0.7647\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 2.0759 - val_accuracy: 0.7671\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 2.1298 - val_accuracy: 0.7506\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1748 - val_accuracy: 0.7482\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.1236e-04 - accuracy: 1.0000 - val_loss: 2.1878 - val_accuracy: 0.7529\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9626e-04 - accuracy: 1.0000 - val_loss: 2.2085 - val_accuracy: 0.7576\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7004e-04 - accuracy: 1.0000 - val_loss: 2.2270 - val_accuracy: 0.7576\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.2442e-04 - accuracy: 1.0000 - val_loss: 2.2493 - val_accuracy: 0.7600\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.9425e-04 - accuracy: 1.0000 - val_loss: 2.2682 - val_accuracy: 0.7576\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.7207e-04 - accuracy: 1.0000 - val_loss: 2.2849 - val_accuracy: 0.7600\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.5991e-04 - accuracy: 1.0000 - val_loss: 2.3027 - val_accuracy: 0.7600\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3558e-04 - accuracy: 1.0000 - val_loss: 2.3185 - val_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2300e-04 - accuracy: 1.0000 - val_loss: 2.3320 - val_accuracy: 0.7600\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0693e-04 - accuracy: 1.0000 - val_loss: 2.3440 - val_accuracy: 0.7600\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.4539e-05 - accuracy: 1.0000 - val_loss: 2.3582 - val_accuracy: 0.7600\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.9795e-05 - accuracy: 1.0000 - val_loss: 2.3738 - val_accuracy: 0.7600\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.9955e-05 - accuracy: 1.0000 - val_loss: 2.3863 - val_accuracy: 0.7600\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.6062e-05 - accuracy: 1.0000 - val_loss: 2.4008 - val_accuracy: 0.7600\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 7.7339e-05 - accuracy: 1.0000 - val_loss: 2.4145 - val_accuracy: 0.7600\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.7743e-05 - accuracy: 1.0000 - val_loss: 2.4277 - val_accuracy: 0.7600\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.6451e-05 - accuracy: 1.0000 - val_loss: 2.4440 - val_accuracy: 0.7600\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.1597e-05 - accuracy: 1.0000 - val_loss: 2.4534 - val_accuracy: 0.7600\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.6114e-05 - accuracy: 1.0000 - val_loss: 2.4669 - val_accuracy: 0.7600\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.0139e-05 - accuracy: 1.0000 - val_loss: 2.4780 - val_accuracy: 0.7600\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1820e-05 - accuracy: 1.0000 - val_loss: 2.4889 - val_accuracy: 0.7624\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.6364e-05 - accuracy: 1.0000 - val_loss: 2.4978 - val_accuracy: 0.7624\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.3694e-05 - accuracy: 1.0000 - val_loss: 2.5084 - val_accuracy: 0.7624\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.0282e-05 - accuracy: 1.0000 - val_loss: 2.5199 - val_accuracy: 0.7624\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.0015e-05 - accuracy: 1.0000 - val_loss: 2.5311 - val_accuracy: 0.7624\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.6222e-05 - accuracy: 1.0000 - val_loss: 2.5411 - val_accuracy: 0.7624\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.1280e-05 - accuracy: 1.0000 - val_loss: 2.5508 - val_accuracy: 0.7624\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.2188e-05 - accuracy: 1.0000 - val_loss: 2.5623 - val_accuracy: 0.7600\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.8353e-05 - accuracy: 1.0000 - val_loss: 2.5714 - val_accuracy: 0.7600\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.8521e-05 - accuracy: 1.0000 - val_loss: 2.5804 - val_accuracy: 0.7600\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.9978e-05 - accuracy: 1.0000 - val_loss: 2.5907 - val_accuracy: 0.7624\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.5635e-05 - accuracy: 1.0000 - val_loss: 2.6009 - val_accuracy: 0.7624\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4513e-05 - accuracy: 1.0000 - val_loss: 2.6086 - val_accuracy: 0.7624\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2999e-05 - accuracy: 1.0000 - val_loss: 2.6183 - val_accuracy: 0.7624\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0232e-05 - accuracy: 1.0000 - val_loss: 2.6274 - val_accuracy: 0.7624\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0274e-05 - accuracy: 1.0000 - val_loss: 2.6368 - val_accuracy: 0.7624\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0235e-05 - accuracy: 1.0000 - val_loss: 2.6454 - val_accuracy: 0.7624\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9895e-05 - accuracy: 1.0000 - val_loss: 2.6546 - val_accuracy: 0.7624\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.7185e-05 - accuracy: 1.0000 - val_loss: 2.6644 - val_accuracy: 0.7624\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.7048e-05 - accuracy: 1.0000 - val_loss: 2.6731 - val_accuracy: 0.7624\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6197e-05 - accuracy: 1.0000 - val_loss: 2.6810 - val_accuracy: 0.7624\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4644e-05 - accuracy: 1.0000 - val_loss: 2.6889 - val_accuracy: 0.7624\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5105e-05 - accuracy: 1.0000 - val_loss: 2.6976 - val_accuracy: 0.7624\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4116e-05 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.7624\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4261e-05 - accuracy: 1.0000 - val_loss: 2.7175 - val_accuracy: 0.7624\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3118e-05 - accuracy: 1.0000 - val_loss: 2.7259 - val_accuracy: 0.7624\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1901e-05 - accuracy: 1.0000 - val_loss: 2.7343 - val_accuracy: 0.7624\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0964e-05 - accuracy: 1.0000 - val_loss: 2.7413 - val_accuracy: 0.7624\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0642e-05 - accuracy: 1.0000 - val_loss: 2.7499 - val_accuracy: 0.7647\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0560e-05 - accuracy: 1.0000 - val_loss: 2.7603 - val_accuracy: 0.7647\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.7010e-06 - accuracy: 1.0000 - val_loss: 2.7690 - val_accuracy: 0.7647\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.2553e-06 - accuracy: 1.0000 - val_loss: 2.7771 - val_accuracy: 0.7647\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.1784e-06 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.7647\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.6810e-06 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.7647\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.4393e-06 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.7624\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.0507e-06 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.7647\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 7.6420e-06 - accuracy: 1.0000 - val_loss: 2.8183 - val_accuracy: 0.7647\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 7.5812e-06 - accuracy: 1.0000 - val_loss: 2.8261 - val_accuracy: 0.7624\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 7.3186e-06 - accuracy: 1.0000 - val_loss: 2.8338 - val_accuracy: 0.7647\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.6412e-06 - accuracy: 1.0000 - val_loss: 2.8413 - val_accuracy: 0.7624\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.2857e-06 - accuracy: 1.0000 - val_loss: 2.8484 - val_accuracy: 0.7624\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.9100e-06 - accuracy: 1.0000 - val_loss: 2.8554 - val_accuracy: 0.7624\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.7027e-06 - accuracy: 1.0000 - val_loss: 2.8634 - val_accuracy: 0.7647\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.5639e-06 - accuracy: 1.0000 - val_loss: 2.8708 - val_accuracy: 0.7624\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.4739e-06 - accuracy: 1.0000 - val_loss: 2.8792 - val_accuracy: 0.7624\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1900e-06 - accuracy: 1.0000 - val_loss: 2.8881 - val_accuracy: 0.7624\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.2310e-06 - accuracy: 1.0000 - val_loss: 2.8958 - val_accuracy: 0.7647\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.9836e-06 - accuracy: 1.0000 - val_loss: 2.9032 - val_accuracy: 0.7647\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.5844e-06 - accuracy: 1.0000 - val_loss: 2.9120 - val_accuracy: 0.7647\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.6117e-06 - accuracy: 1.0000 - val_loss: 2.9179 - val_accuracy: 0.7647\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.3099e-06 - accuracy: 1.0000 - val_loss: 2.9254 - val_accuracy: 0.7624\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.0271e-06 - accuracy: 1.0000 - val_loss: 2.9339 - val_accuracy: 0.7624\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.9247e-06 - accuracy: 1.0000 - val_loss: 2.9425 - val_accuracy: 0.7624\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.7282e-06 - accuracy: 1.0000 - val_loss: 2.9502 - val_accuracy: 0.7624\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.4719e-06 - accuracy: 1.0000 - val_loss: 2.9578 - val_accuracy: 0.7624\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4575e-06 - accuracy: 1.0000 - val_loss: 2.9644 - val_accuracy: 0.7647\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8368e-06 - accuracy: 1.0000 - val_loss: 2.9705 - val_accuracy: 0.7647\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.0125e-06 - accuracy: 1.0000 - val_loss: 2.9782 - val_accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(input_tensor)   \n",
    "    x = Bidirectional(GRU(200, return_sequences=True,dropout=0.5))(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    BiGRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_BiGRU = BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN-biGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 2000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 128)           768128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,035,478\n",
      "Trainable params: 2,035,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 21ms/step - loss: 2.2884 - accuracy: 0.1115 - val_loss: 2.1775 - val_accuracy: 0.1506\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9693 - accuracy: 0.2402 - val_loss: 1.7258 - val_accuracy: 0.3129\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3875 - accuracy: 0.4702 - val_loss: 1.4943 - val_accuracy: 0.4894\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9485 - accuracy: 0.6292 - val_loss: 1.1916 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6096 - accuracy: 0.7659 - val_loss: 1.2696 - val_accuracy: 0.6541\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4270 - accuracy: 0.8613 - val_loss: 1.2211 - val_accuracy: 0.7200\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2620 - accuracy: 0.9147 - val_loss: 1.4600 - val_accuracy: 0.6941\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2180 - accuracy: 0.9268 - val_loss: 1.3424 - val_accuracy: 0.7412\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1437 - accuracy: 0.9571 - val_loss: 1.3517 - val_accuracy: 0.7718\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0851 - accuracy: 0.9758 - val_loss: 1.5447 - val_accuracy: 0.7647\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1193 - accuracy: 0.9652 - val_loss: 1.5595 - val_accuracy: 0.7576\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1019 - accuracy: 0.9728 - val_loss: 1.3924 - val_accuracy: 0.7882\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0662 - accuracy: 0.9803 - val_loss: 1.5495 - val_accuracy: 0.7671\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1173 - accuracy: 0.9617 - val_loss: 1.4702 - val_accuracy: 0.7576\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1114 - accuracy: 0.9596 - val_loss: 1.4624 - val_accuracy: 0.7624\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0561 - accuracy: 0.9849 - val_loss: 1.6125 - val_accuracy: 0.7718\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 1.8542 - val_accuracy: 0.7624\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0367 - accuracy: 0.9909 - val_loss: 1.7841 - val_accuracy: 0.7882\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0417 - accuracy: 0.9849 - val_loss: 1.5746 - val_accuracy: 0.7906\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0934 - accuracy: 0.9717 - val_loss: 1.6773 - val_accuracy: 0.7600\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0985 - accuracy: 0.9702 - val_loss: 1.3141 - val_accuracy: 0.7835\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0382 - accuracy: 0.9904 - val_loss: 1.7263 - val_accuracy: 0.7812\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0780 - accuracy: 0.9813 - val_loss: 1.5586 - val_accuracy: 0.7694\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0606 - accuracy: 0.9808 - val_loss: 1.4458 - val_accuracy: 0.7953\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0323 - accuracy: 0.9919 - val_loss: 1.6003 - val_accuracy: 0.7929\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 1.6614 - val_accuracy: 0.7906\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 1.5411 - val_accuracy: 0.8024\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 1.7487 - val_accuracy: 0.7906\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.7492 - val_accuracy: 0.7929\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 1.7079 - val_accuracy: 0.7976\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.5763e-04 - accuracy: 1.0000 - val_loss: 1.7313 - val_accuracy: 0.7953\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.6516e-04 - accuracy: 1.0000 - val_loss: 1.7645 - val_accuracy: 0.8024\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2297e-04 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.8024\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.6908e-04 - accuracy: 1.0000 - val_loss: 1.8347 - val_accuracy: 0.8024\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4996e-04 - accuracy: 1.0000 - val_loss: 1.8611 - val_accuracy: 0.7976\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2251e-04 - accuracy: 1.0000 - val_loss: 1.8773 - val_accuracy: 0.7976\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0676e-04 - accuracy: 1.0000 - val_loss: 1.8582 - val_accuracy: 0.8024\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2872e-04 - accuracy: 1.0000 - val_loss: 1.8952 - val_accuracy: 0.7976\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2458e-04 - accuracy: 1.0000 - val_loss: 1.9115 - val_accuracy: 0.7953\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1966e-04 - accuracy: 1.0000 - val_loss: 1.9027 - val_accuracy: 0.7929\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.1252e-04 - accuracy: 1.0000 - val_loss: 1.8439 - val_accuracy: 0.8047\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 9.5308e-05 - accuracy: 1.0000 - val_loss: 1.8721 - val_accuracy: 0.8047\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.4913e-04 - accuracy: 1.0000 - val_loss: 1.9638 - val_accuracy: 0.7976\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.4210e-04 - accuracy: 1.0000 - val_loss: 1.9268 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 7.0259e-05 - accuracy: 1.0000 - val_loss: 1.9459 - val_accuracy: 0.8024\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 7.1783e-05 - accuracy: 1.0000 - val_loss: 1.9772 - val_accuracy: 0.7976\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.9449e-05 - accuracy: 1.0000 - val_loss: 1.9903 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.4329e-05 - accuracy: 1.0000 - val_loss: 2.0094 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.7873e-05 - accuracy: 1.0000 - val_loss: 2.0177 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.3035e-05 - accuracy: 1.0000 - val_loss: 2.0431 - val_accuracy: 0.8047\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.4087e-05 - accuracy: 1.0000 - val_loss: 2.0521 - val_accuracy: 0.8024\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.0681e-05 - accuracy: 1.0000 - val_loss: 2.0584 - val_accuracy: 0.8024\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.2159e-05 - accuracy: 1.0000 - val_loss: 2.0508 - val_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7707e-05 - accuracy: 1.0000 - val_loss: 2.0631 - val_accuracy: 0.8000\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.2141e-05 - accuracy: 1.0000 - val_loss: 2.0558 - val_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.4465e-05 - accuracy: 1.0000 - val_loss: 2.0756 - val_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6497e-05 - accuracy: 1.0000 - val_loss: 2.1035 - val_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.2863e-05 - accuracy: 1.0000 - val_loss: 2.1111 - val_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.3968e-05 - accuracy: 1.0000 - val_loss: 2.1308 - val_accuracy: 0.7976\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.0738e-05 - accuracy: 1.0000 - val_loss: 2.1289 - val_accuracy: 0.7976\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.0986e-05 - accuracy: 1.0000 - val_loss: 2.1328 - val_accuracy: 0.8024\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.0682e-05 - accuracy: 1.0000 - val_loss: 2.1430 - val_accuracy: 0.8024\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8713e-05 - accuracy: 1.0000 - val_loss: 2.1634 - val_accuracy: 0.7976\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3777 - accuracy: 0.8885 - val_loss: 1.2500 - val_accuracy: 0.6800\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2529 - accuracy: 0.9168 - val_loss: 1.2849 - val_accuracy: 0.7529\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1152 - accuracy: 0.9677 - val_loss: 1.2800 - val_accuracy: 0.7576\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1482 - accuracy: 0.9516 - val_loss: 1.3583 - val_accuracy: 0.7835\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0808 - accuracy: 0.9773 - val_loss: 1.3729 - val_accuracy: 0.7906\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0557 - accuracy: 0.9828 - val_loss: 1.4406 - val_accuracy: 0.7882\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0509 - accuracy: 0.9849 - val_loss: 1.5389 - val_accuracy: 0.7741\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0275 - accuracy: 0.9950 - val_loss: 1.5100 - val_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 1.5040 - val_accuracy: 0.8071\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 1.7048 - val_accuracy: 0.7906\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 1.6776 - val_accuracy: 0.7929\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0124 - accuracy: 0.9950 - val_loss: 1.7899 - val_accuracy: 0.7976\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.6697 - val_accuracy: 0.8094\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 1.7259 - val_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 0.9975 - val_loss: 1.7850 - val_accuracy: 0.8071\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.7347 - val_accuracy: 0.8047\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.2136e-04 - accuracy: 0.9995 - val_loss: 1.8292 - val_accuracy: 0.8071\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4978e-04 - accuracy: 1.0000 - val_loss: 1.7940 - val_accuracy: 0.8141\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.6030e-04 - accuracy: 1.0000 - val_loss: 1.8115 - val_accuracy: 0.8165\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4139e-04 - accuracy: 1.0000 - val_loss: 1.8050 - val_accuracy: 0.8165\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2220e-04 - accuracy: 1.0000 - val_loss: 1.8085 - val_accuracy: 0.8165\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5054e-04 - accuracy: 1.0000 - val_loss: 1.7849 - val_accuracy: 0.8165\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 1.9058 - val_accuracy: 0.8141\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0695e-04 - accuracy: 1.0000 - val_loss: 1.8888 - val_accuracy: 0.8118\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4253e-04 - accuracy: 1.0000 - val_loss: 1.8893 - val_accuracy: 0.8188\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0362e-04 - accuracy: 1.0000 - val_loss: 1.8857 - val_accuracy: 0.8141\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.7362e-05 - accuracy: 1.0000 - val_loss: 1.8987 - val_accuracy: 0.8141\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.5258e-05 - accuracy: 1.0000 - val_loss: 1.9158 - val_accuracy: 0.8165\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.1388e-04 - accuracy: 1.0000 - val_loss: 1.9017 - val_accuracy: 0.8094\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.4313e-05 - accuracy: 1.0000 - val_loss: 2.0179 - val_accuracy: 0.8165\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0613e-04 - accuracy: 1.0000 - val_loss: 2.0131 - val_accuracy: 0.8141\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.0766e-05 - accuracy: 1.0000 - val_loss: 2.0116 - val_accuracy: 0.8141\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.8474e-05 - accuracy: 1.0000 - val_loss: 1.9980 - val_accuracy: 0.8118\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.5267e-05 - accuracy: 1.0000 - val_loss: 2.0025 - val_accuracy: 0.8141\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3481e-04 - accuracy: 1.0000 - val_loss: 2.0124 - val_accuracy: 0.8165\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1252e-04 - accuracy: 1.0000 - val_loss: 2.0340 - val_accuracy: 0.8212\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.8661e-04 - accuracy: 1.0000 - val_loss: 2.0179 - val_accuracy: 0.8165\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_CNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_BiGRU_model = build_CNN_BiGRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_DCNN_BiGRU = DCNN_BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_2d = reshaped_data.reshape(-1, reshaped_data.shape[2])  # (1000 * 10, 2000)\n",
    "\n",
    "# # Áp dụng PCA để giảm số timesteps từ 2000 xuống 500\n",
    "# n_components = 1000\n",
    "# pca = PCA(n_components=n_components)\n",
    "# X_2d_reduced = pca.fit_transform(X_2d)  # (1000 * 10, 500)\n",
    "\n",
    "# # Chuyển lại thành dạng 3D\n",
    "# X_reduced = X_2d_reduced.reshape(reshaped_data.shape[0], reshaped_data.shape[1], n_components)  # (1000, 10, 500)\n",
    "# print(\"Kích thước dữ liệu sau PCA:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('pca_data.npy', X_reduced)\n",
    "pca_data = np.load('pca_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(1982, 10, 1000)\n",
      "y_train's shape:(1982,)\n",
      "X_test's shape:(425, 10, 1000)\n",
      "y_test's shape:(425,)\n",
      "X_val's shape:(425, 10, 1000)\n",
      "y_val's shape:(425,)\n"
     ]
    }
   ],
   "source": [
    "# input_train = reshaped_data\n",
    "# output_train = reshaped_labels\n",
    "\n",
    "input_train = pca_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train_1, X_temp_1, y_train_1, y_temp_1 = train_test_split(input_train, output_train, test_size=0.3, random_state=42)\n",
    "X_valid_1, X_test_1, y_valid_1, y_test_1 = train_test_split(X_temp_1, y_temp_1, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train_1.shape))\n",
    "print(\"y_train's shape:\" + str(y_train_1.shape))\n",
    "print(\"X_test's shape:\" + str(X_test_1.shape))\n",
    "print(\"y_test's shape:\" + str(y_test_1.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid_1.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 1000)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 10, 128)           384128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 5, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               200100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,651,478\n",
      "Trainable params: 1,651,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 5s 21ms/step - loss: 2.3038 - accuracy: 0.0933 - val_loss: 2.2867 - val_accuracy: 0.1529\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0326 - accuracy: 0.2079 - val_loss: 1.7869 - val_accuracy: 0.2941\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.5203 - accuracy: 0.3905 - val_loss: 1.5718 - val_accuracy: 0.4094\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1638 - accuracy: 0.5434 - val_loss: 1.3995 - val_accuracy: 0.5459\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7023 - accuracy: 0.7321 - val_loss: 1.3220 - val_accuracy: 0.6776\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4684 - accuracy: 0.8360 - val_loss: 1.4692 - val_accuracy: 0.6141\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3213 - accuracy: 0.8850 - val_loss: 1.1944 - val_accuracy: 0.7529\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1623 - accuracy: 0.9420 - val_loss: 1.4678 - val_accuracy: 0.7600\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1631 - accuracy: 0.9450 - val_loss: 1.5651 - val_accuracy: 0.7694\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1382 - accuracy: 0.9586 - val_loss: 1.6975 - val_accuracy: 0.7624\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0931 - accuracy: 0.9728 - val_loss: 1.4811 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0613 - accuracy: 0.9849 - val_loss: 1.3729 - val_accuracy: 0.7835\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0552 - accuracy: 0.9834 - val_loss: 1.5386 - val_accuracy: 0.7882\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0507 - accuracy: 0.9869 - val_loss: 1.6376 - val_accuracy: 0.7929\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0604 - accuracy: 0.9854 - val_loss: 1.7784 - val_accuracy: 0.7906\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1018 - accuracy: 0.9662 - val_loss: 1.6798 - val_accuracy: 0.7576\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1207 - accuracy: 0.9702 - val_loss: 1.5316 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 1.4016 - val_accuracy: 0.8094\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 1.5288 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 1.5686 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 1.6747 - val_accuracy: 0.7906\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9692 - val_loss: 1.5867 - val_accuracy: 0.7694\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9768 - val_loss: 1.6599 - val_accuracy: 0.7482\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0657 - accuracy: 0.9773 - val_loss: 1.2457 - val_accuracy: 0.7953\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 1.3541 - val_accuracy: 0.8024\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 1.9668 - val_accuracy: 0.7600\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 1.6558 - val_accuracy: 0.7976\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 1.5019 - val_accuracy: 0.8165\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7067 - val_accuracy: 0.7976\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 7.1144e-04 - accuracy: 1.0000 - val_loss: 1.6507 - val_accuracy: 0.8188\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.1554e-04 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.8235\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9375e-04 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.8212\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.7618e-04 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.8165\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.4937e-04 - accuracy: 1.0000 - val_loss: 1.7371 - val_accuracy: 0.8165\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.4322e-04 - accuracy: 1.0000 - val_loss: 1.7488 - val_accuracy: 0.8188\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3477e-04 - accuracy: 1.0000 - val_loss: 1.7560 - val_accuracy: 0.8188\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.5000e-04 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.8212\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.3622e-04 - accuracy: 1.0000 - val_loss: 1.7839 - val_accuracy: 0.8118\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 1.7859 - val_accuracy: 0.8165\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.0367e-04 - accuracy: 1.0000 - val_loss: 1.7812 - val_accuracy: 0.8165\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 8.7642e-05 - accuracy: 1.0000 - val_loss: 1.7846 - val_accuracy: 0.8141\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 7.2417e-05 - accuracy: 1.0000 - val_loss: 1.7994 - val_accuracy: 0.8165\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.2475e-04 - accuracy: 1.0000 - val_loss: 1.7826 - val_accuracy: 0.8188\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.4881e-05 - accuracy: 1.0000 - val_loss: 1.7694 - val_accuracy: 0.8212\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.6027e-05 - accuracy: 1.0000 - val_loss: 1.7873 - val_accuracy: 0.8212\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 6.8938e-05 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.8235\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.9624e-05 - accuracy: 1.0000 - val_loss: 1.8222 - val_accuracy: 0.8235\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2608e-04 - accuracy: 1.0000 - val_loss: 1.8240 - val_accuracy: 0.8212\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 8.0115e-05 - accuracy: 1.0000 - val_loss: 1.8071 - val_accuracy: 0.8212\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 6.0889e-05 - accuracy: 1.0000 - val_loss: 1.8345 - val_accuracy: 0.8235\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 8.2102e-05 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.8188\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 7.0074e-05 - accuracy: 1.0000 - val_loss: 1.8903 - val_accuracy: 0.8188\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.7572e-05 - accuracy: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.8165\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1069e-05 - accuracy: 1.0000 - val_loss: 1.8853 - val_accuracy: 0.8165\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.4670e-05 - accuracy: 1.0000 - val_loss: 1.8328 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 7.6276e-04 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.8165\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0477 - accuracy: 0.9859 - val_loss: 2.7334 - val_accuracy: 0.6988\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5303 - accuracy: 0.8517 - val_loss: 1.1481 - val_accuracy: 0.7435\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1404 - accuracy: 0.9637 - val_loss: 1.0223 - val_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0621 - accuracy: 0.9854 - val_loss: 1.1962 - val_accuracy: 0.8024\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0364 - accuracy: 0.9904 - val_loss: 1.5371 - val_accuracy: 0.7859\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 1.1757 - val_accuracy: 0.7976\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 1.2555 - val_accuracy: 0.8188\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.3256 - val_accuracy: 0.8118\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.4127 - val_accuracy: 0.8094\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9955 - val_loss: 1.2834 - val_accuracy: 0.8188\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 1.2591 - val_accuracy: 0.8212\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 1.2869 - val_accuracy: 0.8235\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 1.4793 - val_accuracy: 0.8165\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 1.5010 - val_accuracy: 0.8094\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 1.5220 - val_accuracy: 0.8282\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0391 - accuracy: 0.9914 - val_loss: 1.4956 - val_accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0490 - accuracy: 0.9899 - val_loss: 1.4106 - val_accuracy: 0.7835\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 1.1676 - val_accuracy: 0.8141\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0203 - accuracy: 0.9955 - val_loss: 1.0743 - val_accuracy: 0.8235\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 1.2428 - val_accuracy: 0.8188\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9985 - val_loss: 1.3396 - val_accuracy: 0.8141\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 1.4900 - val_accuracy: 0.8094\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.3601 - val_accuracy: 0.8118\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 1.5542 - val_accuracy: 0.7953\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 1.4888 - val_accuracy: 0.8282\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 1.6408 - val_accuracy: 0.7882\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 1.3781 - val_accuracy: 0.8094\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 1.5268 - val_accuracy: 0.7976\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 1.4402 - val_accuracy: 0.8071\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9960 - val_loss: 1.2013 - val_accuracy: 0.8259\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 1.7189 - val_accuracy: 0.7882\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0339 - accuracy: 0.9919 - val_loss: 1.5559 - val_accuracy: 0.8118\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0449 - accuracy: 0.9909 - val_loss: 1.5062 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9899 - val_loss: 1.8519 - val_accuracy: 0.7929\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 2.1009 - val_accuracy: 0.7741\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 1.4437 - val_accuracy: 0.8306\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.8767 - val_accuracy: 0.8024\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 1.6523 - val_accuracy: 0.8094\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 1.8977 - val_accuracy: 0.7976\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 1.5276 - val_accuracy: 0.8235\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 1.5816 - val_accuracy: 0.8259\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.1267e-04 - accuracy: 1.0000 - val_loss: 1.5244 - val_accuracy: 0.8376\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.2094e-04 - accuracy: 1.0000 - val_loss: 1.6058 - val_accuracy: 0.8212\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0519e-04 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.8282\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_PCA_1DCNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    PCA_DCNN_BiGRU_model = build_PCA_1DCNN_BiGRU_model((X_train_1.shape[1], X_train_1.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    PCA_DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_PCA_DCNN_BiGRU = PCA_DCNN_BiGRU_model.fit(X_train_1, y_train_1, batch_size=32, epochs=100, validation_data=(X_valid_1, y_valid_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCNN_model.save(f'Model/model_1dcnn.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/1dcnn_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_1DCNN.history['accuracy'], \n",
    "#                 'val_accuracy': history_1DCNN.history['val_accuracy'],\n",
    "#                 'train_loss': history_1DCNN.history['loss'],\n",
    "#                 'val_loss': history_1DCNN.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/1dcnn_accuracy.pkl'))\n",
    "\n",
    "# GRU_model.save(f'Model/model_gru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/gru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_GRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_GRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_GRU.history['loss'],\n",
    "#                 'val_loss': history_GRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/gru_accuracy.pkl'))\n",
    "\n",
    "# BiGRU_model.save(f'Model/model_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/bigru_accuracy.pkl'))\n",
    "\n",
    "# DCNN_BiGRU_model.save(f'Model/model_1dcnn_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_DCNN_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_DCNN_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_DCNN_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_DCNN_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/1dcnn_bigru_accuracy.pkl'))\n",
    "\n",
    "# PCA_DCNN_BiGRU_model.save(f'Model/model_pca_1dcnn_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/pca_1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_PCA_DCNN_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_PCA_DCNN_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_PCA_DCNN_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_PCA_DCNN_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/pca_1dcnn_bigru_accuracy.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
