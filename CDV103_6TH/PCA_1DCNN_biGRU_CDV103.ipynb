{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pickle\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, add, LSTM, Dense, Dropout,GRU, Bidirectional, MaxPooling1D\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'Data'\n",
    "\n",
    "# all_data = {}\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.mat'):\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "        \n",
    "#         # Load the .mat file and add its contents to the dictionary\n",
    "#         mat_data = loadmat(filepath)\n",
    "        \n",
    "#         # Use filename (without extension) as key for the data\n",
    "#         key = os.path.splitext(filename)[0]\n",
    "#         row_means = np.mean(mat_data['acceleration'],1)\n",
    "#         rows_2_keep = row_means != 0\n",
    "#         all_data[key] = mat_data['acceleration'][rows_2_keep]\n",
    "        \n",
    "# keys_to_stack = [f'spaceframe{i}' for i in range(1,11)]\n",
    "# input_data = np.stack([all_data[key] for key in keys_to_stack], axis=0)\n",
    "\n",
    "# # Create the corresponding labels\n",
    "# output_labels = np.linspace(0,10,11)  # Using 0 and 1 as class labels for binary cross-entropy\n",
    "# label = output_labels\n",
    "\n",
    "# input_data = input_data[:,:,:15000]\n",
    "# input_data.shape, output_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the data at index (1, 1, :) which has a shape of (8000,)\n",
    "# Data = input_data[1,:, :]\n",
    "# print(Data.shape)\n",
    "# # Create the plot\n",
    "# fig, axes = plt.subplots(12, 1, figsize=(15, 8), sharex=True)\n",
    "\n",
    "# title_font = {'family': 'Times New Roman', 'size': 16, 'weight': 'bold'}\n",
    "# label_font = {'family': 'Times New Roman', 'size': 14}\n",
    "# plt.rcParams['xtick.labelsize'] = 10\n",
    "# plt.rcParams['ytick.labelsize'] = 10\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# # Plot the data for each sub-array\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.plot(Data[i, :], linewidth=1, color = 'b')\n",
    "#     # ax.set_title(f'Z24 Signal Data at Index (1, {i}, :)', fontsize=12)\n",
    "    \n",
    "#     ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     ax.minorticks_on()\n",
    "#     ax.grid(True, which='minor', color='#999999', linestyle='--', alpha=0.2)\n",
    "#     ax.set_xlim(-100, Data.shape[1]+100)\n",
    "# # Set common labels using axes\n",
    "# axes[-1].set_xlabel('Điểm dữ liệu', fontsize=14, fontdict=label_font)\n",
    "# axes[0].set_title('Dữ liệu Khung không gian', fontsize=16, fontdict=title_font)\n",
    "\n",
    "# # Create a \"super\" axis for the common Y-label and make it invisible\n",
    "# super_ax = fig.add_subplot(111, frame_on=False)\n",
    "# plt.tick_params(labelcolor=\"none\", bottom=False, left=False)\n",
    "# super_ax.set_ylabel(\"Giá trị\", fontsize=14, labelpad=15, fontdict=label_font)\n",
    "\n",
    "# # Move the super axis ylabel to avoid overlap with subplots\n",
    "# super_ax.yaxis.set_label_coords(-0.06,0.5)\n",
    "\n",
    "# # Adjust the layout so that plots do not overlap\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 8, 200000)\n"
     ]
    }
   ],
   "source": [
    "input_data = np.load('data_cdv103a3.npy')\n",
    "print(input_data.shape)\n",
    "output_labels = np.linspace(0,5,6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid shape: (8, 43543)\n",
      "Invalid shape: (8, 98615)\n",
      "Invalid shape: (8, 51747)\n",
      "Invalid shape: (8, 131748)\n",
      "Invalid shape: (8, 15884)\n",
      "Invalid shape: (8, 34168)\n",
      "Invalid shape: (8, 87405)\n",
      "Invalid shape: (8, 108582)\n",
      "Invalid shape: (8, 66793)\n",
      "Invalid shape: (8, 83522)\n",
      "Invalid shape: (8, 39936)\n",
      "Invalid shape: (8, 51592)\n",
      "Invalid shape: (8, 64584)\n",
      "Invalid shape: (8, 146962)\n",
      "Invalid shape: (8, 43883)\n",
      "Invalid shape: (8, 18329)\n",
      "Invalid shape: (8, 67760)\n",
      "Invalid shape: (8, 58071)\n",
      "Invalid shape: (8, 78993)\n",
      "Invalid shape: (8, 117073)\n",
      "Invalid shape: (8, 104236)\n",
      "Invalid shape: (8, 19738)\n",
      "Invalid shape: (8, 82070)\n",
      "Invalid shape: (8, 33170)\n",
      "Invalid shape: (8, 69966)\n",
      "Invalid shape: (8, 52822)\n",
      "Invalid shape: (8, 48341)\n",
      "Invalid shape: (8, 17721)\n",
      "Invalid shape: (8, 47771)\n",
      "Invalid shape: (8, 148651)\n",
      "Invalid shape: (8, 167832)\n",
      "Invalid shape: (8, 2697)\n",
      "Invalid shape: (8, 160057)\n",
      "Invalid shape: (8, 33771)\n",
      "Invalid shape: (8, 123200)\n",
      "Invalid shape: (8, 102568)\n",
      "Invalid shape: (8, 99320)\n",
      "Invalid shape: (8, 80282)\n",
      "Invalid shape: (8, 64087)\n",
      "Invalid shape: (8, 175685)\n",
      "Invalid shape: (8, 40737)\n",
      "Invalid shape: (8, 141638)\n",
      "Invalid shape: (8, 22083)\n",
      "Invalid shape: (8, 125434)\n",
      "Invalid shape: (8, 80172)\n",
      "Invalid shape: (8, 36263)\n",
      "Invalid shape: (8, 12881)\n",
      "Invalid shape: (8, 84387)\n",
      "Tất cả các mảng có kích thước giống nhau.\n",
      "(252, 8, 200000) (252,)\n"
     ]
    }
   ],
   "source": [
    "def check_for_different_shapes(arrays):\n",
    "    \"\"\"\n",
    "    Kiểm tra xem các mảng trong danh sách có kích thước không đồng nhất không.\n",
    "\n",
    "    Parameters:\n",
    "        arrays (list): Danh sách các mảng NumPy.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách các mảng không đồng nhất.\n",
    "    \"\"\"\n",
    "    inhomogeneous_arrays = []\n",
    "    expected_shape = None\n",
    "    for array in arrays:\n",
    "        if expected_shape is None:\n",
    "            expected_shape = array.shape\n",
    "        elif array.shape != expected_shape:\n",
    "            inhomogeneous_arrays.append(array)\n",
    "    return inhomogeneous_arrays\n",
    "\n",
    "def augment_time_series_data(input_data, labels, num_augmentations=5):\n",
    "    \"\"\"\n",
    "    Augment time series data.\n",
    "\n",
    "    :param input_data: Original time series data array.\n",
    "    :param labels: Corresponding labels for the data.\n",
    "    :param num_augmentations: Number of augmented samples to generate per original sample.\n",
    "\n",
    "    :return: Augmented data array and corresponding labels.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    num_samples, num_channels, sequence_length = input_data.shape\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for _ in range(num_augmentations):\n",
    "            # Choose a random augmentation technique\n",
    "            augmentation_type = random.choices(['noise', 'reverse', 'crop_pad', 'time_warp', 'random_shift'],\n",
    "                                               weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n",
    "\n",
    "            if augmentation_type == 'noise':\n",
    "                # Add random noise\n",
    "                noise = np.random.normal(0, 0.00005, input_data[i].shape)\n",
    "                augmented_sample = input_data[i] + noise\n",
    "\n",
    "            elif augmentation_type == 'reverse':\n",
    "                # Reverse the sequence\n",
    "                augmented_sample = np.flip(input_data[i], axis=-1)\n",
    "\n",
    "            elif augmentation_type == 'crop_pad':\n",
    "                # Crop and pad the sequence\n",
    "                crop_size = random.randint(1, sequence_length // 100)\n",
    "                padded_sample = np.pad(input_data[i], ((0, 0), (crop_size, 0)), mode='constant', constant_values=0)\n",
    "                augmented_sample = padded_sample[:, :-crop_size]\n",
    "\n",
    "            elif augmentation_type == 'time_warp':\n",
    "                # Time warping\n",
    "                start_idx = random.randint(0, sequence_length // 2)\n",
    "                end_idx = random.randint(start_idx, sequence_length)\n",
    "                warped_segment = np.mean(input_data[i][:, start_idx:end_idx], axis=1, keepdims=True)\n",
    "                augmented_sample = np.concatenate((warped_segment, input_data[i][:, end_idx:]), axis=1)\n",
    "\n",
    "            elif augmentation_type == 'random_shift':\n",
    "                # Random shifting\n",
    "                shift_amount = random.randint(-(sequence_length // 10), sequence_length // 10)\n",
    "                augmented_sample = np.roll(input_data[i], shift_amount, axis=-1)\n",
    "\n",
    "            if augmented_sample.shape == (num_channels, sequence_length):\n",
    "                augmented_data.append(augmented_sample)\n",
    "                augmented_labels.append(labels[i])\n",
    "            else:\n",
    "                print(\"Invalid shape:\", augmented_sample.shape)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    # Sử dụng hàm\n",
    "    inhomogeneous_arrays = check_for_different_shapes(augmented_data)\n",
    "    if inhomogeneous_arrays:\n",
    "        print(\"Các mảng không đồng nhất:\")\n",
    "        for array in inhomogeneous_arrays:\n",
    "            print(array.shape)\n",
    "    else:\n",
    "        print(\"Tất cả các mảng có kích thước giống nhau.\")\n",
    "\n",
    "    return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "# Sử dụng hàm\n",
    "augmented_data, augmented_labels = augment_time_series_data(input_data, output_labels, num_augmentations=50)\n",
    "print(augmented_data.shape, augmented_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080, 8, 5000) (10080,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reshape_time_series_data_v8(input_data, label_data, segments_per_new_sample, segment_length):\n",
    "    \"\"\"\n",
    "    Reshape time series data and corresponding labels into a specified shape.\n",
    "\n",
    "    :param input_data: Original time series data array.\n",
    "    :param label_data: Corresponding labels for the data.\n",
    "    :param segments_per_new_sample: Number of segments per new sample.\n",
    "    :param segment_length: Length of each segment.\n",
    "\n",
    "    :return: Reshaped data array and corresponding labels.\n",
    "    \"\"\"\n",
    "    num_samples_original, num_channels, length_original = input_data.shape\n",
    "\n",
    "    # Validate the feasibility of reshaping\n",
    "    if length_original % segment_length != 0:\n",
    "        raise ValueError(\"Segment length must evenly divide the original length.\")\n",
    "\n",
    "    total_segments_per_original_sample = (length_original // segment_length) * num_channels\n",
    "    num_samples_new = (num_samples_original * total_segments_per_original_sample) // segments_per_new_sample\n",
    "\n",
    "    # Validate if reshaping is possible\n",
    "    if (num_samples_original * total_segments_per_original_sample) % segments_per_new_sample != 0:\n",
    "        raise ValueError(\"Reshaping not possible with the given dimensions.\")\n",
    "\n",
    "    # Initialize reshaped data and labels\n",
    "    new_shape = (num_samples_new, segments_per_new_sample, segment_length)\n",
    "    reshaped_data = np.zeros(new_shape)\n",
    "    reshaped_labels = np.zeros(num_samples_new)\n",
    "\n",
    "    # Reshape the data and labels\n",
    "    count = 0\n",
    "    for i in range(num_samples_original):\n",
    "        segment_count = 0\n",
    "        for j in range(num_channels):\n",
    "            for k in range(length_original // segment_length):\n",
    "                start_idx = k * segment_length\n",
    "                end_idx = start_idx + segment_length\n",
    "                reshaped_data[count, segment_count % segments_per_new_sample, :] = input_data[i, j, start_idx:end_idx]\n",
    "                if (segment_count + 1) % segments_per_new_sample == 0:\n",
    "                    reshaped_labels[count] = label_data[i]  # Assign corresponding label\n",
    "                    count += 1\n",
    "                segment_count += 1\n",
    "\n",
    "    return reshaped_data, reshaped_labels\n",
    "\n",
    "# Example usage\n",
    "segments_per_new_sample = 8\n",
    "segment_length = 5000\n",
    "\n",
    "# Assume 'augmented_data' and 'augmented_labels' are your input data and labels\n",
    "reshaped_data, reshaped_labels = reshape_time_series_data_v8(augmented_data, augmented_labels, segments_per_new_sample, segment_length)\n",
    "print(reshaped_data.shape, reshaped_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('reshaped_data.npy', reshaped_data)\n",
    "# np.save('reshaped_label.npy', reshaped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped_data = np.load('reshaped_data.npy')\n",
    "# reshaped_labels = np.load('reshaped_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(7056, 8, 5000)\n",
      "y_train's shape:(7056,)\n",
      "X_test's shape:(1512, 8, 5000)\n",
      "y_test's shape:(1512,)\n",
      "X_val's shape:(1512, 8, 5000)\n",
      "y_val's shape:(1512,)\n"
     ]
    }
   ],
   "source": [
    "input_train = reshaped_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_train, output_train, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train.shape))\n",
    "print(\"y_train's shape:\" + str(y_train.shape))\n",
    "print(\"X_test's shape:\" + str(X_test.shape))\n",
    "print(\"y_test's shape:\" + str(y_test.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = [0. 1. 2. 3. 4. 5.]\n",
      "No. Labels: 6\n"
     ]
    }
   ],
   "source": [
    "label=np.unique(y_train)\n",
    "print('Label = ' + str(label))\n",
    "num_classes = len(np.unique(y_train))\n",
    "print('No. Labels: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 5000)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 8, 256)            1280256   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 256)           1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 256)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4, 256)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 128)            98432     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 128)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 4, 64)             8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 64)            256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,422,406\n",
      "Trainable params: 1,421,510\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "221/221 [==============================] - 3s 10ms/step - loss: 1.4572 - accuracy: 0.3838 - val_loss: 1.8052 - val_accuracy: 0.2249\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 1.2935 - accuracy: 0.4571 - val_loss: 1.5291 - val_accuracy: 0.3545\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 1.2241 - accuracy: 0.4769 - val_loss: 1.1597 - val_accuracy: 0.5324\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 1.1778 - accuracy: 0.5057 - val_loss: 1.6383 - val_accuracy: 0.4226\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 1.1489 - accuracy: 0.5316 - val_loss: 2.4184 - val_accuracy: 0.4458\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 1s 7ms/step - loss: 1.0962 - accuracy: 0.5497 - val_loss: 1.1600 - val_accuracy: 0.5060\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 1.0444 - accuracy: 0.5862 - val_loss: 4.0891 - val_accuracy: 0.3869\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.9734 - accuracy: 0.6098 - val_loss: 3.3934 - val_accuracy: 0.3803\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.8946 - accuracy: 0.6419 - val_loss: 2.4151 - val_accuracy: 0.3862\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.7581 - accuracy: 0.7024 - val_loss: 1.9895 - val_accuracy: 0.4888\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.6517 - accuracy: 0.7544 - val_loss: 3.1975 - val_accuracy: 0.4153\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.5301 - accuracy: 0.8002 - val_loss: 1.8407 - val_accuracy: 0.5397\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.4341 - accuracy: 0.8434 - val_loss: 3.6888 - val_accuracy: 0.4266\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.3405 - accuracy: 0.8825 - val_loss: 3.6126 - val_accuracy: 0.4425\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.2598 - accuracy: 0.9099 - val_loss: 2.7149 - val_accuracy: 0.4974\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.2071 - accuracy: 0.9260 - val_loss: 4.0558 - val_accuracy: 0.4425\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.1740 - accuracy: 0.9452 - val_loss: 3.3616 - val_accuracy: 0.5225\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.1267 - accuracy: 0.9615 - val_loss: 6.4528 - val_accuracy: 0.4299\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0944 - accuracy: 0.9697 - val_loss: 1.7642 - val_accuracy: 0.6217\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9728 - val_loss: 2.4055 - val_accuracy: 0.5906\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9719 - val_loss: 1.5658 - val_accuracy: 0.6554\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0606 - accuracy: 0.9814 - val_loss: 4.9609 - val_accuracy: 0.4709\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0615 - accuracy: 0.9814 - val_loss: 4.6591 - val_accuracy: 0.4689\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 0.8947 - val_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0498 - accuracy: 0.9857 - val_loss: 4.3264 - val_accuracy: 0.5165\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0462 - accuracy: 0.9872 - val_loss: 0.9510 - val_accuracy: 0.7798\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9875 - val_loss: 7.4075 - val_accuracy: 0.4702\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 2.1294 - val_accuracy: 0.5787\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 2.6663 - val_accuracy: 0.6151\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 2.8125 - val_accuracy: 0.5661\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 1.0389 - val_accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 5.0209 - val_accuracy: 0.5470\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0643 - accuracy: 0.9812 - val_loss: 4.0467 - val_accuracy: 0.5384\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9864 - val_loss: 11.7701 - val_accuracy: 0.4061\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0512 - accuracy: 0.9853 - val_loss: 5.2829 - val_accuracy: 0.4755\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 1.6247 - val_accuracy: 0.6627\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.4697 - val_accuracy: 0.7566\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.8654 - val_accuracy: 0.7751\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 2.8257 - val_accuracy: 0.5899\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 1.2369 - val_accuracy: 0.7235\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.8430 - val_accuracy: 0.8089\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 1.6123 - val_accuracy: 0.7328\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 2.0863 - val_accuracy: 0.6931\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.8508 - val_accuracy: 0.8247\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 1.3673 - val_accuracy: 0.7189\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 3.3408 - val_accuracy: 0.6409\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0188 - accuracy: 0.9956 - val_loss: 1.6320 - val_accuracy: 0.7513\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 3.3022 - val_accuracy: 0.5099\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.8416 - val_accuracy: 0.8208\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 10.0990 - val_accuracy: 0.4392\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 2.7717 - val_accuracy: 0.5509\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 1.8147 - val_accuracy: 0.6706\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 5.6605 - val_accuracy: 0.5403\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 4.9702 - val_accuracy: 0.5192\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 3.2393 - val_accuracy: 0.6104\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.9801 - val_accuracy: 0.8386\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.1301 - val_accuracy: 0.7937\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 1.1181 - val_accuracy: 0.7844\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 1.4033 - val_accuracy: 0.7328\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 1.3316 - val_accuracy: 0.8042\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 1.0216 - val_accuracy: 0.8175\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9841 - val_loss: 1.2186 - val_accuracy: 0.6700\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0714 - accuracy: 0.9773 - val_loss: 1.4834 - val_accuracy: 0.6746\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.8256 - val_accuracy: 0.8267\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 3.2072 - val_accuracy: 0.6581\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 0.9967 - val_loss: 0.8998 - val_accuracy: 0.8439\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 1.9559 - val_accuracy: 0.7130\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 1.3776 - val_accuracy: 0.8049\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 1.8317 - val_accuracy: 0.6799\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 1.4872 - val_accuracy: 0.7817\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 2.2671 - val_accuracy: 0.7083\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 4.3712 - val_accuracy: 0.5152\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 1.0791 - val_accuracy: 0.8208\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 1.7142 - val_accuracy: 0.7751\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0448 - accuracy: 0.9878 - val_loss: 1.1673 - val_accuracy: 0.7381\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0352 - accuracy: 0.9894 - val_loss: 0.9060 - val_accuracy: 0.8022\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 2.1223 - val_accuracy: 0.7269\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 1.3677 - val_accuracy: 0.8148\n",
      "Epoch 79/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 1.3247 - val_accuracy: 0.7884\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 1.5983 - val_accuracy: 0.7447\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 2.0122 - val_accuracy: 0.7513\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.3056 - val_accuracy: 0.8194\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 1.1835 - val_accuracy: 0.8261\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 8.3988 - val_accuracy: 0.4696\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.9698 - val_accuracy: 0.8280\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 2.8920 - val_accuracy: 0.6614\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 1.2029 - val_accuracy: 0.7467\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9955 - val_loss: 1.9229 - val_accuracy: 0.7718\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.8977 - val_accuracy: 0.7090\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 1.2255 - val_accuracy: 0.8135\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 1.2253 - val_accuracy: 0.7923\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 1.2985 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 1.7873 - val_accuracy: 0.7903\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.9921 - val_accuracy: 0.7586\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 1.3977 - val_accuracy: 0.8280\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 1.3938 - val_accuracy: 0.7983\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 1.8491 - val_accuracy: 0.6905\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 1.2881 - val_accuracy: 0.8181\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 3.3319 - val_accuracy: 0.6720\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 1.9916 - val_accuracy: 0.7639\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_1DCNN_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # 1D-CNN Preprocessing Layers\n",
    "    x = Conv1D(filters=256, kernel_size=1, padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool1D()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=64, kernel_size=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Dense Layers for Classification\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_model = build_1DCNN_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    DCNN_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_1DCNN = DCNN_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 5000)]         0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 8, 200)            3121200   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 8, 200)            241200    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               160100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,523,106\n",
      "Trainable params: 3,523,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "221/221 [==============================] - 4s 10ms/step - loss: 1.7707 - accuracy: 0.2038 - val_loss: 1.7104 - val_accuracy: 0.2685\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.6316 - accuracy: 0.2792 - val_loss: 1.5218 - val_accuracy: 0.3618\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.5373 - accuracy: 0.3308 - val_loss: 1.4969 - val_accuracy: 0.4140\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.4827 - accuracy: 0.3637 - val_loss: 1.4268 - val_accuracy: 0.3896\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.4225 - accuracy: 0.3893 - val_loss: 1.3847 - val_accuracy: 0.4061\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.3895 - accuracy: 0.4107 - val_loss: 1.3817 - val_accuracy: 0.4405\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.3613 - accuracy: 0.4223 - val_loss: 1.3827 - val_accuracy: 0.4173\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.3313 - accuracy: 0.4351 - val_loss: 1.3772 - val_accuracy: 0.4497\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.3218 - accuracy: 0.4486 - val_loss: 1.3547 - val_accuracy: 0.4907\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.2968 - accuracy: 0.4694 - val_loss: 1.3319 - val_accuracy: 0.4722\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.2578 - accuracy: 0.4836 - val_loss: 1.2567 - val_accuracy: 0.5172\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.2125 - accuracy: 0.5183 - val_loss: 1.2779 - val_accuracy: 0.5377\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.1654 - accuracy: 0.5346 - val_loss: 1.3056 - val_accuracy: 0.5470\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.1152 - accuracy: 0.5737 - val_loss: 1.2401 - val_accuracy: 0.5661\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.0670 - accuracy: 0.5952 - val_loss: 1.2544 - val_accuracy: 0.5919\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.9897 - accuracy: 0.6257 - val_loss: 1.1736 - val_accuracy: 0.6197\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.9713 - accuracy: 0.6370 - val_loss: 1.2320 - val_accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.8924 - accuracy: 0.6682 - val_loss: 1.0548 - val_accuracy: 0.6462\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.8504 - accuracy: 0.6817 - val_loss: 1.1551 - val_accuracy: 0.6614\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.8093 - accuracy: 0.6995 - val_loss: 1.1253 - val_accuracy: 0.6753\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7541 - accuracy: 0.7253 - val_loss: 1.1039 - val_accuracy: 0.6700\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7213 - accuracy: 0.7384 - val_loss: 1.3262 - val_accuracy: 0.6746\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7159 - accuracy: 0.7412 - val_loss: 1.0915 - val_accuracy: 0.6693\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6347 - accuracy: 0.7698 - val_loss: 1.1160 - val_accuracy: 0.6905\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5923 - accuracy: 0.7812 - val_loss: 1.1253 - val_accuracy: 0.7057\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5899 - accuracy: 0.7901 - val_loss: 1.1008 - val_accuracy: 0.7097\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5419 - accuracy: 0.8158 - val_loss: 1.0380 - val_accuracy: 0.7255\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5177 - accuracy: 0.8183 - val_loss: 0.9862 - val_accuracy: 0.7341\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.4658 - accuracy: 0.8335 - val_loss: 1.0796 - val_accuracy: 0.7315\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.4418 - accuracy: 0.8452 - val_loss: 1.1921 - val_accuracy: 0.7169\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.4314 - accuracy: 0.8522 - val_loss: 1.0449 - val_accuracy: 0.7242\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.4339 - accuracy: 0.8506 - val_loss: 1.0654 - val_accuracy: 0.7354\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.3656 - accuracy: 0.8757 - val_loss: 1.1767 - val_accuracy: 0.7176\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.3872 - accuracy: 0.8665 - val_loss: 1.0604 - val_accuracy: 0.7447\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.3526 - accuracy: 0.8793 - val_loss: 1.1978 - val_accuracy: 0.7507\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.3128 - accuracy: 0.8885 - val_loss: 1.1299 - val_accuracy: 0.7513\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.3056 - accuracy: 0.8933 - val_loss: 1.0763 - val_accuracy: 0.7493\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2913 - accuracy: 0.8981 - val_loss: 1.3638 - val_accuracy: 0.7288\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2683 - accuracy: 0.9048 - val_loss: 1.0530 - val_accuracy: 0.7665\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2327 - accuracy: 0.9196 - val_loss: 1.2029 - val_accuracy: 0.7731\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2505 - accuracy: 0.9147 - val_loss: 1.1306 - val_accuracy: 0.7480\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2573 - accuracy: 0.9154 - val_loss: 1.2575 - val_accuracy: 0.7679\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2278 - accuracy: 0.9255 - val_loss: 1.4846 - val_accuracy: 0.7394\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.2132 - accuracy: 0.9281 - val_loss: 1.2665 - val_accuracy: 0.7705\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1845 - accuracy: 0.9398 - val_loss: 1.3532 - val_accuracy: 0.7646\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1676 - accuracy: 0.9392 - val_loss: 1.4037 - val_accuracy: 0.7751\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1643 - accuracy: 0.9412 - val_loss: 1.3644 - val_accuracy: 0.7738\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1804 - accuracy: 0.9406 - val_loss: 1.3444 - val_accuracy: 0.7705\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1502 - accuracy: 0.9464 - val_loss: 1.2375 - val_accuracy: 0.7698\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1353 - accuracy: 0.9534 - val_loss: 1.4564 - val_accuracy: 0.7738\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1275 - accuracy: 0.9551 - val_loss: 1.3677 - val_accuracy: 0.7599\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1393 - accuracy: 0.9498 - val_loss: 1.6117 - val_accuracy: 0.7685\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1496 - accuracy: 0.9528 - val_loss: 1.7755 - val_accuracy: 0.7599\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1990 - accuracy: 0.9369 - val_loss: 1.5548 - val_accuracy: 0.7837\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1085 - accuracy: 0.9674 - val_loss: 1.4304 - val_accuracy: 0.7798\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1115 - accuracy: 0.9646 - val_loss: 1.6906 - val_accuracy: 0.7553\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0910 - accuracy: 0.9700 - val_loss: 1.8763 - val_accuracy: 0.7646\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0772 - accuracy: 0.9746 - val_loss: 1.7449 - val_accuracy: 0.7771\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0730 - accuracy: 0.9746 - val_loss: 2.0028 - val_accuracy: 0.7619\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1158 - accuracy: 0.9639 - val_loss: 2.1959 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0988 - accuracy: 0.9651 - val_loss: 1.6993 - val_accuracy: 0.7751\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0735 - accuracy: 0.9741 - val_loss: 1.6335 - val_accuracy: 0.7903\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1354 - accuracy: 0.9585 - val_loss: 1.6131 - val_accuracy: 0.7745\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0666 - accuracy: 0.9800 - val_loss: 1.5918 - val_accuracy: 0.7851\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0702 - accuracy: 0.9785 - val_loss: 1.6978 - val_accuracy: 0.7837\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 1.7537 - val_accuracy: 0.7784\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0780 - accuracy: 0.9749 - val_loss: 1.6395 - val_accuracy: 0.7864\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 1.8524 - val_accuracy: 0.7884\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0606 - accuracy: 0.9782 - val_loss: 1.5976 - val_accuracy: 0.7890\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 1.7749 - val_accuracy: 0.7970\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1305 - accuracy: 0.9593 - val_loss: 1.7505 - val_accuracy: 0.7956\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1059 - accuracy: 0.9799 - val_loss: 1.8614 - val_accuracy: 0.7718\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1092 - accuracy: 0.9729 - val_loss: 1.5906 - val_accuracy: 0.7844\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0496 - accuracy: 0.9857 - val_loss: 1.6233 - val_accuracy: 0.7890\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 2.0171 - val_accuracy: 0.7791\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 2.0559 - val_accuracy: 0.7851\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0485 - accuracy: 0.9814 - val_loss: 1.8057 - val_accuracy: 0.7831\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 1.9262 - val_accuracy: 0.7811\n",
      "Epoch 79/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 1.9413 - val_accuracy: 0.7864\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1107 - accuracy: 0.9651 - val_loss: 1.7142 - val_accuracy: 0.7817\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 1.8720 - val_accuracy: 0.7903\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 2.0054 - val_accuracy: 0.7831\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.1121 - accuracy: 0.9637 - val_loss: 2.0203 - val_accuracy: 0.7698\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 1.9743 - val_accuracy: 0.7831\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 2.1657 - val_accuracy: 0.7817\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0692 - accuracy: 0.9793 - val_loss: 2.0998 - val_accuracy: 0.7725\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0897 - accuracy: 0.9736 - val_loss: 1.9511 - val_accuracy: 0.7864\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 1.9942 - val_accuracy: 0.8069\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0609 - accuracy: 0.9899 - val_loss: 2.0307 - val_accuracy: 0.7963\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0398 - accuracy: 0.9882 - val_loss: 1.9625 - val_accuracy: 0.7811\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0942 - accuracy: 0.9793 - val_loss: 1.8307 - val_accuracy: 0.7970\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 1.9428 - val_accuracy: 0.7970\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 1.9159 - val_accuracy: 0.8003\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0322 - accuracy: 0.9922 - val_loss: 2.1407 - val_accuracy: 0.7976\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0708 - accuracy: 0.9780 - val_loss: 1.9535 - val_accuracy: 0.7923\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 1.9873 - val_accuracy: 0.7943\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 2.1643 - val_accuracy: 0.7897\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 2.0301 - val_accuracy: 0.7771\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0555 - accuracy: 0.9812 - val_loss: 1.9215 - val_accuracy: 0.7943\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 2.0901 - val_accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = GRU(200, return_sequences=True)(input_tensor)   \n",
    "    x = GRU(200, return_sequences=True,dropout=0.5)(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    GRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    GRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_GRU = GRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 5000)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 8, 400)           6242400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 8, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               320100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,285,506\n",
      "Trainable params: 7,285,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "221/221 [==============================] - 8s 18ms/step - loss: 1.7683 - accuracy: 0.2170 - val_loss: 1.7134 - val_accuracy: 0.2493\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.6186 - accuracy: 0.2895 - val_loss: 1.5138 - val_accuracy: 0.3386\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.5212 - accuracy: 0.3410 - val_loss: 1.4572 - val_accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.4528 - accuracy: 0.3716 - val_loss: 1.4138 - val_accuracy: 0.3948\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.4094 - accuracy: 0.3872 - val_loss: 1.4022 - val_accuracy: 0.4001\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.3814 - accuracy: 0.4056 - val_loss: 1.4001 - val_accuracy: 0.4425\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.3504 - accuracy: 0.4243 - val_loss: 1.3694 - val_accuracy: 0.4881\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.3175 - accuracy: 0.4508 - val_loss: 1.3452 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.2843 - accuracy: 0.4639 - val_loss: 1.3478 - val_accuracy: 0.4828\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.2299 - accuracy: 0.4957 - val_loss: 1.2694 - val_accuracy: 0.5238\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.1907 - accuracy: 0.5190 - val_loss: 1.2747 - val_accuracy: 0.4987\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.1177 - accuracy: 0.5619 - val_loss: 1.2311 - val_accuracy: 0.5476\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 1.0531 - accuracy: 0.5957 - val_loss: 1.1754 - val_accuracy: 0.5628\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.9682 - accuracy: 0.6400 - val_loss: 1.1860 - val_accuracy: 0.6356\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.8693 - accuracy: 0.6842 - val_loss: 1.1183 - val_accuracy: 0.6567\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.8351 - accuracy: 0.7008 - val_loss: 1.1472 - val_accuracy: 0.6376\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.7529 - accuracy: 0.7306 - val_loss: 1.1818 - val_accuracy: 0.6620\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.6842 - accuracy: 0.7615 - val_loss: 1.0491 - val_accuracy: 0.7183\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.6445 - accuracy: 0.7754 - val_loss: 1.0165 - val_accuracy: 0.7249\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.5969 - accuracy: 0.7949 - val_loss: 0.9023 - val_accuracy: 0.7513\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.5574 - accuracy: 0.8142 - val_loss: 1.0553 - val_accuracy: 0.7255\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.5131 - accuracy: 0.8258 - val_loss: 1.0737 - val_accuracy: 0.7573\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.4777 - accuracy: 0.8399 - val_loss: 1.2555 - val_accuracy: 0.7341\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.4434 - accuracy: 0.8547 - val_loss: 1.0366 - val_accuracy: 0.7533\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.4133 - accuracy: 0.8642 - val_loss: 0.9458 - val_accuracy: 0.7434\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.4096 - accuracy: 0.8661 - val_loss: 0.9723 - val_accuracy: 0.7606\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.3545 - accuracy: 0.8784 - val_loss: 1.0618 - val_accuracy: 0.7718\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.3131 - accuracy: 0.8907 - val_loss: 1.0768 - val_accuracy: 0.7738\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.3425 - accuracy: 0.8900 - val_loss: 0.9666 - val_accuracy: 0.7771\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.3362 - accuracy: 0.8934 - val_loss: 1.1344 - val_accuracy: 0.7560\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.2665 - accuracy: 0.9099 - val_loss: 1.0668 - val_accuracy: 0.7659\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 3s 13ms/step - loss: 0.2427 - accuracy: 0.9188 - val_loss: 1.1751 - val_accuracy: 0.7685\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.2143 - accuracy: 0.9277 - val_loss: 1.2646 - val_accuracy: 0.7507\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.2502 - accuracy: 0.9223 - val_loss: 1.4799 - val_accuracy: 0.7520\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.2662 - accuracy: 0.9199 - val_loss: 1.2129 - val_accuracy: 0.7665\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1896 - accuracy: 0.9393 - val_loss: 1.2546 - val_accuracy: 0.7698\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1624 - accuracy: 0.9480 - val_loss: 1.2952 - val_accuracy: 0.7646\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1560 - accuracy: 0.9454 - val_loss: 1.2033 - val_accuracy: 0.7751\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1675 - accuracy: 0.9436 - val_loss: 1.3045 - val_accuracy: 0.7811\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1627 - accuracy: 0.9454 - val_loss: 1.2719 - val_accuracy: 0.7586\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1260 - accuracy: 0.9589 - val_loss: 1.4422 - val_accuracy: 0.7665\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1310 - accuracy: 0.9571 - val_loss: 1.2847 - val_accuracy: 0.7705\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1307 - accuracy: 0.9585 - val_loss: 1.1627 - val_accuracy: 0.7937\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1206 - accuracy: 0.9607 - val_loss: 1.8068 - val_accuracy: 0.7421\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1313 - accuracy: 0.9592 - val_loss: 1.3883 - val_accuracy: 0.7930\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0993 - accuracy: 0.9681 - val_loss: 1.3461 - val_accuracy: 0.7837\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0745 - accuracy: 0.9755 - val_loss: 1.6212 - val_accuracy: 0.7791\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1330 - accuracy: 0.9569 - val_loss: 1.3624 - val_accuracy: 0.7864\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1062 - accuracy: 0.9709 - val_loss: 1.5136 - val_accuracy: 0.7890\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1284 - accuracy: 0.9607 - val_loss: 1.3212 - val_accuracy: 0.7791\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0800 - accuracy: 0.9712 - val_loss: 1.4343 - val_accuracy: 0.7844\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1363 - accuracy: 0.9612 - val_loss: 1.1197 - val_accuracy: 0.7897\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0644 - accuracy: 0.9814 - val_loss: 1.2580 - val_accuracy: 0.7897\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0607 - accuracy: 0.9831 - val_loss: 1.2289 - val_accuracy: 0.7903\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 3s 13ms/step - loss: 0.0687 - accuracy: 0.9776 - val_loss: 1.3734 - val_accuracy: 0.7784\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 3s 13ms/step - loss: 0.0632 - accuracy: 0.9786 - val_loss: 1.4249 - val_accuracy: 0.7804\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0742 - accuracy: 0.9739 - val_loss: 1.3891 - val_accuracy: 0.7864\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 1.5124 - val_accuracy: 0.7897\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0757 - accuracy: 0.9756 - val_loss: 1.4569 - val_accuracy: 0.8062\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 3s 13ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 1.5555 - val_accuracy: 0.8003\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1162 - accuracy: 0.9623 - val_loss: 1.3962 - val_accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0524 - accuracy: 0.9847 - val_loss: 1.4230 - val_accuracy: 0.7937\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0407 - accuracy: 0.9864 - val_loss: 1.7107 - val_accuracy: 0.7778\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0847 - accuracy: 0.9735 - val_loss: 1.5789 - val_accuracy: 0.7950\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 3s 13ms/step - loss: 0.0646 - accuracy: 0.9772 - val_loss: 1.5477 - val_accuracy: 0.7956\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0759 - accuracy: 0.9785 - val_loss: 1.3712 - val_accuracy: 0.8036\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0407 - accuracy: 0.9894 - val_loss: 1.6191 - val_accuracy: 0.7804\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0659 - accuracy: 0.9789 - val_loss: 1.4422 - val_accuracy: 0.7923\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0446 - accuracy: 0.9858 - val_loss: 1.6655 - val_accuracy: 0.7864\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.1145 - accuracy: 0.9711 - val_loss: 1.7513 - val_accuracy: 0.7255\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0929 - accuracy: 0.9708 - val_loss: 1.3145 - val_accuracy: 0.7983\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 1.5591 - val_accuracy: 0.7884\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0509 - accuracy: 0.9895 - val_loss: 1.6159 - val_accuracy: 0.7917\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0454 - accuracy: 0.9889 - val_loss: 2.0925 - val_accuracy: 0.7632\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0544 - accuracy: 0.9843 - val_loss: 1.6371 - val_accuracy: 0.7870\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 1.5482 - val_accuracy: 0.7943\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 1.5904 - val_accuracy: 0.8042\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0574 - accuracy: 0.9817 - val_loss: 1.6547 - val_accuracy: 0.7639\n",
      "Epoch 79/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0694 - accuracy: 0.9792 - val_loss: 1.6298 - val_accuracy: 0.7903\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 1.5395 - val_accuracy: 0.7970\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 1.7717 - val_accuracy: 0.8003\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 1.7094 - val_accuracy: 0.7884\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0655 - accuracy: 0.9776 - val_loss: 1.5718 - val_accuracy: 0.7970\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0617 - accuracy: 0.9804 - val_loss: 1.5929 - val_accuracy: 0.8029\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 1.8687 - val_accuracy: 0.7837\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 1.6681 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 1.8033 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0466 - accuracy: 0.9840 - val_loss: 1.5242 - val_accuracy: 0.8102\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 1.8514 - val_accuracy: 0.8003\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.8599 - val_accuracy: 0.8056\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0767 - accuracy: 0.9783 - val_loss: 1.7710 - val_accuracy: 0.7798\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0547 - accuracy: 0.9855 - val_loss: 1.6185 - val_accuracy: 0.7817\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0419 - accuracy: 0.9921 - val_loss: 1.3458 - val_accuracy: 0.8102\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 1.4525 - val_accuracy: 0.7970\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 1.7147 - val_accuracy: 0.7996\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.8909 - val_accuracy: 0.7996\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0933 - accuracy: 0.9724 - val_loss: 1.6101 - val_accuracy: 0.7870\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0751 - accuracy: 0.9749 - val_loss: 1.3421 - val_accuracy: 0.8062\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 1.4878 - val_accuracy: 0.8036\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 3s 14ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 1.6071 - val_accuracy: 0.8042\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(input_tensor)   \n",
    "    x = Bidirectional(GRU(200, return_sequences=True,dropout=0.5))(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    BiGRU_model = build_GRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_BiGRU = BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN-biGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 5000)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 8, 128)            1920128   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 64)             8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 64)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 4, 200)            159600    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 4, 200)            241200    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               80100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,409,890\n",
      "Trainable params: 2,409,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "221/221 [==============================] - 4s 10ms/step - loss: 1.6032 - accuracy: 0.2880 - val_loss: 1.4471 - val_accuracy: 0.3598\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.4151 - accuracy: 0.3893 - val_loss: 1.2700 - val_accuracy: 0.4325\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.3173 - accuracy: 0.4372 - val_loss: 1.2413 - val_accuracy: 0.5119\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.2752 - accuracy: 0.4583 - val_loss: 1.1963 - val_accuracy: 0.5212\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 1.1731 - accuracy: 0.4982 - val_loss: 1.0496 - val_accuracy: 0.5503\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 1.0751 - accuracy: 0.5343 - val_loss: 1.0756 - val_accuracy: 0.5562\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.9549 - accuracy: 0.5669 - val_loss: 0.9486 - val_accuracy: 0.5595\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.9084 - accuracy: 0.5792 - val_loss: 0.8300 - val_accuracy: 0.6091\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.8665 - accuracy: 0.5941 - val_loss: 0.8249 - val_accuracy: 0.6151\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.8501 - accuracy: 0.5982 - val_loss: 0.7737 - val_accuracy: 0.6316\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.8506 - accuracy: 0.5928 - val_loss: 0.7453 - val_accuracy: 0.6131\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.8246 - accuracy: 0.6056 - val_loss: 0.7672 - val_accuracy: 0.6329\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.8260 - accuracy: 0.6156 - val_loss: 0.7833 - val_accuracy: 0.6376\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7982 - accuracy: 0.6086 - val_loss: 0.7321 - val_accuracy: 0.6554\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7889 - accuracy: 0.6251 - val_loss: 0.7178 - val_accuracy: 0.6614\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7877 - accuracy: 0.6216 - val_loss: 0.7074 - val_accuracy: 0.6687\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7678 - accuracy: 0.6257 - val_loss: 0.7364 - val_accuracy: 0.6528\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7773 - accuracy: 0.6200 - val_loss: 0.7261 - val_accuracy: 0.6693\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7607 - accuracy: 0.6288 - val_loss: 0.7268 - val_accuracy: 0.6356\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7835 - accuracy: 0.6346 - val_loss: 0.7840 - val_accuracy: 0.6554\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7672 - accuracy: 0.6288 - val_loss: 0.7394 - val_accuracy: 0.6673\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7640 - accuracy: 0.6327 - val_loss: 0.7067 - val_accuracy: 0.6587\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7735 - accuracy: 0.6266 - val_loss: 0.6911 - val_accuracy: 0.6475\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7632 - accuracy: 0.6251 - val_loss: 0.6944 - val_accuracy: 0.6627\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7555 - accuracy: 0.6322 - val_loss: 0.7099 - val_accuracy: 0.6554\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7444 - accuracy: 0.6389 - val_loss: 0.8167 - val_accuracy: 0.6038\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7399 - accuracy: 0.6446 - val_loss: 0.7196 - val_accuracy: 0.6548\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7411 - accuracy: 0.6353 - val_loss: 0.8041 - val_accuracy: 0.6607\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7267 - accuracy: 0.6485 - val_loss: 0.6564 - val_accuracy: 0.6991\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6996 - accuracy: 0.6558 - val_loss: 0.6534 - val_accuracy: 0.6799\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7256 - accuracy: 0.6447 - val_loss: 0.6900 - val_accuracy: 0.6587\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7178 - accuracy: 0.6524 - val_loss: 0.6686 - val_accuracy: 0.6587\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7112 - accuracy: 0.6494 - val_loss: 0.7664 - val_accuracy: 0.5952\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7250 - accuracy: 0.6505 - val_loss: 0.6536 - val_accuracy: 0.6779\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.7214 - accuracy: 0.6514 - val_loss: 0.6322 - val_accuracy: 0.6865\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6990 - accuracy: 0.6613 - val_loss: 0.6767 - val_accuracy: 0.6561\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7094 - accuracy: 0.6528 - val_loss: 0.6245 - val_accuracy: 0.6918\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6940 - accuracy: 0.6559 - val_loss: 0.6563 - val_accuracy: 0.6607\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6713 - accuracy: 0.6665 - val_loss: 0.6348 - val_accuracy: 0.6753\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6812 - accuracy: 0.6652 - val_loss: 0.6320 - val_accuracy: 0.6825\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6992 - accuracy: 0.6535 - val_loss: 0.6781 - val_accuracy: 0.6581\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.7409 - accuracy: 0.6505 - val_loss: 0.6819 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6906 - accuracy: 0.6583 - val_loss: 0.6363 - val_accuracy: 0.6964\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6742 - accuracy: 0.6616 - val_loss: 0.6488 - val_accuracy: 0.6872\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6913 - accuracy: 0.6576 - val_loss: 0.7146 - val_accuracy: 0.6303\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6865 - accuracy: 0.6617 - val_loss: 0.6484 - val_accuracy: 0.6779\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6563 - accuracy: 0.6728 - val_loss: 0.7129 - val_accuracy: 0.6534\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6545 - accuracy: 0.6793 - val_loss: 0.6497 - val_accuracy: 0.6607\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6569 - accuracy: 0.6811 - val_loss: 0.6213 - val_accuracy: 0.6938\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6462 - accuracy: 0.6810 - val_loss: 0.6606 - val_accuracy: 0.6501\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6660 - accuracy: 0.6774 - val_loss: 0.5960 - val_accuracy: 0.7083\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6502 - accuracy: 0.6790 - val_loss: 0.6358 - val_accuracy: 0.7017\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6415 - accuracy: 0.6871 - val_loss: 0.6565 - val_accuracy: 0.6753\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6522 - accuracy: 0.6779 - val_loss: 0.7057 - val_accuracy: 0.6938\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6257 - accuracy: 0.6926 - val_loss: 0.6261 - val_accuracy: 0.6997\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6661 - accuracy: 0.6793 - val_loss: 0.6001 - val_accuracy: 0.7116\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6383 - accuracy: 0.6916 - val_loss: 0.6429 - val_accuracy: 0.6878\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6324 - accuracy: 0.6866 - val_loss: 0.5797 - val_accuracy: 0.7103\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6305 - accuracy: 0.6923 - val_loss: 0.5937 - val_accuracy: 0.7136\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6169 - accuracy: 0.7015 - val_loss: 0.8266 - val_accuracy: 0.6640\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6462 - accuracy: 0.6886 - val_loss: 0.5795 - val_accuracy: 0.7249\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6169 - accuracy: 0.6990 - val_loss: 0.7598 - val_accuracy: 0.6157\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6619 - accuracy: 0.6837 - val_loss: 0.5729 - val_accuracy: 0.7302\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6302 - accuracy: 0.6891 - val_loss: 0.5980 - val_accuracy: 0.7097\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6094 - accuracy: 0.7079 - val_loss: 0.5565 - val_accuracy: 0.7156\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.5876 - accuracy: 0.7150 - val_loss: 0.6474 - val_accuracy: 0.6607\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6095 - accuracy: 0.7025 - val_loss: 0.5168 - val_accuracy: 0.7606\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5926 - accuracy: 0.7092 - val_loss: 0.6636 - val_accuracy: 0.7063\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6120 - accuracy: 0.6993 - val_loss: 0.5462 - val_accuracy: 0.7361\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.5795 - accuracy: 0.7173 - val_loss: 0.5347 - val_accuracy: 0.7354\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5848 - accuracy: 0.7252 - val_loss: 0.5323 - val_accuracy: 0.7632\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5921 - accuracy: 0.7153 - val_loss: 0.5649 - val_accuracy: 0.7196\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5873 - accuracy: 0.7229 - val_loss: 0.6289 - val_accuracy: 0.7004\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.6144 - accuracy: 0.7092 - val_loss: 0.5755 - val_accuracy: 0.7249\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5549 - accuracy: 0.7331 - val_loss: 0.6669 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5680 - accuracy: 0.7272 - val_loss: 0.5610 - val_accuracy: 0.7242\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5739 - accuracy: 0.7259 - val_loss: 0.6858 - val_accuracy: 0.6832\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6436 - accuracy: 0.6998 - val_loss: 0.5763 - val_accuracy: 0.6991\n",
      "Epoch 79/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5528 - accuracy: 0.7348 - val_loss: 0.5061 - val_accuracy: 0.7507\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5759 - accuracy: 0.7252 - val_loss: 0.6069 - val_accuracy: 0.7163\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5618 - accuracy: 0.7286 - val_loss: 0.5518 - val_accuracy: 0.7440\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.6263 - accuracy: 0.7039 - val_loss: 0.5186 - val_accuracy: 0.7526\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5447 - accuracy: 0.7338 - val_loss: 0.5297 - val_accuracy: 0.7388\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5706 - accuracy: 0.7241 - val_loss: 0.5326 - val_accuracy: 0.7599\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.5440 - accuracy: 0.7404 - val_loss: 0.5290 - val_accuracy: 0.7447\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5823 - accuracy: 0.7255 - val_loss: 0.5422 - val_accuracy: 0.7388\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5426 - accuracy: 0.7433 - val_loss: 0.5193 - val_accuracy: 0.7533\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5392 - accuracy: 0.7327 - val_loss: 0.5758 - val_accuracy: 0.7335\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5596 - accuracy: 0.7405 - val_loss: 0.5282 - val_accuracy: 0.7341\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5440 - accuracy: 0.7432 - val_loss: 0.5064 - val_accuracy: 0.7480\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5237 - accuracy: 0.7489 - val_loss: 0.4969 - val_accuracy: 0.7626\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5141 - accuracy: 0.7520 - val_loss: 0.4945 - val_accuracy: 0.7771\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 2s 7ms/step - loss: 0.5222 - accuracy: 0.7541 - val_loss: 0.5039 - val_accuracy: 0.7632\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5255 - accuracy: 0.7520 - val_loss: 0.5573 - val_accuracy: 0.7295\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5247 - accuracy: 0.7469 - val_loss: 0.4837 - val_accuracy: 0.7394\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5044 - accuracy: 0.7565 - val_loss: 0.4810 - val_accuracy: 0.7725\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5136 - accuracy: 0.7601 - val_loss: 0.4929 - val_accuracy: 0.7705\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5052 - accuracy: 0.7571 - val_loss: 0.5261 - val_accuracy: 0.7493\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.5040 - accuracy: 0.7618 - val_loss: 0.4913 - val_accuracy: 0.7771\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 0.4730 - accuracy: 0.7735 - val_loss: 0.5093 - val_accuracy: 0.7573\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_CNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=1, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.5)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    DCNN_BiGRU_model = build_CNN_BiGRU_model((X_train.shape[1], X_train.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_DCNN_BiGRU = DCNN_BiGRU_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu sau PCA: (10080, 8, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_2d = reshaped_data.reshape(-1, reshaped_data.shape[2])  # (1000 * 10, 2000)\n",
    "\n",
    "# Áp dụng PCA để giảm số timesteps từ 2000 xuống 500\n",
    "n_components = 1000\n",
    "pca = PCA(n_components=n_components)\n",
    "X_2d_reduced = pca.fit_transform(X_2d)  # (1000 * 10, 500)\n",
    "\n",
    "# Chuyển lại thành dạng 3D\n",
    "X_reduced = X_2d_reduced.reshape(reshaped_data.shape[0], reshaped_data.shape[1], n_components)  # (1000, 10, 500)\n",
    "print(\"Kích thước dữ liệu sau PCA:\", X_reduced.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('pca_data.npy', X_reduced)\n",
    "pca_data = np.load('pca_data.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape:(7056, 8, 1000)\n",
      "y_train's shape:(7056,)\n",
      "X_test's shape:(1512, 8, 1000)\n",
      "y_test's shape:(1512,)\n",
      "X_val's shape:(1512, 8, 1000)\n",
      "y_val's shape:(1512,)\n"
     ]
    }
   ],
   "source": [
    "# input_train = reshaped_data\n",
    "# output_train = reshaped_labels\n",
    "\n",
    "input_train = pca_data\n",
    "output_train = reshaped_labels\n",
    "\n",
    "# input_train = augmented_data\n",
    "# output_train = augmented_labels\n",
    "\n",
    "X_train_1, X_temp_1, y_train_1, y_temp_1 = train_test_split(input_train, output_train, test_size=0.3, random_state=42)\n",
    "X_valid_1, X_test_1, y_valid_1, y_test_1 = train_test_split(X_temp_1, y_temp_1, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train's shape:\" + str(X_train_1.shape))\n",
    "print(\"y_train's shape:\" + str(y_train_1.shape))\n",
    "print(\"X_test's shape:\" + str(X_test_1.shape))\n",
    "print(\"y_test's shape:\" + str(y_test_1.shape))\n",
    "print(\"X_val's shape:\" + str(X_valid_1.shape))\n",
    "print(\"y_val's shape:\" + str(y_valid_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 1000)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 8, 400)           1442400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 8, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               320100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,485,506\n",
      "Trainable params: 2,485,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "221/221 [==============================] - 6s 14ms/step - loss: 1.7742 - accuracy: 0.2048 - val_loss: 1.7220 - val_accuracy: 0.2249\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.6744 - accuracy: 0.2673 - val_loss: 1.6210 - val_accuracy: 0.2467\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.5584 - accuracy: 0.3190 - val_loss: 1.5841 - val_accuracy: 0.3122\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.5071 - accuracy: 0.3465 - val_loss: 1.5215 - val_accuracy: 0.3724\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.4549 - accuracy: 0.3764 - val_loss: 1.5155 - val_accuracy: 0.3823\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.4236 - accuracy: 0.3999 - val_loss: 1.5019 - val_accuracy: 0.3790\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3830 - accuracy: 0.4097 - val_loss: 1.5212 - val_accuracy: 0.4173\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3592 - accuracy: 0.4297 - val_loss: 1.4920 - val_accuracy: 0.4418\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3439 - accuracy: 0.4444 - val_loss: 1.5639 - val_accuracy: 0.4193\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3199 - accuracy: 0.4658 - val_loss: 1.4624 - val_accuracy: 0.4299\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.2992 - accuracy: 0.4667 - val_loss: 1.5424 - val_accuracy: 0.4226\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.2812 - accuracy: 0.4940 - val_loss: 1.5480 - val_accuracy: 0.4325\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.2566 - accuracy: 0.5020 - val_loss: 1.4719 - val_accuracy: 0.4643\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.2084 - accuracy: 0.5232 - val_loss: 1.4658 - val_accuracy: 0.5013\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.1267 - accuracy: 0.5568 - val_loss: 1.4102 - val_accuracy: 0.5159\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.0502 - accuracy: 0.5869 - val_loss: 1.4096 - val_accuracy: 0.5317\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.9830 - accuracy: 0.6154 - val_loss: 1.2970 - val_accuracy: 0.6230\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.9166 - accuracy: 0.6385 - val_loss: 1.3358 - val_accuracy: 0.6045\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.8738 - accuracy: 0.6529 - val_loss: 1.2063 - val_accuracy: 0.6303\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.8188 - accuracy: 0.6780 - val_loss: 1.2994 - val_accuracy: 0.6283\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.7747 - accuracy: 0.6895 - val_loss: 1.2247 - val_accuracy: 0.6653\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.7396 - accuracy: 0.7065 - val_loss: 1.2905 - val_accuracy: 0.6541\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.7077 - accuracy: 0.7256 - val_loss: 1.2336 - val_accuracy: 0.6825\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.6578 - accuracy: 0.7358 - val_loss: 1.2106 - val_accuracy: 0.6931\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.6345 - accuracy: 0.7571 - val_loss: 1.1424 - val_accuracy: 0.6978\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.6213 - accuracy: 0.7622 - val_loss: 1.1124 - val_accuracy: 0.7216\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.5938 - accuracy: 0.7744 - val_loss: 1.1290 - val_accuracy: 0.7083\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.5672 - accuracy: 0.7884 - val_loss: 1.2197 - val_accuracy: 0.7381\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.5422 - accuracy: 0.7894 - val_loss: 1.2047 - val_accuracy: 0.7553\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.5116 - accuracy: 0.8043 - val_loss: 1.1753 - val_accuracy: 0.7440\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4888 - accuracy: 0.8204 - val_loss: 1.3211 - val_accuracy: 0.7235\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4697 - accuracy: 0.8211 - val_loss: 1.3335 - val_accuracy: 0.7407\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4743 - accuracy: 0.8258 - val_loss: 1.1330 - val_accuracy: 0.7864\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4411 - accuracy: 0.8355 - val_loss: 1.1402 - val_accuracy: 0.7480\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4127 - accuracy: 0.8495 - val_loss: 1.0753 - val_accuracy: 0.7738\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3948 - accuracy: 0.8553 - val_loss: 1.0201 - val_accuracy: 0.7976\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3772 - accuracy: 0.8591 - val_loss: 1.0575 - val_accuracy: 0.8029\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3495 - accuracy: 0.8682 - val_loss: 1.1668 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3149 - accuracy: 0.8841 - val_loss: 1.0918 - val_accuracy: 0.8148\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3105 - accuracy: 0.8887 - val_loss: 1.0832 - val_accuracy: 0.8089\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2882 - accuracy: 0.8926 - val_loss: 1.0909 - val_accuracy: 0.8347\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3133 - accuracy: 0.8917 - val_loss: 1.1191 - val_accuracy: 0.8168\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2805 - accuracy: 0.8977 - val_loss: 0.9812 - val_accuracy: 0.8386\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2841 - accuracy: 0.9004 - val_loss: 1.2196 - val_accuracy: 0.8003\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2362 - accuracy: 0.9114 - val_loss: 1.0272 - val_accuracy: 0.8426\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2613 - accuracy: 0.9049 - val_loss: 0.9769 - val_accuracy: 0.8406\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2405 - accuracy: 0.9140 - val_loss: 1.0466 - val_accuracy: 0.8426\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2196 - accuracy: 0.9157 - val_loss: 0.9485 - val_accuracy: 0.8446\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2129 - accuracy: 0.9236 - val_loss: 1.0109 - val_accuracy: 0.8499\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2131 - accuracy: 0.9205 - val_loss: 1.1533 - val_accuracy: 0.8393\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1897 - accuracy: 0.9298 - val_loss: 1.1255 - val_accuracy: 0.8505\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2026 - accuracy: 0.9249 - val_loss: 1.1285 - val_accuracy: 0.8433\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1995 - accuracy: 0.9290 - val_loss: 1.1861 - val_accuracy: 0.8194\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1766 - accuracy: 0.9349 - val_loss: 1.0495 - val_accuracy: 0.8532\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2138 - accuracy: 0.9208 - val_loss: 0.9237 - val_accuracy: 0.8644\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1749 - accuracy: 0.9379 - val_loss: 0.9803 - val_accuracy: 0.8638\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1913 - accuracy: 0.9338 - val_loss: 1.1157 - val_accuracy: 0.8664\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1937 - accuracy: 0.9354 - val_loss: 1.1323 - val_accuracy: 0.8360\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1806 - accuracy: 0.9358 - val_loss: 1.1590 - val_accuracy: 0.8578\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1692 - accuracy: 0.9382 - val_loss: 1.0404 - val_accuracy: 0.8505\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1487 - accuracy: 0.9442 - val_loss: 1.1559 - val_accuracy: 0.8618\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1304 - accuracy: 0.9512 - val_loss: 1.1048 - val_accuracy: 0.8598\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1432 - accuracy: 0.9474 - val_loss: 1.1209 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1653 - accuracy: 0.9399 - val_loss: 1.1278 - val_accuracy: 0.8604\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1691 - accuracy: 0.9408 - val_loss: 1.1185 - val_accuracy: 0.8618\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1428 - accuracy: 0.9494 - val_loss: 1.1340 - val_accuracy: 0.8611\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1317 - accuracy: 0.9562 - val_loss: 0.9648 - val_accuracy: 0.8671\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1264 - accuracy: 0.9537 - val_loss: 0.9984 - val_accuracy: 0.8690\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1212 - accuracy: 0.9561 - val_loss: 1.1232 - val_accuracy: 0.8644\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1636 - accuracy: 0.9426 - val_loss: 1.1178 - val_accuracy: 0.8591\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1354 - accuracy: 0.9525 - val_loss: 1.3132 - val_accuracy: 0.8538\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1221 - accuracy: 0.9545 - val_loss: 1.2136 - val_accuracy: 0.8664\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1005 - accuracy: 0.9656 - val_loss: 1.2549 - val_accuracy: 0.8585\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1176 - accuracy: 0.9583 - val_loss: 1.2885 - val_accuracy: 0.8525\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0883 - accuracy: 0.9685 - val_loss: 1.2413 - val_accuracy: 0.8783\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0926 - accuracy: 0.9673 - val_loss: 1.3111 - val_accuracy: 0.8604\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1205 - accuracy: 0.9558 - val_loss: 1.1969 - val_accuracy: 0.8770\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0980 - accuracy: 0.9639 - val_loss: 1.1397 - val_accuracy: 0.8823\n",
      "Epoch 79/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0900 - accuracy: 0.9677 - val_loss: 1.2157 - val_accuracy: 0.8598\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1187 - accuracy: 0.9576 - val_loss: 0.9692 - val_accuracy: 0.8849\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1162 - accuracy: 0.9609 - val_loss: 1.0108 - val_accuracy: 0.8836\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0837 - accuracy: 0.9692 - val_loss: 1.0815 - val_accuracy: 0.8823\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0833 - accuracy: 0.9690 - val_loss: 1.2182 - val_accuracy: 0.8869\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0800 - accuracy: 0.9708 - val_loss: 1.2462 - val_accuracy: 0.8651\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0809 - accuracy: 0.9711 - val_loss: 1.0998 - val_accuracy: 0.8968\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0707 - accuracy: 0.9742 - val_loss: 1.1522 - val_accuracy: 0.8869\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1219 - accuracy: 0.9558 - val_loss: 1.4049 - val_accuracy: 0.8724\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1320 - accuracy: 0.9613 - val_loss: 1.1766 - val_accuracy: 0.8724\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1001 - accuracy: 0.9668 - val_loss: 0.9658 - val_accuracy: 0.8869\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0728 - accuracy: 0.9772 - val_loss: 0.8938 - val_accuracy: 0.8862\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0726 - accuracy: 0.9732 - val_loss: 1.0203 - val_accuracy: 0.8790\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0672 - accuracy: 0.9755 - val_loss: 0.9478 - val_accuracy: 0.8909\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0757 - accuracy: 0.9729 - val_loss: 0.9900 - val_accuracy: 0.8829\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0617 - accuracy: 0.9763 - val_loss: 0.9980 - val_accuracy: 0.8862\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0571 - accuracy: 0.9792 - val_loss: 1.0170 - val_accuracy: 0.8909\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 1.2570 - val_accuracy: 0.8552\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1061 - accuracy: 0.9644 - val_loss: 0.9854 - val_accuracy: 0.8955\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0714 - accuracy: 0.9760 - val_loss: 0.9050 - val_accuracy: 0.8856\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 1.0156 - val_accuracy: 0.8862\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0565 - accuracy: 0.9777 - val_loss: 1.0554 - val_accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_GRU_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape=input_shape)    \n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(input_tensor)   \n",
    "    x = Bidirectional(GRU(200, return_sequences=True,dropout=0.5))(x)  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    BiGRU_model = build_GRU_model((X_train_1.shape[1], X_train_1.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_BiGRU = BiGRU_model.fit(X_train_1, y_train_1, batch_size=32, epochs=100, validation_data=(X_valid_1, y_valid_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 1000)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 8, 128)            384128    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 64)             24640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 4, 400)           319200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 4, 400)           722400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               160100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,611,074\n",
      "Trainable params: 1,611,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "221/221 [==============================] - 7s 14ms/step - loss: 1.5711 - accuracy: 0.2980 - val_loss: 1.4710 - val_accuracy: 0.3161\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.4648 - accuracy: 0.3455 - val_loss: 1.4240 - val_accuracy: 0.3750\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.4248 - accuracy: 0.3673 - val_loss: 1.4005 - val_accuracy: 0.3816\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.4072 - accuracy: 0.3710 - val_loss: 1.4723 - val_accuracy: 0.3399\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3825 - accuracy: 0.3910 - val_loss: 1.4231 - val_accuracy: 0.3909\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3642 - accuracy: 0.3954 - val_loss: 1.4164 - val_accuracy: 0.3651\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3551 - accuracy: 0.4080 - val_loss: 1.3399 - val_accuracy: 0.4696\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3258 - accuracy: 0.4246 - val_loss: 1.3253 - val_accuracy: 0.4497\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.3006 - accuracy: 0.4419 - val_loss: 1.3137 - val_accuracy: 0.4491\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.2102 - accuracy: 0.5052 - val_loss: 1.2400 - val_accuracy: 0.5503\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 1.1003 - accuracy: 0.5540 - val_loss: 1.3524 - val_accuracy: 0.4583\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.9929 - accuracy: 0.6091 - val_loss: 0.9264 - val_accuracy: 0.6620\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.9166 - accuracy: 0.6396 - val_loss: 1.0424 - val_accuracy: 0.5866\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.8154 - accuracy: 0.6828 - val_loss: 0.8562 - val_accuracy: 0.7011\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.7054 - accuracy: 0.7343 - val_loss: 0.6460 - val_accuracy: 0.7692\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.6647 - accuracy: 0.7511 - val_loss: 0.9111 - val_accuracy: 0.6872\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.5924 - accuracy: 0.7771 - val_loss: 0.7922 - val_accuracy: 0.7242\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.5174 - accuracy: 0.8119 - val_loss: 0.6355 - val_accuracy: 0.7851\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4482 - accuracy: 0.8348 - val_loss: 0.4959 - val_accuracy: 0.8234\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4115 - accuracy: 0.8502 - val_loss: 0.6539 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.4473 - accuracy: 0.8353 - val_loss: 0.4426 - val_accuracy: 0.8611\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3729 - accuracy: 0.8692 - val_loss: 0.6092 - val_accuracy: 0.7745\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3440 - accuracy: 0.8766 - val_loss: 0.4142 - val_accuracy: 0.8519\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3170 - accuracy: 0.8893 - val_loss: 0.5472 - val_accuracy: 0.8161\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.3054 - accuracy: 0.8899 - val_loss: 0.6174 - val_accuracy: 0.8062\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2723 - accuracy: 0.9039 - val_loss: 0.4273 - val_accuracy: 0.8611\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2685 - accuracy: 0.9029 - val_loss: 0.4111 - val_accuracy: 0.8552\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2353 - accuracy: 0.9137 - val_loss: 0.4989 - val_accuracy: 0.8307\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2043 - accuracy: 0.9247 - val_loss: 0.3914 - val_accuracy: 0.8763\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.2424 - accuracy: 0.9168 - val_loss: 0.3970 - val_accuracy: 0.8578\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1904 - accuracy: 0.9334 - val_loss: 0.4321 - val_accuracy: 0.8644\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1747 - accuracy: 0.9412 - val_loss: 0.4221 - val_accuracy: 0.8664\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1790 - accuracy: 0.9352 - val_loss: 0.4160 - val_accuracy: 0.8690\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1589 - accuracy: 0.9432 - val_loss: 0.4186 - val_accuracy: 0.8790\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1773 - accuracy: 0.9365 - val_loss: 0.4409 - val_accuracy: 0.8664\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1179 - accuracy: 0.9580 - val_loss: 0.4508 - val_accuracy: 0.8776\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1483 - accuracy: 0.9474 - val_loss: 0.3798 - val_accuracy: 0.8856\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1283 - accuracy: 0.9535 - val_loss: 0.4811 - val_accuracy: 0.8638\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1245 - accuracy: 0.9590 - val_loss: 0.4908 - val_accuracy: 0.8677\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1288 - accuracy: 0.9573 - val_loss: 0.4448 - val_accuracy: 0.8743\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1409 - accuracy: 0.9512 - val_loss: 0.4434 - val_accuracy: 0.8704\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1110 - accuracy: 0.9620 - val_loss: 0.5878 - val_accuracy: 0.8604\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 0.5198 - val_accuracy: 0.8690\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0988 - accuracy: 0.9654 - val_loss: 0.5227 - val_accuracy: 0.8757\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1037 - accuracy: 0.9641 - val_loss: 0.5228 - val_accuracy: 0.8690\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1152 - accuracy: 0.9633 - val_loss: 0.4945 - val_accuracy: 0.8717\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1129 - accuracy: 0.9595 - val_loss: 0.5493 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0620 - accuracy: 0.9785 - val_loss: 0.7569 - val_accuracy: 0.8492\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0883 - accuracy: 0.9711 - val_loss: 0.6011 - val_accuracy: 0.8479\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0854 - accuracy: 0.9692 - val_loss: 0.6071 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 0.4558 - val_accuracy: 0.8757\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0676 - accuracy: 0.9765 - val_loss: 0.5886 - val_accuracy: 0.8651\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 0.6308 - val_accuracy: 0.8519\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.7736 - val_accuracy: 0.8545\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0877 - accuracy: 0.9702 - val_loss: 0.6132 - val_accuracy: 0.8651\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.6076 - val_accuracy: 0.8724\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.6474 - val_accuracy: 0.8671\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 0.7304 - val_accuracy: 0.8624\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0504 - accuracy: 0.9831 - val_loss: 0.6714 - val_accuracy: 0.8730\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.5932 - val_accuracy: 0.8816\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0407 - accuracy: 0.9874 - val_loss: 0.7131 - val_accuracy: 0.8677\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0773 - accuracy: 0.9762 - val_loss: 0.6742 - val_accuracy: 0.8565\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0701 - accuracy: 0.9758 - val_loss: 0.5197 - val_accuracy: 0.8810\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0536 - accuracy: 0.9813 - val_loss: 0.5850 - val_accuracy: 0.8803\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.6413 - val_accuracy: 0.8724\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0849 - accuracy: 0.9712 - val_loss: 0.5804 - val_accuracy: 0.8757\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.7884 - val_accuracy: 0.8671\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0928 - accuracy: 0.9694 - val_loss: 0.6373 - val_accuracy: 0.8690\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.6561 - val_accuracy: 0.8783\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.7801 - val_accuracy: 0.8538\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.7247 - val_accuracy: 0.8611\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0529 - accuracy: 0.9816 - val_loss: 0.5884 - val_accuracy: 0.8770\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0746 - accuracy: 0.9743 - val_loss: 0.5360 - val_accuracy: 0.8717\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.6995 - val_accuracy: 0.8651\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.6815 - val_accuracy: 0.8796\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.7739 - val_accuracy: 0.8611\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0601 - accuracy: 0.9814 - val_loss: 0.5562 - val_accuracy: 0.8763\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0356 - accuracy: 0.9874 - val_loss: 0.6783 - val_accuracy: 0.8737\n",
      "Epoch 79/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.6528 - val_accuracy: 0.8730\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.7623 - val_accuracy: 0.8776\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0783 - accuracy: 0.9769 - val_loss: 0.5870 - val_accuracy: 0.8776\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.8029 - val_accuracy: 0.8611\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0796 - accuracy: 0.9742 - val_loss: 0.5771 - val_accuracy: 0.8664\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.7624 - val_accuracy: 0.8724\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.7693 - val_accuracy: 0.8737\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.1001 - accuracy: 0.9684 - val_loss: 0.5789 - val_accuracy: 0.8717\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.7375 - val_accuracy: 0.8697\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.8500 - val_accuracy: 0.8320\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.7109 - val_accuracy: 0.8657\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.7582 - val_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 1.2906 - val_accuracy: 0.8095\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0796 - accuracy: 0.9746 - val_loss: 0.6804 - val_accuracy: 0.8737\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0335 - accuracy: 0.9878 - val_loss: 0.6422 - val_accuracy: 0.8737\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.7103 - val_accuracy: 0.8763\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 0.7690 - val_accuracy: 0.8710\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.7617 - val_accuracy: 0.8677\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.8709 - val_accuracy: 0.8519\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.6337 - val_accuracy: 0.8776\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.7256 - val_accuracy: 0.8730\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 2s 10ms/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 0.8578 - val_accuracy: 0.8519\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "def build_PCA_1DCNN_BiGRU_model(input_shape, num_classes):\n",
    "    # Định nghĩa input tensor\n",
    "    input_tensor = Input(shape=input_shape)  # input_shape: (timesteps, features), ví dụ (10, 2000)\n",
    "\n",
    "    # 1D CNN layers để trích xuất đặc trưng không gian\n",
    "    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "    x = MaxPooling1D(pool_size=2)(x)  # Giảm kích thước chuỗi (timesteps) xuống một nửa\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(x)  # Thêm dropout để giảm overfitting\n",
    "\n",
    "    # BiGRU layers để học thông tin tuần tự\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)  # Lớp BiGRU đầu tiên\n",
    "    x = Bidirectional(GRU(200, return_sequences=True, dropout=0.5))(x)  # Lớp BiGRU thứ hai với dropout\n",
    "    x = Flatten()(x)  # Chuyển thành vector 1D để kết nối với Dense layers\n",
    "\n",
    "    # Dense layers để phân loại\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Run the model on GPU if available\n",
    "with tf.device('/GPU:0'):\n",
    "    PCA_DCNN_BiGRU_model = build_PCA_1DCNN_BiGRU_model((X_train_1.shape[1], X_train_1.shape[2]), num_classes)  # Adjusted input shape to have 3 dimensions\n",
    "    \n",
    "    PCA_DCNN_BiGRU_model.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_PCA_DCNN_BiGRU = PCA_DCNN_BiGRU_model.fit(X_train_1, y_train_1, batch_size=32, epochs=100, validation_data=(X_valid_1, y_valid_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History saved to 'History/pca_1dcnn_bigru_accuracy.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# DCNN_model.save(f'Model/model_1dcnn.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/1dcnn_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_1DCNN.history['accuracy'], \n",
    "#                 'val_accuracy': history_1DCNN.history['val_accuracy'],\n",
    "#                 'train_loss': history_1DCNN.history['loss'],\n",
    "#                 'val_loss': history_1DCNN.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/1dcnn_accuracy.pkl'))\n",
    "\n",
    "# GRU_model.save(f'Model/model_gru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/gru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_GRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_GRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_GRU.history['loss'],\n",
    "#                 'val_loss': history_GRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/gru_accuracy.pkl'))\n",
    "\n",
    "BiGRU_model.save(f'Model/model_pca_1dcnn_bigru.h5')\n",
    "# Save history as a.pkl file\n",
    "with open(f'History/pca_1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "    pickle.dump({'train_accuracy': history_BiGRU.history['accuracy'], \n",
    "                'val_accuracy': history_BiGRU.history['val_accuracy'],\n",
    "                'train_loss': history_BiGRU.history['loss'],\n",
    "                'val_loss': history_BiGRU.history['val_loss']}, f)\n",
    "print(\"History saved to '{}'.\".format(f'History/pca_1dcnn_bigru_accuracy.pkl'))\n",
    "\n",
    "# DCNN_BiGRU_model.save(f'Model/model_1dcnn_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_DCNN_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_DCNN_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_DCNN_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_DCNN_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/1dcnn_bigru_accuracy.pkl'))\n",
    "\n",
    "# PCA_DCNN_BiGRU_model.save(f'Model/model_pca_1dcnn_bigru.h5')\n",
    "# # Save history as a.pkl file\n",
    "# with open(f'History/pca_1dcnn_bigru_accuracy.pkl','wb') as f:\n",
    "#     pickle.dump({'train_accuracy': history_PCA_DCNN_BiGRU.history['accuracy'], \n",
    "#                 'val_accuracy': history_PCA_DCNN_BiGRU.history['val_accuracy'],\n",
    "#                 'train_loss': history_PCA_DCNN_BiGRU.history['loss'],\n",
    "#                 'val_loss': history_PCA_DCNN_BiGRU.history['val_loss']}, f)\n",
    "# print(\"History saved to '{}'.\".format(f'History/pca_1dcnn_bigru_accuracy.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
